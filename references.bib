@Article{chikhaouiLearningSongACTR2009,
  title = {Learning a {{Song}}: An {{ACT-R Model}}},
  shorttitle = {Learning a {{Song}}},
  author = {Belkacem Chikhaoui and H{\a'e}{\a`\i} Ene and Mathieu Beaudoin and Guillaume Pratte and Philippe Bellefeuille and Fernando Laudares},
  date = {2009-01-01},
  abstract = {The way music is interpreted by the human brain is a very interesting topic, but also an intricate one. Although this domain has been studied for over a century, many gray areas remain in the understanding of music. Recent advances have enabled us to perform accurate measurements of the time taken by the human brain to interpret and assimilate a sound. Cognitive computing provides tools and development environments that facilitate human cognition simulation. ACT-R is a cognitive architecture which offers an environment for implementing human cognitive tasks. This project combines our understanding of the music interpretation by a human listener and the ACT-R cognitive architecture to build SINGER, a computerized simulation for listening and recalling songs. The results are similar to human experimental data. Simulation results also show how it is easier to remember short melodies than long melodies which require more trials to be recalled correctly.},
  file = {/Users/sebsilas/Zotero/storage/JUA379SZ/Chikhaoui et al. - 2009 - Learning a Song an ACT-R Model.pdf},
}
@InCollection{reiter-haasPredictingMusicRelistening2021,
  title = {Predicting {{Music Relistening Behavior Using}} the {{ACT-R Framework}}},
  booktitle = {Fifteenth {{ACM Conference}} on {{Recommender Systems}}},
  author = {Markus Reiter-Haas and Emilia Parada-Cabaleiro and Markus Schedl and Elham Motamedi and Marko Tkalcic and Elisabeth Lex},
  date = {2021-09-13},
  pages = {702--707},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  url = {https://doi.org/10.1145/3460231.3478846},
  urldate = {2022-05-27},
  abstract = {Providing suitable recommendations is of vital importance to improve the user satisfaction of music recommender systems. Here, users often listen to the same track repeatedly and appreciate recommendations of the same song multiple times. Thus, accounting for users’ relistening behavior is critical for music recommender systems. In this paper, we describe a psychology-informed approach to model and predict music relistening behavior that is inspired by studies in music psychology, which relate music preferences to human memory. We adopt a well-established psychological theory of human cognition that models the operations of human memory, i.e., Adaptive Control of Thought—Rational (ACT-R). In contrast to prior work, which uses only the base-level component of ACT-R, we utilize five components of ACT-R, i.e., base-level, spreading, partial matching, valuation, and noise, to investigate the effect of five factors on music relistening behavior: (i) recency and frequency of prior exposure to tracks, (ii) co-occurrence of tracks, (iii) the similarity between tracks, (iv) familiarity with tracks, and (v) randomness in behavior. On a dataset of 1.7 million listening events from Last.fm, we evaluate the performance of our approach by sequentially predicting the next track(s) in user sessions. We find that recency and frequency of prior exposure to tracks is an effective predictor of relistening behavior. Besides, considering the co-occurrence of tracks and familiarity with tracks further improves performance in terms of R-precision. We hope that our work inspires future research on the merits of considering cognitive aspects of memory retrieval to model and predict complex user behavior.},
  isbn = {978-1-4503-8458-2},
  keywords = {adaptive control thought-rational (ACT-R),cognition-inspired retrieval,human cognition,music prediction,psychology-informed recommender systems,relistening behavior,user modeling},
}
@Article{bigandAreWeExperienced2006,
  title = {Are We “Experienced Listeners”? {{A}} Review of the Musical Capacities That Do Not Depend on Formal Musical Training},
  shorttitle = {Are We “Experienced Listeners”?},
  author = {E. Bigand and B. Poulin-Charronnat},
  date = {2006-05-01},
  journaltitle = {Cognition},
  shortjournal = {Cognition},
  series = {The {{Nature}} of {{Music}}},
  volume = {100},
  number = {1},
  pages = {100--130},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2005.11.007},
  url = {https://www.sciencedirect.com/science/article/pii/S0010027705002234},
  urldate = {2022-01-28},
  abstract = {The present paper reviews a set of studies designed to investigate different aspects of the capacity for processing Western music. This includes perceiving the relationships between a theme and its variations, perceiving musical tensions and relaxations, generating musical expectancies, integrating local structures in large-scale structures, learning new compositional systems and responding to music in an emotional (affective) way. The main focus of these studies was to evaluate the influence of intensive musical training on these capacities. The overall set of data highlights that some musical capacities are acquired through exposure to music without the help of explicit training. These capacities reach such a degree of sophistication that they enable untrained listeners to respond to music as “musically experienced listeners” do.},
  langid = {english},
  keywords = {Emotion,Implicit learning,Music cognition,Musical expertise,Musical priming},
  file = {/Users/sebsilas/Zotero/storage/TUG72UXL/S0010027705002234.html},
}

@Article{bigandMultidimensionalScalingEmotional2005,
  title = {Multidimensional Scaling of Emotional Responses to Music: {{The}} Effect of Musical Expertise and of the Duration of the Excerpts},
  shorttitle = {Multidimensional Scaling of Emotional Responses to Music},
  author = {E. Bigand and S. Vieillard and F. Madurell and J. Marozeau and A. Dacquet},
  date = {2005-12-01},
  journaltitle = {Cognition and Emotion},
  volume = {19},
  number = {8},
  pages = {1113--1139},
  publisher = {{Routledge}},
  issn = {0269-9931},
  doi = {10.1080/02699930500204250},
  url = {https://doi.org/10.1080/02699930500204250},
  urldate = {2022-01-28},
  abstract = {Musically trained and untrained listeners were required to listen to 27 musical excerpts and to group those that conveyed a similar emotional meaning (Experiment 1). The groupings were transformed into a matrix of emotional dissimilarity that was analysed through multidimensional scaling methods (MDS). A 3-dimensional space was found to provide a good fit of the data, with arousal and emotional valence as the primary dimensions. Experiments 2 and 3 confirmed the consistency of this 3-dimensional space using excerpts of only 1 second duration. The overall findings indicate that emotional responses to music are very stable within and between participants, and are weakly influenced by musical expertise and excerpt duration. These findings are discussed in light of a cognitive account of musical emotion.},
  annotation = {\_eprint: https://doi.org/10.1080/02699930500204250},
}

@Article{ettlingerImplicitMemoryMusic2011,
  title = {Implicit {{Memory}} in {{Music}} and {{Language}}},
  author = {Marc Ettlinger and Elizabeth Margulis and Patrick Wong},
  date = {2011},
  journaltitle = {Frontiers in Psychology},
  volume = {2},
  issn = {1664-1078},
  url = {https://www.frontiersin.org/article/10.3389/fpsyg.2011.00211},
  urldate = {2022-01-28},
  abstract = {Research on music and language in recent decades has focused on their overlapping neurophysiological, perceptual, and cognitive underpinnings, ranging from the mechanism for encoding basic auditory cues to the mechanism for detecting violations in phrase structure. These overlaps have most often been identified in musicians with musical knowledge that was acquired explicitly, through formal training. In this paper, we review independent bodies of work in music and language that suggest an important role for implicitly acquired knowledge, implicit memory, and their associated neural structures in the acquisition of linguistic or musical grammar. These findings motivate potential new work that examines music and language comparatively in the context of the implicit memory system.},
  file = {/Users/sebsilas/Zotero/storage/FKG9MDX4/Ettlinger et al. - 2011 - Implicit Memory in Music and Language.pdf},
}

@Article{mullensiefenRoleFeaturesContext2014,
  title = {The Role of Features and Context in Recognition of Novel Melodies},
  author = {Daniel M{\"u}llensiefen and Andrea R. Halpern},
  date = {2014},
  journaltitle = {Music Perception},
  volume = {31},
  number = {5},
  pages = {418--435},
  publisher = {{University of California Press}},
  location = {{US}},
  issn = {1533-8312(Electronic),0730-7829(Print)},
  doi = {10.1525/mp.2014.31.5.418},
  abstract = {We investigated how well structural features such as note density or the relative number of changes in the melodic contour could predict success in implicit and explicit memory for unfamiliar melodies. We also analyzed which features are more likely to elicit increasingly confident judgments of “old” in a recognition memory task. An automated analysis program computed structural aspects of melodies, both independent of any context, and also with reference to the other melodies in the testset and the parent corpus of pop music. A few features predicted success in both memory tasks, which points to a shared memory component. However, motivic complexity compared to a large corpus of pop music had different effects on explicit and implicit memory. We also found that just a few features are associated with different rates of “old” judgments, whether the items were old or new. Rarer motives relative to the testset predicted hits and rarer motives relative to the corpus predicted false alarms. This data-driven analysis provides further support for both shared and separable mechanisms in implicit and explicit memory retrieval, as well as the role of distinctiveness in true and false judgments of familiarity. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Analysis,Explicit Memory,Implicit Memory,Judgment,Memory,Music},
  file = {/Users/sebsilas/Zotero/storage/8WSVRZYZ/Müllensiefen and Halpern - 2014 - The role of features and context in recognition of.pdf;/Users/sebsilas/Zotero/storage/PU8B6D3J/2014-24007-002.html},
}

@Article{schellenbergFinegrainedImplicitMemory2019,
  title = {Fine-Grained {{Implicit Memory}} for {{Key}} and {{Tempo}}},
  author = {E. Glenn Schellenberg and Michael W. Weiss and Chen Peng and Shayan Alam},
  date = {2019-01-01},
  journaltitle = {Music \& Science},
  shortjournal = {Music \& Science},
  volume = {2},
  pages = {2059204319857198},
  publisher = {{SAGE Publications Ltd}},
  issn = {2059-2043},
  doi = {10.1177/2059204319857198},
  url = {https://doi.org/10.1177/2059204319857198},
  urldate = {2022-01-28},
  abstract = {Listeners remember the pitch level (key) and tempo of musical recordings they have heard multiple times. They also have long-term implicit memory for the key and tempo of novel melodies heard for the first time in the laboratory. In previous research, however, the stimulus melodies were simple and repetitive and the changes in key or tempo were large. Here, we tested the limits of implicit memory for the key and tempo of more complex stimulus melodies. Musically trained and untrained listeners heard 12 novel melodies during an exposure phase and 24 (12 old, 12 new) during a subsequent test (recognition) phase. From exposure to test, half of the melodies were transposed up or down (changed in key) (Experiment 1), or sped up or slowed down (Experiment 2), but to varying degrees. Musically trained listeners displayed enhanced recognition, but transposing or changing the tempo of the melodies reduced performance similarly for all listeners. The effect of the key change did not wane as the transposition was reduced from 6 semitones to 1, but recognition in general was worse as the pitch range of the stimulus melodies increased. The magnitude of the tempo change had a very small effect on response patterns, but Bayesian analyses indicated that the observed data were more likely without considering magnitude. The results suggest that musically trained and untrained listeners have implicit memory for key and tempo that is remarkably fine-grained, even for melodies that are heard for the first time in the laboratory, such that small changes in either feature make a melody less recognizable.},
  langid = {english},
  keywords = {Key,melody,music training,pitch,recognition,tempo},
  file = {/Users/sebsilas/Zotero/storage/PEWX4J99/Schellenberg et al. - 2019 - Fine-grained Implicit Memory for Key and Tempo.pdf},
}

@Article{tillmannImplicitLearningTonality2000,
  title = {Implicit Learning of Tonality: {{A}} Self-Organizing Approach},
  shorttitle = {Implicit Learning of Tonality},
  author = {Barbara Tillmann and Jamshed J. Bharucha and Emmanuel Bigand},
  date = {2000},
  journaltitle = {Psychological Review},
  volume = {107},
  number = {4},
  pages = {885--913},
  publisher = {{American Psychological Association}},
  location = {{US}},
  issn = {1939-1471(Electronic),0033-295X(Print)},
  doi = {10.1037/0033-295X.107.4.885},
  abstract = {Tonal music is a highly structured system that is ubiquitous in our cultural environment. We demonstrate the acquisition of implicit knowledge of tonal structure through neural self-organization resulting from mere exposure to simultaneous and sequential combinations of tones. In the process of learning, a network with fundamental neural constraints comes to internalize the essential correlational structure of tonal music. After learning, the network was run through a range of experiments from the literature. The model provides a parsimonious account of a variety of empirical findings dealing with the processing of tone, chord, and key relationships, including relatedness judgments, memory judgments, and expectancies. It also illustrates the plausibility of activation being a unifying mechanism underlying a range of cognitive tasks. (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
  keywords = {Connectionism,Experimentation,Implicit Learning,Incidental Learning,Music Perception,Neural Networks,Pitch (Frequency)},
  file = {/Users/sebsilas/Zotero/storage/WYQ3T9Z6/Tillmann et al. - 2000 - Implicit learning of tonality A self-organizing a.pdf;/Users/sebsilas/Zotero/storage/LEZTZY3K/2000-02818-009.html},
}
@Article{jakubowskiDissectingEarwormMelodic2017,
  title = {Dissecting an Earworm: {{Melodic}} Features and Song Popularity Predict Involuntary Musical Imagery},
  shorttitle = {Dissecting an Earworm},
  author = {Kelly Jakubowski and Sebastian Finkel and Lauren Stewart and Daniel M{\"u}llensiefen},
  date = {2017},
  journaltitle = {Psychology of Aesthetics, Creativity, and the Arts},
  volume = {11},
  number = {2},
  pages = {122--135},
  publisher = {{Educational Publishing Foundation}},
  location = {{US}},
  issn = {1931-390X},
  doi = {10.1037/aca0000090},
  abstract = {Involuntary musical imagery (INMI or “earworms”)—the spontaneous recall and repeating of a tune in one’s mind—can be attributed to a wide range of triggers, including memory associations and recent musical exposure. The present study examined whether a song’s popularity and melodic features might also help to explain whether it becomes INMI, using a dataset of tunes that were named as INMI by 3,000 survey participants. It was found that songs that had achieved greater success and more recent runs in the U.K. music charts were reported more frequently as INMI. A set of 100 of these frequently named INMI tunes was then matched to 100 tunes never named as INMI by the survey participants, in terms of popularity and song style. These 2 groups of tunes were compared using 83 statistical summary and corpus-based melodic features and automated classification techniques. INMI tunes were found to have more common global melodic contours and less common average gradients between melodic turning points than non-INMI tunes, in relation to a large pop music corpus. INMI tunes also displayed faster average tempi than non-INMI tunes. Results are discussed in relation to literature on INMI, musical memory, and melodic “catchiness.” (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  keywords = {Analysis,Imagery,Memory,Music,Music Perception},
  file = {/Users/sebsilas/Zotero/storage/RHJGB2ZL/Jakubowski et al. - 2017 - Dissecting an earworm Melodic features and song p.pdf;/Users/sebsilas/Zotero/storage/SR9CUKCH/2016-53098-001.html},
}
@Article{idsonBidimensionalModelPitch1978,
  title = {A Bidimensional Model of Pitch in the Recognition of Melodies},
  author = {Wendy L. Idson and Dominic W. Massaro},
  date = {1978},
  journaltitle = {Perception \& Psychophysics},
  volume = {24},
  number = {6},
  pages = {551--565},
  publisher = {{Psychonomic Society}},
  location = {{US}},
  issn = {1532-5962},
  doi = {10.3758/BF03198783},
  abstract = {In 4 experiments with a total of 81 undergraduates, melodies were subjected to structural transformations designed to evaluate the effects of interval magnitude, contour, tone height, and tone chroma. In 2 transformations, the component tones of a melody were displaced by octave intervals, either preserving or violating the pattern of changes in pitch direction (melodic contour). Replicating previous work, when contour was violated perception of the melody was severely disrupted. In contrast, when contour was preserved, the melodies were identified as accurately as the untransformed melodies. In other transformations, a variety of forms of contour information were preserved, while eliminating information for absolute pitch and interval magnitude. The level of performance on all such transformations fell between the levels observed in the other 2 conditions. Results suggest that the bidimensional model of pitch is applicable to recognition of melodies as well as single tones. Moreover, the results argue that contour, as well as interval magnitude, is providing essential information for melodic perception. (43 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Auditory Discrimination,Models,Music,Pitch (Frequency),Recognition (Learning),Stimulus Parameters},
  file = {/Users/sebsilas/Zotero/storage/FH37X2SH/Idson and Massaro - 1978 - A bidimensional model of pitch in the recognition .pdf;/Users/sebsilas/Zotero/storage/2CCKTXRU/1980-20352-001.html},
}
@Article{dowlingScaleContourTwo1978,
  title = {Scale and Contour: {{Two}} Components of a Theory of Memory for Melodies},
  shorttitle = {Scale and Contour},
  author = {W. Jay Dowling},
  date = {1978},
  journaltitle = {Psychological Review},
  volume = {85},
  number = {4},
  pages = {341--354},
  publisher = {{American Psychological Association}},
  location = {{US}},
  issn = {1939-1471},
  doi = {10.1037/0033-295X.85.4.341},
  abstract = {Develops a 2-component model of how melodies are stored in long- and short-term memory. The 1st component is the overlearned perceptual-motor schema of the musical scale. Evidence is presented supporting the lifetime stability of scales and the fact that they seem to have a basically logarithmic form cross-culturally. The 2nd component, melodic contour, is shown to function independently of pitch interval sequence in memory. 21 college students were studied using a recognition memory paradigm in which tonal standard stimuli were confused with same-contour comparisons, whether they were exact transpositions or tonal answers, but not with atonal comparison stimuli. This result is contrasted with earlier work using atonal melodies and shows the interdependence of the 2 components, scale and contour. (32 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Human Information Storage,Memory,Music,Pitch (Frequency)},
  file = {/Users/sebsilas/Zotero/storage/KUWF7RA7/1979-22754-001.html},
}

@Article{dowlingTimeCourseRecognition1995,
  title = {The Time Course of Recognition of Novel Melodies},
  author = {W. J. Dowling and S. Kwak and M. W. Andrews},
  date = {1995-02},
  journaltitle = {Perception \& Psychophysics},
  shortjournal = {Percept Psychophys},
  volume = {57},
  number = {2},
  eprint = {7885812},
  eprinttype = {pmid},
  pages = {136--149},
  issn = {0031-5117},
  doi = {10.3758/bf03206500},
  abstract = {Seven experiments explored the time course of recognition of brief novel melodies. In a continuous-running-memory task, subjects recognized melodic transpositions following delays up to 2.0 min. The delays were either empty or filled with other melodies. Test items included exact transpositions (T), same-contour lures (SC) with altered pitch intervals, and different-contour lures (DC); DCs differed from Ts in the pattern of ups and downs of pitch. With this design, we assessed subjects' discrimination of detailed changes in pitch intervals (T/SC discrimination) as well as their discrimination of contour changes (T/DC). We used both artificial and {"}real{"} melodies. Artificial melodies differed in conformity to a musical key, being tonal or atonal. After empty delays, T/DC discrimination was superior to T/SC discrimination. Surprisingly, after filled delays, T/SC discrimination was superior to T/DC. When only filled delays were tested, T/SC discrimination did not decline over the longest delays. T/DC performance declined more than did T/SC performance across both empty and filled delays. Tonality was an important factor only for T/SC discrimination after filled delays. T/DC performance was better with rhythmically intact folk melodies than with artificial isochronous melodies. Although T/SC performance improved over filled delays, it did not overtake T/DC performance. These results suggest that (1) contour and pitch-interval information make different contributions to recognition, with contour dominating performance after brief empty delays and pitch intervals dominating after longer filled delays; (2) a coherent tonality facilitates the encoding of pitch-interval patterns of melodies; and (3) the rich melodic-rhythmic contours of real melodies facilitate T/DC discrimination. These results are discussed in terms of automatic and controlled processing of melodic information.},
  langid = {english},
  keywords = {Adult,Attention,Female,Humans,Male,Mental Recall,Music,Pitch Perception,Psychoacoustics,Retention; Psychology},
  file = {/Users/sebsilas/Zotero/storage/M5I2KCKI/Dowling et al. - 1995 - The time course of recognition of novel melodies.pdf},
}

@Article{edworthyIntervalContourMelody1985,
  title = {Interval and {{Contour}} in {{Melody Processing}}},
  author = {Judy Edworthy},
  date = {1985},
  journaltitle = {Music Perception: An Interdisciplinary Journal},
  volume = {2},
  number = {3},
  eprint = {40285305},
  eprinttype = {jstor},
  pages = {375--388},
  publisher = {{University of California Press}},
  issn = {0730-7829},
  doi = {10.2307/40285305},
  abstract = {Musician subjects were required to detect interval and contour changes in transposed versions of standard melodies of 3, 5, 7, 9,11,13, and 15 notes. Subjects were significantly better at detecting contour alterations for melodies of up to 11 notes but significantly better at detecting interval alterations in the 15-note melodies. Serial position effects for 5-, 7-, and 9-note melodies showed contour to be immediately precise after transposition, whereas the ability to detect interval alterations improved as the melodies progressed. These results suggest that, on transposition, contour information is immediately precise but is lost as melody length increases. Interval information is initially less precise but is more resistant to forgetting in longer melodies. The implication of this is that contour can be encoded independently of tonal context, whereas interval information becomes more precise as a tonal framework is established. Some musical implications of the finding are discussed.},
}

@Article{massaroRoleToneHeight1980,
  title = {The Role of Tone Height, Melodic Contour, and Tone Chroma in Melody Recognition},
  author = {Dom Massaro and Howard Kallman and Janet Kelly},
  date = {1980-02-01},
  journaltitle = {Journal of experimental psychology. Human learning and memory},
  shortjournal = {Journal of experimental psychology. Human learning and memory},
  volume = {6},
  pages = {77--90},
  doi = {10.1037//0278-7393.6.1.77},
  abstract = {The present experiments assessed the contribution of tone height, melodic contour, and tone chroma to melody recognition. Rather than using highly familiar folk songs as in earlier studies, subjects were taught new melodies. Novel melodies were used to (a) more precisely control potential cues (e.g., rhythm) that are not of present interest, (b) eliminate unison intervals that cannot be transformed appropriately, (c) provide a direct analysis of the nature of confusion errors, (d) test whether recently learned melodies are recognized differently than highly overlearned melodies, and (e) evaluate the extent to which practice in the experimental task alters the process of recognition. The results replicate previous studies using familiar folk songs. Transformations of the original melodies were accurately recognized when tone height was violated, but both melodic contour and tone chroma were maintained. Violating both tone height and contour while maintaining chroma produced extremely poor recognition. Performance was intermediate when just melodic contour was preserved. There is now good evidence to support the idea that melodic contour and tone chroma, in addition to tone height, contribute to recognition of both highly familiar and recently learned melodies.},
  file = {/Users/sebsilas/Zotero/storage/9FN9SUGF/Massaro et al. - 1980 - The role of tone height, melodic contour, and tone.pdf},
}
@Article{longRelationshipsPitchMemory1977,
  title = {Relationships between {{Pitch Memory}} in {{Short Melodies}} and {{Selected Factors}}},
  author = {Peggy A. Long},
  date = {1977},
  journaltitle = {Journal of Research in Music Education},
  volume = {25},
  number = {4},
  eprint = {3345268},
  eprinttype = {jstor},
  pages = {272--282},
  publisher = {{[MENC: The National Association for Music Education, Sage Publications, Inc.]}},
  issn = {0022-4294},
  doi = {10.2307/3345268},
  abstract = {This study investigated relationships between memory for pitch in short melodies and melody length, tonal structure, melodic contour, and music perception ability. Results indicated that all these factors interact to some degree with memory. The factors demonstrating the greatest influence were music perception ability (a product of previous music learning), and tonal structure (the degree of relationships among the pitches of a melody, commonly described as tonality or atonality). Memory for pitch improved as the number of pitches in a melody decreased. Certain melodic contours also caused variations in pitch memory.},
}
@Article{dewittRecognitionNovelMelodies1986,
  title = {Recognition of {{Novel Melodies}} after {{Brief Delays}}},
  author = {Lucinda A. Dewitt and Robert G. Crowder},
  date = {1986},
  journaltitle = {Music Perception: An Interdisciplinary Journal},
  volume = {3},
  number = {3},
  eprint = {40285336},
  eprinttype = {jstor},
  pages = {259--274},
  publisher = {{University of California Press}},
  issn = {0730-7829},
  doi = {10.2307/40285336},
  abstract = {Three experiments on the recognition of short melodies investigated the influence of contour and interval information (respectively, the pattern of changes in pitch direction and the ordered sequence of pitch distances in a melody). Subjects rated pairs of melodies as {"}same{"} or {"}different{"} on a five-point scale. Six conditions were defined by two delays (short, 1 sec; and long, 30 sec) and three item types (target, related, and lure). In Target pairs, the second melody retained the contour and interval information of the first melody, being an exact transposition to another key. In Related pairs, only the contour information was retained, while in the Lure pairs neither contour nor interval information was retained. In conformity with the reports of Dowling and Bartlett (1981), the results indicated that contour information had a larger influence on recognition at short delays, whereas interval information had a relatively larger influence at long delays. The results are also consistent with an alternative interpretation stressing the importance of tonality/modality information in melody recognition at long delays.},
}

@Article{dowlingImportanceIntervalInformation1981,
  title = {The {{Importance}} of {{Interval Information}} in {{Long-term Memory}} for {{Melodies}}},
  author = {Walter Dowling and James Bartlett},
  date = {1981-01-01},
  journaltitle = {Psychomusicology: A Journal of Research in Music Cognition},
  shortjournal = {Psychomusicology: A Journal of Research in Music Cognition},
  volume = {1},
  doi = {10.1037/h0094275},
  abstract = {Four experiments examined the roles of melodic contour and pitch interval information in recognition memory for melodies. In Experiments 1 and 2, subjects heard excerpts from Beethoven String Quartets, and subsequently attempted to detect copies of input melodies (Targets) as well as Related items, which resembled input items with respect to contour and rhythm, but not pitch intervals. Targets were recognized significantly better than Relateds, which were recognized only slightly more often than lures (Lures were drawn from other quartet movements not represented on the input list). Experiment 3 replicated this finding with novel, randomly generated melodies. All three experiments supported substantial retention of information regarding pitch intervals, as well as contour, over a retention interval of several minutes. Using the materials of Experiment 3 in a short-term memory paradigm, Experiment 4 examined short (5 sec) and long (31 sec) retention interval conditions. Contour information dominated performance with the short delay, but not with the long delay, where performance resembled that of the prior long-term memory experiments. While interval information is difficult to encode, it is apparently retained with high efficiency in long-term memory.},
  file = {/Users/sebsilas/Zotero/storage/WSHGBDBT/Dowling and Bartlett - 1981 - The Importance of Interval Information in Long-ter.pdf},
}

@Article{dowlingTonalStrengthMelody1991,
  title = {Tonal Strength and Melody Recognition after Long and Short Delays},
  author = {W. J. Dowling},
  date = {1991-10},
  journaltitle = {Perception \& Psychophysics},
  shortjournal = {Percept Psychophys},
  volume = {50},
  number = {4},
  eprint = {1758762},
  eprinttype = {pmid},
  pages = {305--313},
  issn = {0031-5117},
  doi = {10.3758/bf03212222},
  abstract = {In a continuous-running-memory task, subjects heard novel seven-note melodies that were tested after delays of 11 sec (empty) or 39 sec (filled). Test items were transposed to new pitch levels (to moderately distant keys in the musical sense) and included exact transpositions (targets), same-contour lures with altered pitch intervals, and new-contour lures. Melodies differed in tonal strength (degree of conformity to a musical key) and were tonally strong, tonally weak, or atonal. False alarms to same-contour lures decreased over the longer delay period, but only for tonal stimuli. In agreement with previous studies, discrimination of detailed changes in pitch intervals improved with increased delay, whereas discrimination of more global contour information declined, again only for tonal stimuli. These results suggest that poor short-delay performance in rejecting same-contour lures arises from confusion that is based on the similarity of tonality between standard stimuli and lures. If a test item has the same contour and a similar tonality to a just-presented item, subjects tend to accept it. After a delay filled with melodies in other tonalities, the salience of key information recedes, and subjects base their judgments on more detailed pattern information (namely, exact pitch intervals). The fact that tonality affects judgments of melodic contour indicates that contour is not an entirely separable feature of melodies but rather that a melody with its contour constitutes an integrated perceptual whole.},
  langid = {english},
  keywords = {Adult,Attention,Humans,Mental Recall,Music,Pitch Discrimination,Psychoacoustics,Retention; Psychology},
  file = {/Users/sebsilas/Zotero/storage/B3RDT3YJ/Dowling - 1991 - Tonal strength and melody recognition after long a.pdf},
}
@Article{kauffmanMemoryIntactMusic1989,
  title = {Memory for Intact Music Works: {{The}} Importance of Music Expertise and Retention Interval},
  shorttitle = {Memory for Intact Music Works},
  author = {William H. Kauffman and James C. Carlsen},
  date = {1989},
  journaltitle = {Psychomusicology: A Journal of Research in Music Cognition},
  volume = {8},
  number = {1},
  pages = {3--20},
  publisher = {{Illinois State University}},
  location = {{US}},
  issn = {2162-1535},
  doi = {10.1037/h0094235},
  abstract = {Examined the effects of music expertise and retention interval on memory for music. Expert and novice musicians and nonmusicians listened to pairs of musical excerpts under 2 conditions: a current phase, comprised of a number of standard/comparison-type trials, and a delayed phase, comprised of music excerpts played in later sessions compared with excerpts played in earlier sessions. Findings demonstrate that (1) music memory can be investigated in the context of intact music, (2) even nonmusicians possessed delayed memory ability for novel music well above the level of chance, (3) the outer limits of short-term memory for music did not conform well to data in the psychological literature with nonmusic stimuli, and (4) retention curves for different levels of music expertise were similar over time until one expertise level reached asymptote. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  keywords = {Experience Level,Memory,Music,Retention},
  file = {/Users/sebsilas/Zotero/storage/6ZRBHDYA/1990-03541-001.html},
}
@Article{harrisonApplyingModernPsychometric2017,
  title = {Applying Modern Psychometric Techniques to Melodic Discrimination Testing: {{Item}} Response Theory, Computerised Adaptive Testing, and Automatic Item Generation},
  shorttitle = {Applying Modern Psychometric Techniques to Melodic Discrimination Testing},
  author = {Peter M. C. Harrison and Tom Collins and Daniel M{\"u}llensiefen},
  date = {2017-06-15},
  journaltitle = {Scientific Reports},
  volume = {7},
  number = {1},
  pages = {3618},
  issn = {2045-2322},
  doi = {10.1038/s41598-017-03586-z},
  url = {https://www.nature.com/articles/s41598-017-03586-z},
  urldate = {2019-04-07},
  abstract = {Modern psychometric theory provides many useful tools for ability testing, such as item response theory, computerised adaptive testing, and automatic item generation. However, these techniques have yet to be integrated into mainstream psychological practice. This is unfortunate, because modern psychometric techniques can bring many benefits, including sophisticated reliability measures, improved construct validity, avoidance of exposure effects, and improved efficiency. In the present research we therefore use these techniques to develop a new test of a well-studied psychological capacity: melodic discrimination, the ability to detect differences between melodies. We calibrate and validate this test in a series of studies. Studies 1 and 2 respectively calibrate and validate an initial test version, while Studies 3 and 4 calibrate and validate an updated test version incorporating additional easy items. The results support the new test’s viability, with evidence for strong reliability and construct validity. We discuss how these modern psychometric techniques may also be profitably applied to other areas of music psychology and psychological science in general.},
  issue = {1},
  langid = {english},
}
@Book{pfleidererJazzomatNewPerspectives2017,
  title = {Inside the {{Jazzomat}} - New Perspectives for Jazz Research},
  editor = {Martin Pfleiderer and Klaus Frieler and Jakob Abe{\ss}er and Wolf-Georg Zaddach and Benjamin Burkhart},
  date = {2017},
  publisher = {{Schott Campus}},
}
@Article{bakerMeloSolCorpus2021,
  title = {{{MeloSol Corpus}}},
  author = {David Baker},
  date = {2021-12-10},
  journaltitle = {Empirical Musicology Review},
  shortjournal = {Empirical Musicology Review},
  volume = {16},
  pages = {106--113},
  doi = {10.18061/emr.v16i1.7645},
  abstract = {This data report introduces the MeloSol corpus, a collection of 783 Western, tonal monophonic melodies. I first begin by describing the overall structure of the corpus, then proceed to detail its contents as they would be helpful for researchers working in the field of computational musicology or music psychology. In order to contextualize the MeloSol corpus in relation to other corpora in the literature, I present descriptive statistics of the MeloSol corpus alongside the The Densmore Collection of Native American Song and The Essen Folk Song Collection. I suggest possible future uses of this corpus including extending research investigating Western tonality, perceptual experiments needing novel ecological stimuli, or work involving the musical generation of monophonic melodies in the style of Western tonal music.},
  file = {/Users/sebsilas/Zotero/storage/F3BH6E4H/Baker - 2021 - MeloSol Corpus.pdf},
}
@Book{slobodaMusicalMindCognitive1985,
  title = {The {{Musical Mind}}: {{The Cognitive Psychology}} of {{Music}}},
  shorttitle = {The {{Musical Mind}}},
  author = {John A. Sloboda and Professor of Psychology John A. Sloboda},
  date = {1985},
  eprint = {oZCfAAAAMAAJ},
  eprinttype = {googlebooks},
  publisher = {{Clarendon Press}},
  abstract = {In this comprehensive survey of the experimental literature on the cognitive psychology of music, Professor Sloboda, a psychologist and practicing musician, and {"}understanding{"} music and shows how such skills are acquired. {"}A break-through...brings together recent work in a way that demonstrates its significance for musicians, whilst in no way compromising the psychological theory on which it is based. The clarity of Sloboda's writing and his numerous suggestions for further research will make his book essential reading for anyone, student or researcher, interested in how minds and music interact.{"}--Nature},
  isbn = {978-0-19-852114-3},
  langid = {english},
  pagetotal = {312},
  keywords = {Music / General},
}
@Article{ouraMemoryMelodiesSubjects1988,
  title = {Memory for Melodies among Subjects Differing in Age and Experience in Music},
  author = {Yoko Oura and Giyoo Hatano},
  date = {1988},
  journaltitle = {Psychology of Music},
  volume = {16},
  number = {2},
  pages = {91--109},
  publisher = {{Sage Publications}},
  location = {{US}},
  issn = {1741-3087},
  doi = {10.1177/0305735688162001},
  abstract = {A total of 5 musically experienced and 9 inexperienced college students and 6 9–10 yr old children with about 5 yrs of piano training participated in 3 experiments to investigate storage and retrieval of a melody. In Exp 1, Ss learned an unfamiliar commercial song, which was presented auditorially and which they were required to reproduce by singing. Speed of acquisition and mastery of the melody were superior in the 2 experienced groups compared with the inexperienced group. Exp 2 indicated that experienced Ss' better performances in melodic memory were due to music domain-specific knowledge rather than general memory ability. Results of Exp 3 suggest that knowledge supporting memory of melodies was specific to tonal music. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Age Differences,Human Information Storage,Memory,Music},
  file = {/Users/sebsilas/Zotero/storage/Z593ELYB/1989-21312-001.html},
}
@Article{ogawaModificationMusicalSchema1995,
  title = {Modification of {{Musical Schema}} for {{Japanese Melody}}: {{A Study}} of {{Comprehensible}} and {{Memorable Melody}}},
  shorttitle = {Modification of {{Musical Schema}} for {{Japanese Melody}}},
  author = {Yoko Ogawa and Tsugihiro Kimura and Hiromichi Mito},
  date = {1995},
  journaltitle = {Bulletin of the Council for Research in Music Education},
  number = {127},
  eprint = {40318777},
  eprinttype = {jstor},
  pages = {136--141},
  publisher = {{University of Illinois Press}},
  issn = {0010-9894},
  abstract = {The purpose of this study is to investigate differences in comprehensibility and memorability of melodies. This study examines the reference point employed by young people in Japan as they listen to Japanese traditional music using their musical schema. Two experiments were designed from the point of the difference of (a) musical experience, (b) musical stimuli, and (c) methodology in memory for melody research. In Experiment 1,44 high school students were required to make comprehensibility assessment task and recognition task In Experiment 2, 80 undergraduates were asked to listen to the same melodies as those prepared for Experiment 1, providing an attempt at sung recall The results show that the comprehensibility score was high for both mixed-schema melody that was constructed in mixed Japanese-Western tone and in-schema melody that was composed of typical Japanese tone. However, recognition probability scores of the music learner for in-schema melody were significantly lower than those for mixed-schema melody, in spite of the fact that the tones are confined within the in-schema form. On the other hand, in the recall task, musicians were usually able to perform with less errors and less trials for in-schema melody. These findings suggest that subjects vary in their reference point for comprehensibility and memorability depending on the melody pattern. They place their reference point for recognition only on the surface, however peculiar the pattern, whereas the reference point for recall task is placed on the deeper structural information underlying the input melodies.},
}

@Article{zielinskaMemorisingTwoMelodies1992,
  title = {Memorising Two Melodies of Different Style},
  author = {Halina Zielinska and Kacper Miklaszewski},
  date = {1992},
  journaltitle = {Psychology of Music},
  volume = {20},
  number = {2},
  pages = {95--111},
  publisher = {{Sage Publications}},
  location = {{US}},
  issn = {1741-3087},
  doi = {10.1177/0305735692202001},
  abstract = {31 undergraduates at a music academy, 5 classified as having absolute pitch (AP) and 26 classified as not having AP, memorized 1 melody with a clear tonal structure and 1 melody based on a modal scale. The modal melody was more difficult for both groups, and the rhythm of the melodies caused more trouble in reproductions than pitch. The musical material and Ss' individual characteristics that were not controlled, not the possession of AP per se, influenced strategies of learning. Possession of AP did not modify the proportions of contour, interval and rhythm errors during melodic memorization of both melodies, though Ss with AP memorized both melodies faster than Ss without AP. Ss with AP also scored significantly better in retaining the key and storing pitch information when they recalled the melodies from long term memory. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Learning Strategies,Memory,Musical Ability,Pitch Discrimination},
  file = {/Users/sebsilas/Zotero/storage/CBWBT9CU/1993-16366-001.html},
}
@InCollection{slobodaImmediateRecallMelodies1985,
  title = {Immediate Recall of Melodies},
  booktitle = {Musical Structure and Cognition},
  author = {J.A Sloboda and D. H. H. Parker},
  editor = {R. West and P Howell and I Cross},
  date = {1985},
  pages = {143--167},
  publisher = {{London: Academic Press.}},
}
@Book{krumhanslCognitiveFoundationsMusical1990,
  title = {Cognitive {{Foundations}} of {{Musical Pitch}}},
  author = {Carol Krumhansl},
  date = {1990-03-15},
  eprint = {aJDEVqyArr4C},
  eprinttype = {googlebooks},
  publisher = {{Oxford University Press, USA}},
  abstract = {This book addresses the central problem of music cognition: how listeners' responses move beyond mere registration of auditory events to include the organization, interpretation, and remembrance of these events in terms of their function in a musical context of pitch and rhythm. Equally important, the work offers an analysis of the relationship between the psychological organization of music and its internal structure. Combining over a decade of original research on music cognition with an overview of the available literature, the work will be of interest to cognitive and physiological psychologists, psychobiologists, musicians, music researchers, and music educators. The author provides the necessary background in experimental methodology and music theory so that no specialized knowledge is required for following her major arguments.},
  isbn = {978-0-19-802215-2},
  langid = {english},
  pagetotal = {322},
  keywords = {Music / Instruction & Study / General},
}
@Article{doi:10.1080/09298215.2017.1305419,
  title = {Compression-Based Modelling of Musical Similarity Perception},
  author = {Marcus Pearce and Daniel M{\"u}llensiefen},
  date = {2017},
  journaltitle = {Journal of New Music Research},
  volume = {46},
  number = {2},
  eprint = {https://doi.org/10.1080/09298215.2017.1305419},
  pages = {135--155},
  publisher = {{Routledge}},
  doi = {10.1080/09298215.2017.1305419},
  url = {https://doi.org/10.1080/09298215.2017.1305419},
}

@Article{mullensiefenCourtDecisionsMusic2009,
  title = {Court Decisions on Music Plagiarism and the Predictive Value of Similarity Algorithms},
  author = {Daniel M{\"u}llensiefen and Marc Pendzich},
  date = {2009-03-01},
  journaltitle = {Musicae Scientiae},
  shortjournal = {Musicae Scientiae},
  volume = {13},
  pages = {257--295},
  publisher = {{SAGE Publications Ltd}},
  issn = {1029-8649},
  doi = {10.1177/102986490901300111},
  url = {https://doi.org/10.1177/102986490901300111},
  urldate = {2022-07-22},
  abstract = {Tune plagiarism in pop music is a common and often feverishly debated phenomenon which surely has to do with the vast amounts of money that individual melodies are able to generate in today's pop music business. The similarity between melodies is assumed to be a very important factor in a court's decision about whether a new tune is an illegitimate version of a pre-existing melody. Despite the wide-spread belief that there is a fixed and simple limit to the number of corresponding notes between two melodies, actual court decisions are based on far more complex considerations regarding the musical material., This paper first sketches the legal framework and principal features of the legal processing of cases of alleged melodic plagiarism with a focus on US copyright law and discusses selected cases to highlight the corresponding legal practices. In the empirical part of this paper, we model court decisions for cases of alleged melodic plagiarism employing a number of similarity algorithms. As a ground truth dataset we use a collection of 20 publicly available cases from the last 30 years of US jurisdiction. We compare the performance of standard similarity algorithms (edit distance and n-gram similarity measures) to several new similarity algorithms that make use of statistical information about the prevalence of chains of pitch intervals in a large pop music database. Results indicate that these statistically informed algorithms generally outperform the comparison algorithms. In particular, algorithms based on Tversky's (1977) concept of similarity show a high performance of up to 90\% of court decisions correctly predicted. We discuss the performance and structure of the algorithms in relation to a few interesting example cases and give an outlook on the potential and intricacies of our approach.},
  issue = {1\_suppl},
  langid = {english},
  keywords = {melodic similarity,music copyright,plagiarism,similarity algorithms,Tversky's similarity model},
  file = {/Users/sebsilas/Zotero/storage/LJNLD7E3/Müllensiefen and Pendzich - 2009 - Court decisions on music plagiarism and the predic.pdf},
}

@InProceedings{mullensiefenMelodicSimilarityApproaches2004,
  title = {Melodic Similarity: Approaches and Applications},
  booktitle = {Proceedings of the 8th {{ICMPC}}},
  author = {Daniel M{\"u}llensiefen and Klaus Frieler},
  editor = {S.D. Lipscombe and R. Ashley and R.O. Gjerdingen and P. Webster},
  date = {2004},
  pages = {283--289},
  location = {{IL}},
  abstract = {This paper describes the systematization, testing and optimiziation of different approaches for measuring similarities of melodies. First, a quick overview of our mathematical systematization for similarity measures, including data transformations and calculation methods is given. Behavioral data from three listener experiments is used to model experts’ similarity judgments of short melodies from popular music in different contextual situations. A weighted combination of several similarity measures, representing two resp. three different sources of information, is found to explain user ratings best. As an application example one of the optimal similarity measures resulting from these three experiments is used to analyze a body of about 600 folk melodies from Luxembourg. Finally, the expert classification of the individual phrases of these melodies that has carried out in an extensive ethno-musicological study (Sagrillo, 1999) is reconstructed with the help of an optimal combination of similarity measures using logistic regression.},
  langid = {english},
  file = {/Users/sebsilas/Zotero/storage/CQZ78TYM/Müllensiefen and Frieler - MELODIC SIMILARITY APPROACHES AND APPLICATIONS.pdf},
}

@Article{mullensiefenModellingExpertsNotions2007,
  title = {Modelling Experts’ Notions of Melodic Similarity},
  author = {Daniel M{\"u}llensiefen and Klaus Frieler},
  date = {2007-03-01},
  journaltitle = {Musicae Scientiae},
  shortjournal = {Musicae Scientiae},
  volume = {11},
  pages = {183--210},
  publisher = {{SAGE Publications Ltd}},
  issn = {1029-8649},
  doi = {10.1177/102986490701100108},
  url = {https://doi.org/10.1177/102986490701100108},
  urldate = {2022-01-11},
  abstract = {In this article we show that a subgroup of music experts has a reliable and consistent notion of melodic similarity, and that this notion can be measured with satisfactory precision. Our measurements enable us to model the similarity ratings of music experts by automated and algorithmic means. A large number of algorithmic similarity measure found in the literature were mathematically systematised and implemented. The best similarity algorithms compared to human experts were chosen and optimised by statistical means according to different contexts. A multidimensional scaling model of the algorithmic similarity measures is constructed to give an overiew over the different musical dimensions reflected by these measures. We show some examples where this optimised methods could be successfully applied to real world problems like folk song categorisation and analysis, and discuss further applications and implications.},
  issue = {1\_suppl},
  langid = {english},
}
@Article{nakagawaGeneralSimpleMethod2013,
  title = {A General and Simple Method for Obtaining {{R2}} from Generalized Linear Mixed-Effects Models},
  author = {Shinichi Nakagawa and Holger Schielzeth},
  date = {2013},
  journaltitle = {Methods in Ecology and Evolution},
  volume = {4},
  number = {2},
  pages = {133--142},
  issn = {2041-210X},
  doi = {10.1111/j.2041-210x.2012.00261.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2041-210x.2012.00261.x},
  urldate = {2022-07-18},
  abstract = {The use of both linear and generalized linear mixed-effects models (LMMs and GLMMs) has become popular not only in social and medical sciences, but also in biological sciences, especially in the field of ecology and evolution. Information criteria, such as Akaike Information Criterion (AIC), are usually presented as model comparison tools for mixed-effects models. The presentation of ‘variance explained’ (R2) as a relevant summarizing statistic of mixed-effects models, however, is rare, even though R2 is routinely reported for linear models (LMs) and also generalized linear models (GLMs). R2 has the extremely useful property of providing an absolute value for the goodness-of-fit of a model, which cannot be given by the information criteria. As a summary statistic that describes the amount of variance explained, R2 can also be a quantity of biological interest. One reason for the under-appreciation of R2 for mixed-effects models lies in the fact that R2 can be defined in a number of ways. Furthermore, most definitions of R2 for mixed-effects have theoretical problems (e.g. decreased or negative R2 values in larger models) and/or their use is hindered by practical difficulties (e.g. implementation). Here, we make a case for the importance of reporting R2 for mixed-effects models. We first provide the common definitions of R2 for LMs and GLMs and discuss the key problems associated with calculating R2 for mixed-effects models. We then recommend a general and simple method for calculating two types of R2 (marginal and conditional R2) for both LMMs and GLMMs, which are less susceptible to common problems. This method is illustrated by examples and can be widely employed by researchers in any fields of research, regardless of software packages used for fitting mixed-effects models. The proposed method has the potential to facilitate the presentation of R2 for a wide range of circumstances.},
  langid = {english},
  keywords = {coefficient of determination,goodness-of-fit,heritability,information criteria,intra-class correlation,linear models,model fit,repeatability,variance explained},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.2041-210x.2012.00261.x},
  file = {/Users/sebsilas/Zotero/storage/VS84YCLK/Nakagawa and Schielzeth - 2013 - A general and simple method for obtaining R2 from .pdf},
}
@InCollection{andersonFranSimulationModel1972,
  title = {Fran: {{A Simulation Model}} of {{Free Recall}}},
  shorttitle = {Fran},
  booktitle = {Psychology of {{Learning}} and {{Motivation}}},
  author = {John Robert Anderson},
  editor = {Gordon H. Bower},
  date = {1972-01-01},
  volume = {5},
  pages = {315--378},
  publisher = {{Academic Press}},
  doi = {10.1016/S0079-7421(08)60444-2},
  url = {https://www.sciencedirect.com/science/article/pii/S0079742108604442},
  urldate = {2022-05-28},
  abstract = {This chapter discusses fran—a simulation model of free recall. The basic free recall experiment with which one will be concerned involves the presentation to a subject (S) of a list of words, one word at a time. After seeing all the words in the list, the S is asked to recall them in any order one chooses. The experimental paradigm derives its name from the fact that the S is not constrained to recall items in a particular order. The free recall paradigm has recently attracted much research interest because of evidence indicating the strong influence of various types of conceptual organization upon the S's recall. This chapter outlines how several different strategies could be implemented in terms of FRAN's mental mechanisms. The fact that these various strategies can be formulated in terms of FRAN's machinery supports the assertion that FRAN models the structures and processes underlying human memory in general.},
  langid = {english},
  file = {/Users/sebsilas/Zotero/storage/LHARVH5U/S0079742108604442.html},
}
@Article{christiansenNoworNeverBottleneckFundamental2016,
  title = {The {{Now-or-Never}} Bottleneck: {{A}} Fundamental Constraint on Language},
  shorttitle = {The {{Now-or-Never}} Bottleneck},
  author = {Morten H. Christiansen and Nick Chater},
  year = {2016/ed},
  journaltitle = {Behavioral and Brain Sciences},
  volume = {39},
  publisher = {{Cambridge University Press}},
  issn = {0140-525X, 1469-1825},
  doi = {10.1017/S0140525X1500031X},
  url = {https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/nowornever-bottleneck-a-fundamental-constraint-on-language/938D54E80A2A90A1C5990F4915B5E8D8#},
  urldate = {2020-12-21},
  abstract = {Memory is fleeting. New material rapidly obliterates previous material. How, then, can the brain deal successfully with the continual deluge of linguistic input? We argue that, to deal with this “Now-or-Never” bottleneck, the brain must compress and recode linguistic input as rapidly as possible. This observation has strong implications for the nature of language processing: (1) the language system must “eagerly” recode and compress linguistic input; (2) as the bottleneck recurs at each new representational level, the language system must build a multilevel linguistic representation; and (3) the language system must deploy all available information predictively to ensure that local linguistic ambiguities are dealt with “Right-First-Time”; once the original input is lost, there is no way for the language system to recover. This is “Chunk-and-Pass” processing. Similarly, language learning must also occur in the here and now, which implies that language acquisition is learning to process, rather than inducing, a grammar. Moreover, this perspective provides a cognitive foundation for grammaticalization and other aspects of language change. Chunk-and-Pass processing also helps explain a variety of core properties of language, including its multilevel representational structure and duality of patterning. This approach promises to create a direct relationship between psycholinguistics and linguistic theory. More generally, we outline a framework within which to integrate often disconnected inquiries into language processing, language acquisition, and language change and evolution.},
  langid = {english},
  keywords = {chunking,grammaticalization,incremental interpretation,language acquisition,language evolution,language processing,online learning,prediction,processing bottleneck,psycholinguistics},
  file = {/Users/sebsilas/Zotero/storage/NJZBQPAC/938D54E80A2A90A1C5990F4915B5E8D8.html},
}

@Article{cowanMagicalMysteryFour2010,
  title = {The Magical Mystery Four: How Is Working Memory Capacity Limited, and Why?},
  shorttitle = {The Magical Mystery Four},
  author = {Nelson Cowan},
  date = {2010-02-01},
  journaltitle = {Current directions in psychological science},
  shortjournal = {Curr Dir Psychol Sci},
  volume = {19},
  number = {1},
  eprint = {20445769},
  eprinttype = {pmid},
  pages = {51--57},
  issn = {0963-7214},
  doi = {10.1177/0963721409359277},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2864034/},
  urldate = {2019-11-05},
  abstract = {Working memory storage capacity is important because cognitive tasks can be completed only with sufficient ability to hold information as it is processed. The ability to repeat information depends on task demands but can be distinguished from a more constant, underlying mechanism: a central memory store limited to 3 to 5 meaningful items in young adults. I will discuss why this central limit is important, how it can be observed, how it differs among individuals, and why it may occur.},
  issue = {1},
  pmcid = {PMC2864034},
}

@Article{millerMagicalNumberSeven1956,
  title = {The Magical Number Seven, plus or Minus Two: {{Some}} Limits on Our Capacity for Processing Information},
  shorttitle = {The Magical Number Seven, plus or Minus Two},
  author = {George A. Miller},
  date = {1956},
  journaltitle = {Psychological Review},
  volume = {63},
  number = {2},
  pages = {81--97},
  publisher = {{American Psychological Association}},
  location = {{US}},
  issn = {1939-1471},
  doi = {10.1037/h0043158},
  abstract = {A variety of researches are examined from the standpoint of information theory. It is shown that the unaided observer is severely limited in terms of the amount of information he can receive, process, and remember. However, it is shown that by the use of various techniques, e.g., use of several stimulus dimensions, recoding, and various mnemonic devices, this informational bottleneck can be broken. 20 references. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  keywords = {Cognitive Processes,Information Theory},
  file = {/Users/sebsilas/Zotero/storage/P5YA239F/Miller - 1956 - The magical number seven, plus or minus two Some .pdf;/Users/sebsilas/Zotero/storage/DR5WK2C9/1957-02914-001.html},
}

@Article{oberauerWorkingMemoryCapacity2007,
  title = {Working Memory Capacity: (2005)},
  author = {Klaus Oberauer and Nelson Cowan},
  date = {2007-01},
  journaltitle = {Experimental Psychology - EXP PSYCHOL},
  volume = {54},
  pages = {245--246},
  doi = {10.1027/1618-3169.54.3.245},
}
@Article{silasAssociationsMusicTraining2022,
  title = {The Associations between Music Training, Musical Working Memory, and Visuospatial Working Memory: An Opportunity for Causal Modeling},
  shorttitle = {The Associations between Music Training, Musical Working Memory, and Visuospatial Working Memory},
  author = {Sebastian Silas and Daniel M{\"u}llensiefen and Rebecca Gelding and Klaus Frieler and Peter M. C. Harrison},
  date = {2022-04-01},
  journaltitle = {Music Perception},
  shortjournal = {Music Perception},
  volume = {39},
  number = {4},
  pages = {401--420},
  issn = {0730-7829},
  doi = {10.1525/mp.2022.39.4.401},
  url = {https://doi.org/10.1525/mp.2022.39.4.401},
  urldate = {2022-04-21},
  abstract = {Prior research studying the relationship between music training (MT) and more general cognitive faculties, such as visuospatial working memory (VSWM), often fails to include tests of musical memory. This may result in causal pathways between MT and other such variables being misrepresented, potentially explaining certain ambiguous findings in the literature concerning the relationship between MT and executive functions. Here we address this problem using latent variable modeling and causal modeling to study a triplet of variables related to working memory: MT, musical working memory (MWM), and VSWM. The triplet framing allows for the potential application of d-separation (similar to mediation analysis) and V-structure search, which is particularly useful since, in the absence of expensive randomized control trials, it can test causal hypotheses using cross-sectional data. We collected data from 148 participants using a battery of MWM and VSWM tasks as well as a MT questionnaire. Our results suggest: 1) VSWM and MT are unrelated, conditional on MWM; and 2) by implication, there is no far transfer between MT and VSWM without near transfer. However, the data are unable to distinguish an unambiguous causal structure. We conclude by discussing the possibility of extending these models to incorporate more complex or cyclic effects.},
  file = {/Users/sebsilas/Zotero/storage/EBWGRILD/Silas et al. - 2022 - The Associations Between Music Training, Musical W.pdf;/Users/sebsilas/Zotero/storage/2USNE25L/The-Associations-Between-Music-Training-Musical.html},
}
@Book{lehmannPsychologyMusiciansUnderstanding2007,
  title = {Psychology for Musicians: Understanding and Acquiring the Skills},
  shorttitle = {Psychology for Musicians},
  author = {Andreas C. Lehmann and John A. Sloboda and Robert Henley Woody and Robert H. Woody},
  date = {2007-02-08},
  eprint = {wI4RDAAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{Oxford University Press, USA}},
  abstract = {This book provides a concise, accessible, and up-to-date introduction to psychological research for musicians - performers, music educators, and studio teachers. Designed to address the needs and priorities of the performing musician rather than the research community, it reviews the relevant psychological research findings in relation to situations and issues faced by musicians, and draws out practical implications for the practice of teaching and performance. Rather than a list of DOs and DON'Ts, this book equips musicians with an understanding of the basic psychological principles that underlie music performcance, enabling each reader to apply the content flexibly to the task at hand. Following a brief review of the scientific method as a way of thinking about the issues and problems in music, this text addresses the nature-nurture problem, identification and assessment of musical aptitude, musical development, adult skill maintenance, technical and expressive skills, practice, interpretation and expressivity, sight-reading, memorization, creativity, and composition, performance anxiety, critical listening, and teaching and learning. While there is a large body of empirical research regarding music, most musicians lack the scientific training to interpret these studies. This text bridges this gap by relating these skills to the musician's experiences, addressing their needs directly with non-technical language and practical application. The book includes multiple illustrations, brief music examples, cases, questions, and suggestions for further reading.},
  isbn = {978-0-19-514610-3},
  langid = {english},
  pagetotal = {279},
  keywords = {Music / Instruction & Study / Theory,Psychology / Cognitive Psychology & Cognition},
}
@Book{hoyleHandbookStructuralEquation2012,
  title = {Handbook of {{Structural Equation Modelling}}},
  author = {Rick H. Hoyle},
  date = {2012-05-21},
  journaltitle = {Handbook of Structural Equation Modeling},
  eprint = {qC4aMfXL1JkC},
  eprinttype = {googlebooks},
  publisher = {{Guilford Press}},
  abstract = {The first comprehensive structural equation modeling (SEM) handbook, this accessible volume offers broad and deep coverage of both the mechanics of SEM and specific SEM strategies and applications. The editor, contributors, and editorial advisory board are leading methodologists who have organized the book to move from simpler material to more statistically complex modeling approaches. Sections cover the foundations of SEM; statistical underpinnings, from assumptions to model modifications; steps in implementation, from data preparation through writing the SEM report; and basic and advanced applications, including new and emerging topics in SEM, such as intensive longitudinal assessments, dyadic data, brain imaging, and genotyping. Each chapter provides conceptually oriented descriptions, fully explicated analyses, and engaging examples that reveal modeling possibilities for use with readers' data. Many of the chapters also include access to data and syntax files at the companion website, allowing readers to try their hands at reproducing the authors' results.},
  isbn = {978-1-4625-0447-3},
  langid = {english},
  keywords = {Business & Economics / Statistics,Education / Statistics,Medical / Nursing / Research & Theory,Psychology / Statistics,Social Science / Statistics},
  annotation = {Book Authors: \_:n462},
}
@Book{longLongitudinalDataAnalysis2011,
  title = {Longitudinal {{Data Analysis}} for the {{Behavioral Sciences Using R}}},
  author = {Jeffrey D. Long},
  date = {2011-10-31},
  eprint = {RyFzAwAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{SAGE Publications}},
  abstract = {This book is unique in its focus on showing students in the behavioral sciences how to analyze longitudinal data using R software. The book focuses on application, making it practical and accessible to students in psychology, education, and related fields, who have a basic foundation in statistics. It provides explicit instructions in R computer programming throughout the book, showing students exactly how a specific analysis is carried out and how output is interpreted.},
  isbn = {978-1-4833-4155-2},
  langid = {english},
  pagetotal = {569},
  keywords = {Reference / Research,Social Science / Research},
}
@Article{silasSingingAbilityAssessment2022,
  title = {Singing {{Ability Assessment}}: Development and Validation of an Open-Source Testing Environment for Singing Data},
  author = {S Silas and D M{\"u}llensiefen and Reinhard Kopiez},
  date = {2022},
  journaltitle = {In prep.},
}
@Article{murdockjr.ImmediateRetentionUnrelated1960,
  title = {The Immediate Retention of Unrelated Words},
  author = {Bennet B. {Murdock Jr.}},
  date = {1960},
  journaltitle = {Journal of Experimental Psychology},
  volume = {60},
  number = {4},
  pages = {222--234},
  publisher = {{American Psychological Association}},
  location = {{US}},
  issn = {0022-1015},
  doi = {10.1037/h0045145},
  abstract = {{"}For the experiments on free-recall verbal learning a standard procedure and a standard method of fitting the exponential were used; normative data and data on reliability were presented. It was shown that there was no learning-how-to-learn or warm-up effect. Also, there was no difference between visual and auditory presentation or between individual and group testing. Learning was found to be a linear function of log frequency of usage… . it was possible to predict the learning of a list with a fair degree of accuracy given its length and presentation time.{"} (19 ref.) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Recall (Learning),Retention,Verbal Learning,Words (Phonetic Units)},
  file = {/Users/sebsilas/Zotero/storage/GK49PH7S/1961-04456-001.html},
}
@InCollection{baddeleyWorkingMemory1974,
  title = {Working {{Memory}}},
  booktitle = {Psychology of {{Learning}} and {{Motivation}}},
  author = {Alan D. Baddeley and Graham Hitch},
  editor = {Gordon H. Bower},
  date = {1974-01-01},
  volume = {8},
  pages = {47--89},
  publisher = {{Academic Press}},
  doi = {10.1016/S0079-7421(08)60452-1},
  url = {https://www.sciencedirect.com/science/article/pii/S0079742108604521},
  urldate = {2021-11-15},
  abstract = {This chapter presents a body of new experimental evidence, which provides a firm basis for the working memory hypothesis. The chapter presents a series of experiments on the role of memory in reasoning, language comprehension, and learning. An attempt is made to apply the comparable techniques in all three cases to allow a common pattern to emerge, if the same working memory system is operative in all three instances. The chapter makes a case for postulating the working memory-LTS system as a modification of the current STS-LTS view. Working memory represents a control system with limits on both its storage and processing capabilities, and has access to phonemically coded information (possibly by controlling a rehearsal buffer), that it is responsible for the limited memory span, but does not underlie the recency effect in free recall. The experiments presented in the chapter suggest that the phonemic rehearsal buffer plays a limited role in this process, but is by no means essential. These experiments also suggest that working memory plays a part in verbal reasoning and in prose comprehension. Understanding the detailed role of working memory in these tasks, however, must proceed hand-in-hand with an understanding of the tasks themselves.},
  langid = {english},
  file = {/Users/sebsilas/Zotero/storage/G3XAYPRI/S0079742108604521.html},
}
@Article{harrisonModellingMelodicDiscrimination2016,
  title = {Modelling Melodic Discrimination Tests: Descriptive and Explanatory Approaches},
  shorttitle = {Modelling Melodic Discrimination Tests},
  author = {Peter M. C. Harrison and Jason Ji{\v r}{\a'\i} Musil and Daniel M{\"u}llensiefen},
  date = {2016-07-02},
  journaltitle = {Journal of New Music Research},
  volume = {45},
  number = {3},
  pages = {265--280},
  issn = {0929-8215},
  doi = {10.1080/09298215.2016.1197953},
  url = {https://doi.org/10.1080/09298215.2016.1197953},
  urldate = {2019-04-07},
  abstract = {Melodic discrimination tests have been used for many years to assess individual differences in musical abilities. These tests are usually analysed using classical test theory. However, classical test theory is not well suited for optimizing test efficiency or for investigating construct validity. This paper addresses this problem by applying modern item response modelling techniques to three melodic discrimination tests. First, descriptive item response modelling is used to develop a short melodic discrimination test from a larger item pool. The resulting test meets the test-theoretic assumptions of a Rasch (1960) item response model and possesses good concurrent and convergent validity as well as good testing efficiency. Second, an explicit cognitive model of melodic discrimination is used to generate hypotheses relating item difficulty to structural item features such as melodic complexity, similarity, and tonalness. These hypotheses are then tested on response data from three melodic discrimination tests using explanatory item response modelling. Results indicate that item difficulty is predicted by melodic complexity and melodic similarity, consistent with the proposed cognitive model. This provides useful evidence for construct validity. This paper therefore demonstrates the benefits of item response modelling both for efficient test construction and for test validity.},
  issue = {3},
  keywords = {item response modelling,melodic discrimination,memory,musical abilities,similarity},
}
@InCollection{mullensiefenSlobodaParkerRecall2011,
  title = {Sloboda and {{Parker}}'s Recall Paradigm for Melodic Memory: {{A}} New, Computational Perspective},
  shorttitle = {Sloboda and {{Parker}}'s Recall Paradigm for Melodic Memory},
  booktitle = {Music and the Mind: {{Essays}} in Honour of {{John Sloboda}}},
  author = {Daniel M{\"u}llensiefen and Geraint A. Wiggins},
  date = {2011},
  pages = {161--186},
  publisher = {{Oxford University Press}},
  location = {{New York, NY, US}},
  abstract = {Sloboda and Parker (1985) proposed a new experimental paradigm for research on melodic memory in which participants are asked to listen to novel melodies and to sing back the parts they can recall from memory. In contrast to the many varieties of melodic recognition paradigms frequently used in memory research this sung recall paradigm can answer questions about how mental representations of a melody build up in memory over time, about the nature of memory errors, and about the interplay between different musical dimensions in memory. Although the paradigm has clear advantages with regard to ecological validity, Sloboda and Parker also note a number of difficulties inherent to the paradigm that mostly result from necessity to analyse 'dirty musical data' as sung by mostly untrained participants. This contribution reviews previous research done using the sung recall paradigm and proposes a computational approach for the analysis of dirty melodic data. This approach is applied to data from a new study using Sloboda and Parker's paradigm. This chapter discusses how this new approach not only enables researchers to handle large amounts of data but also make use of concepts from computational music analysis and music information retrieval that introduce a new level of analytic precision and conceptual clarity and thus provide a new interface which connects Sloboda's paradigm to rigorous quantitative data analysis. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  isbn = {978-0-19-958156-6},
  keywords = {Automated Information Retrieval,Computational Modeling,Memory,Music,Recall (Learning)},
  file = {/Users/sebsilas/Zotero/storage/6QHFQW7N/2011-07517-009.html},
}
@Article{pearceMullensiiefen2017,
  title = {Compression-Based Modelling of Musical Similarity Perception},
  author = {Marcus Pearce and Daniel M{\"u}llensiefen},
  date = {2017},
  journaltitle = {Journal of New Music Research},
  volume = {46},
  number = {2},
  eprint = {https://doi.org/10.1080/09298215.2017.1305419},
  pages = {135--155},
  publisher = {{Routledge}},
  doi = {10.1080/09298215.2017.1305419},
  url = {https://doi.org/10.1080/09298215.2017.1305419},
}

@Article{typkeTransportationDistancesHuman2007,
  title = {Transportation Distances and Human Perception of Melodic Similarity},
  author = {Rainer Typke and Frans Wiering and Remco C. Veltkamp},
  date = {2007-03-01},
  journaltitle = {Musicae Scientiae},
  shortjournal = {Musicae Scientiae},
  volume = {11},
  pages = {153--181},
  publisher = {{SAGE Publications Ltd}},
  issn = {1029-8649},
  doi = {10.1177/102986490701100107},
  url = {https://doi.org/10.1177/102986490701100107},
  urldate = {2022-08-03},
  abstract = {This article describes how transportation distances such as the Earth Mover's Distance can be used for measuring melodic similarity for notated music. We represent music notation as weighted point sets in a two-dimensional space of onset time and pitch. The Earth Mover's Distance can then be used for comparing point sets by determining how much work it would take to convert one of the point sets into the other by moving weight between the point sets., For evaluating how well this method and other methods agree with human perception of melodic similarity, we established a ground truth for the RISM A/II collection based on the opinions of human experts., The RISM A/II collection contains about half a million musical incipits. For 22 queries, we filtered the collection so that about 50 candidates per query were left, each of which we then presented to about 30 human experts (out of a group of 37 experts) for a final ranking. We present our filtering methods, the experiment design, the resulting ground truth, and a new measure (called “Average Dynamic Recall”) that can be used for comparing different similarity measures with the ground truth.},
  issue = {1\_suppl},
  langid = {english},
  file = {/Users/sebsilas/Zotero/storage/K35589I5/Typke et al. - 2007 - Transportation distances and human perception of m.pdf},
}

@Misc{yuanPerceptualVsAutomated2020,
  title = {Perceptual vs. Automated Judgments of Music Copyright Infringement},
  author = {Yuchen Yuan and Sho Oishi and Charles Cronin and Daniel M{\"u}llensiefen and Quentin Atkinson and Shinya Fujii and Patrick E. Savage},
  date = {2020-07-10T14:49:15},
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/tq7v5},
  url = {https://psyarxiv.com/tq7v5/},
  urldate = {2022-08-03},
  abstract = {Music copyright lawsuits often result in multimillion dollar damage awards or settlements, yet there are few objective guidelines for applying copyright law in infringement claims involving musical works. Recent re-search has attempted to develop objective methods based on automated similarity algorithms, but there remains almost no data on the role of perceived similarity in mu-sic copyright decisions despite its crucial role in copy-right law. We collected perceptual data from 20 participants for 17 adjudicated copyright cases from the USA and Japan after editing the disputed sections to contain either full audio, melody only, or lyrics only. Due to the historical emphasis in legal opinions on melody as the key criterion for deciding infringement, we predicted that listening to melody-only versions would result in perceptual judgements that more closely matched actual past legal decisions. Surprisingly, however, we found no significant differences between the three conditions, with participants matching past decisions in between 50-60\% of cases in all three conditions. Automated algorithms designed to calculate melodic and audio similarity produced comparable results: both algorithms were able to match past decisions with identical accuracy of 71\% (12/17 cases). Analysis of cases that were difficult to classify suggests that melody, lyrics, and other factors sometimes interact in complex ways difficult to capture using quantitative metrics. We propose directions for further investigation of the role of similarity in music copy-right law using larger and more diverse samples of cases and enhanced methods, and adapting our perceptual experiment method to avoid relying for ground truth data only on court decisions (which may be subject to selection bias). Our results contribute to important practical debates, such as whether jury members should be allowed to listen to full audio recordings during copyright cases.},
  langid = {american},
  keywords = {Music,Social and Behavioral Sciences},
  file = {/Users/sebsilas/Zotero/storage/JI7ZIYK4/Yuan et al. - 2020 - Perceptual vs. automated judgments of music copyri.pdf},
}
@Article{rosseelLavaanPackageStructural2012a,
  title = {Lavaan: {{An R Package}} for {{Structural Equation Modeling}}},
  author = {Yves Rosseel},
  date = {2012},
  journaltitle = {Journal of Statistical Software},
  volume = {48},
  number = {2},
  pages = {1--36},
  url = {https://www.jstatsoft.org/v48/i02/},
}
@Article{gobetChunkingMechanismsHuman2001,
  title = {Chunking Mechanisms in Human Learning},
  author = {Fernand Gobet and Peter C. R. Lane and Steve Croker and Peter C-H. Cheng and Gary Jones and Iain Oliver and Julian M. Pine},
  date = {2001-06-01},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {5},
  number = {6},
  pages = {236--243},
  issn = {1364-6613},
  doi = {10.1016/S1364-6613(00)01662-4},
  url = {https://www.sciencedirect.com/science/article/pii/S1364661300016624},
  urldate = {2022-08-04},
  abstract = {Pioneering work in the 1940s and 1950s suggested that the concept of ‘chunking’ might be important in many processes of perception, learning and cognition in humans and animals. We summarize here the major sources of evidence for chunking mechanisms, and consider how such mechanisms have been implemented in computational models of the learning process. We distinguish two forms of chunking: the first deliberate, under strategic control, and goal-oriented; the second automatic, continuous, and linked to perceptual processes. Recent work with discrimination-network computational models of long- and short-term memory (EPAM/CHREST) has produced a diverse range of applications of perceptual chunking. We focus on recent successes in verbal learning, expert memory, language acquisition and learning multiple representations, to illustrate the implementation and use of chunking mechanisms within contemporary models of human learning.},
  langid = {english},
  keywords = {chunking,discrimination networks,expertise,language,learning,multiple representations},
  file = {/Users/sebsilas/Zotero/storage/RKN5PBEB/S1364661300016624.html},
}

@Article{gobetChunkingModelsExpertise2005,
  title = {Chunking Models of Expertise: Implications for Education},
  shorttitle = {Chunking Models of Expertise},
  author = {Fernand Gobet},
  date = {2005},
  journaltitle = {Applied Cognitive Psychology},
  volume = {19},
  number = {2},
  pages = {183--204},
  issn = {1099-0720},
  doi = {10.1002/acp.1110},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/acp.1110},
  urldate = {2022-08-04},
  abstract = {Chunking models offer a parsimonious explanation of how people acquire knowledge and have been validated in domains such as expert behaviour and the acquisition of language. In this paper, we review two computational theories based on chunking mechanisms (the chunking theory and the template theory) and show what insight they offer for instruction and training. The suggested implications include the importance of perception in learning, the cost of acquiring knowledge, the significance of segmenting and ordering instruction material, the role of the variability of the instructional material in acquiring schemata, and the importance of taking individual differences into account. Copyright © 2005 John Wiley \& Sons, Ltd.},
  langid = {english},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/acp.1110},
  file = {/Users/sebsilas/Zotero/storage/UFBFJYAC/Gobet - 2005 - Chunking models of expertise implications for edu.pdf;/Users/sebsilas/Zotero/storage/JN56HS85/acp.html},
}

@Article{thalmannHowDoesChunking2019,
  title = {How Does Chunking Help Working Memory?},
  author = {Mirko Thalmann and Alessandra S. Souza and Klaus Oberauer},
  date = {2019},
  journaltitle = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {45},
  number = {1},
  pages = {37--55},
  publisher = {{American Psychological Association}},
  location = {{US}},
  issn = {1939-1285},
  doi = {10.1037/xlm0000578},
  abstract = {Chunking is the recoding of smaller units of information into larger, familiar units. Chunking is often assumed to help bypassing the limited capacity of working memory (WM). We investigate how chunks are used in WM tasks, addressing three questions: (a) Does chunking reduce the load on WM? Across four experiments chunking benefits were found not only for recall of the chunked but also of other not-chunked information concurrently held in WM, supporting the assumption that chunking reduces load. (b) Is the chunking benefit independent of chunk size? The chunking benefit was independent of chunk size only if the chunks were composed of unique elements, so that each chunk could be replaced by its first element (Experiment 1), but not when several chunks consisted of overlapping sets of elements, disabling this replacement strategy (Experiments 2 and 3). The chunk-size effect is not due to differences in rehearsal duration as it persisted when participants were required to perform articulatory suppression (Experiment 3). Hence, WM capacity is not limited to a fixed number of chunks regardless of their size. (c) Does the chunking benefit depend on the serial position of the chunk? Chunks in early list positions improved recall of other, not-chunked material, but chunks at the end of the list did not. We conclude that a chunk reduces the load on WM via retrieval of a compact chunk representation from long-term memory that replaces the representations of individual elements of the chunk. This frees up capacity for subsequently encoded material. (PsycINFO Database Record (c) 2018 APA, all rights reserved)},
  keywords = {Chunking,Human Channel Capacity,Long Term Memory,Short Term Memory},
  file = {/Users/sebsilas/Zotero/storage/FY8PNMXI/Thalmann et al. - 2019 - How does chunking help working memory.pdf;/Users/sebsilas/Zotero/storage/GXGR5UXM/2018-18179-001.html},
}
