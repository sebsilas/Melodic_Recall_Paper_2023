
@book{lehmannPsychologyMusiciansUnderstanding2007,
	title = {Psychology for musicians: understanding and acquiring the skills},
	isbn = {978-0-19-514610-3},
	shorttitle = {Psychology for musicians},
	abstract = {This book provides a concise, accessible, and up-to-date introduction to psychological research for musicians - performers, music educators, and studio teachers. Designed to address the needs and priorities of the performing musician rather than the research community, it reviews the relevant psychological research findings in relation to situations and issues faced by musicians, and draws out practical implications for the practice of teaching and performance. Rather than a list of {DOs} and {DON}'Ts, this book equips musicians with an understanding of the basic psychological principles that underlie music performcance, enabling each reader to apply the content flexibly to the task at hand. Following a brief review of the scientific method as a way of thinking about the issues and problems in music, this text addresses the nature-nurture problem, identification and assessment of musical aptitude, musical development, adult skill maintenance, technical and expressive skills, practice, interpretation and expressivity, sight-reading, memorization, creativity, and composition, performance anxiety, critical listening, and teaching and learning. While there is a large body of empirical research regarding music, most musicians lack the scientific training to interpret these studies. This text bridges this gap by relating these skills to the musician's experiences, addressing their needs directly with non-technical language and practical application. The book includes multiple illustrations, brief music examples, cases, questions, and suggestions for further reading.},
	pagetotal = {279},
	publisher = {Oxford University Press, {USA}},
	author = {Lehmann, Andreas C. and Sloboda, John A. and Woody, Robert Henley},
	date = {2007-02-08},
	langid = {english},
	note = {Google-Books-{ID}: {wI}4RDAAAQBAJ},
	keywords = {Music / Instruction \& Study / Theory, Psychology / Cognitive Psychology \& Cognition},
}

@article{ericssonLongtermWorkingMemory1995,
	title = {Long-term working memory},
	volume = {102},
	issn = {0033-295X},
	doi = {10.1037/0033-295x.102.2.211},
	abstract = {To account for the large demands on working memory during text comprehension and expert performance, the traditional models of working memory involving temporary storage must be extended to include working memory based on storage in long-term memory. In the proposed theoretical framework cognitive processes are viewed as a sequence of stable states representing end products of processing. In skilled activities, acquired memory skills allow these end products to be stored in long-term memory and kept directly accessible by means of retrieval cues in short-term memory, as proposed by skilled memory theory. These theoretical claims are supported by a review of evidence on memory in text comprehension and expert performance in such domains as mental calculation, medical diagnosis, and chess.},
	pages = {211--245},
	number = {2},
	journaltitle = {Psychological Review},
	shortjournal = {Psychol Rev},
	author = {Ericsson, K. A. and Kintsch, W.},
	date = {1995-04},
	pmid = {7740089},
	keywords = {Humans, Attention, Aptitude, Concept Formation, Mental Processes, Retention, Psychology},
}

@article{tillmannImplicitLearningTonality2000,
	title = {Implicit learning of tonality: A self-organizing approach},
	volume = {107},
	issn = {1939-1471(Electronic),0033-295X(Print)},
	doi = {10.1037/0033-295X.107.4.885},
	shorttitle = {Implicit learning of tonality},
	abstract = {Tonal music is a highly structured system that is ubiquitous in our cultural environment. We demonstrate the acquisition of implicit knowledge of tonal structure through neural self-organization resulting from mere exposure to simultaneous and sequential combinations of tones. In the process of learning, a network with fundamental neural constraints comes to internalize the essential correlational structure of tonal music. After learning, the network was run through a range of experiments from the literature. The model provides a parsimonious account of a variety of empirical findings dealing with the processing of tone, chord, and key relationships, including relatedness judgments, memory judgments, and expectancies. It also illustrates the plausibility of activation being a unifying mechanism underlying a range of cognitive tasks. ({PsycINFO} Database Record (c) 2017 {APA}, all rights reserved)},
	pages = {885--913},
	number = {4},
	journaltitle = {Psychological Review},
	author = {Tillmann, Barbara and Bharucha, Jamshed J. and Bigand, Emmanuel},
	date = {2000},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Connectionism, Experimentation, Implicit Learning, Incidental Learning, Music Perception, Neural Networks, Pitch (Frequency)},
	file = {Snapshot:/Users/sebsilas/Zotero/storage/LEZTZY3K/2000-02818-009.html:text/html;Submitted Version:/Users/sebsilas/Zotero/storage/WYQ3T9Z6/Tillmann et al. - 2000 - Implicit learning of tonality A self-organizing a.pdf:application/pdf},
}

@incollection{claytonSocialPersonalFunctions2008,
	title = {The social and personal functions of music in cross-cultural perspective},
	isbn = {978-0-19-929845-7},
	url = {https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780199298457.001.0001/oxfordhb-9780199298457-e-004},
	abstract = {"The social and personal functions of music in cross-cultural perspective" published on  by Oxford University Press.},
	booktitle = {Oxford Handbook of Music Psychology},
	author = {Clayton, Martin},
	urldate = {2020-04-30},
	date = {2008-12-04},
	langid = {english},
	doi = {10.1093/oxfordhb/9780199298457.013.0004},
	file = {Snapshot:/Users/sebsilas/Zotero/storage/F3X878TK/oxfordhb-9780199298457-e-004.html:text/html},
}

@article{talaminiMusiciansHaveBetter2017,
	title = {Musicians have better memory than nonmusicians: A meta-analysis},
	volume = {12},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0186773},
	doi = {10.1371/journal.pone.0186773},
	shorttitle = {Musicians have better memory than nonmusicians},
	abstract = {Background Several studies have found that musicians perform better than nonmusicians in memory tasks, but this is not always the case, and the strength of this apparent advantage is unknown. Here, we conducted a meta-analysis with the aim of clarifying whether musicians perform better than nonmusicians in memory tasks. Methods Education Source; {PEP} ({WEB})—Psychoanalytic Electronic Publishing; Psychology and Behavioral Science ({EBSCO}); {PsycINFO} (Ovid); {PubMed}; {ScienceDirect}—{AllBooks} Content (Elsevier {API}); {SCOPUS} (Elsevier {API}); {SocINDEX} with Full Text ({EBSCO}) and Google Scholar were searched for eligible studies. The selected studies involved two groups of participants: young adult musicians and nonmusicians. All the studies included memory tasks (loading long-term, short-term or working memory) that contained tonal, verbal or visuospatial stimuli. Three meta-analyses were run separately for long-term memory, short-term memory and working memory. Results We collected 29 studies, including 53 memory tasks. The results showed that musicians performed better than nonmusicians in terms of long-term memory, g = .29, 95\% {CI} (.08–.51), short-term memory, g = .57, 95\% {CI} (.41–.73), and working memory, g = .56, 95\% {CI} (.33–.80). To further explore the data, we included a moderator (the type of stimulus presented, i.e., tonal, verbal or visuospatial), which was found to influence the effect size for short-term and working memory, but not for long-term memory. In terms of short-term and working memory, the musicians’ advantage was large with tonal stimuli, moderate with verbal stimuli, and small or null with visuospatial stimuli. Conclusions The three meta-analyses revealed a small effect size for long-term memory, and a medium effect size for short-term and working memory, suggesting that musicians perform better than nonmusicians in memory tasks. Moreover, the effect of the moderator suggested that, the type of stimuli influences this advantage.},
	pages = {e0186773},
	number = {10},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Talamini, Francesca and Altoè, Gianmarco and Carretti, Barbara and Grassi, Massimo},
	urldate = {2019-02-06},
	date = {2017-10-19},
	langid = {english},
	note = {Number: 10
Reporter: {PLOS} {ONE}},
	keywords = {Learning, Music cognition, Memory, Long-term memory, Meta-analysis, Music perception, Short-term memory, Working memory},
}

@incollection{slobodaImmediateRecallMelodies1985,
	title = {Immediate recall of melodies},
	pages = {143--167},
	booktitle = {Musical structure and cognition},
	publisher = {London: Academic Press.},
	author = {Sloboda, J.A and Parker, D. H. H.},
	editor = {West, R. and Howell, P and Cross, I},
	date = {1985},
	note = {Reporter: Musical structure and cognition},
}

@article{harrisonApplyingModernPsychometric2017,
	title = {Applying modern psychometric techniques to melodic discrimination testing: Item response theory, computerised adaptive testing, and automatic item generation},
	volume = {7},
	rights = {2017 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-017-03586-z},
	doi = {10.1038/s41598-017-03586-z},
	shorttitle = {Applying modern psychometric techniques to melodic discrimination testing},
	abstract = {Modern psychometric theory provides many useful tools for ability testing, such as item response theory, computerised adaptive testing, and automatic item generation. However, these techniques have yet to be integrated into mainstream psychological practice. This is unfortunate, because modern psychometric techniques can bring many benefits, including sophisticated reliability measures, improved construct validity, avoidance of exposure effects, and improved efficiency. In the present research we therefore use these techniques to develop a new test of a well-studied psychological capacity: melodic discrimination, the ability to detect differences between melodies. We calibrate and validate this test in a series of studies. Studies 1 and 2 respectively calibrate and validate an initial test version, while Studies 3 and 4 calibrate and validate an updated test version incorporating additional easy items. The results support the new test’s viability, with evidence for strong reliability and construct validity. We discuss how these modern psychometric techniques may also be profitably applied to other areas of music psychology and psychological science in general.},
	pages = {3618},
	number = {1},
	journaltitle = {Scientific Reports},
	author = {Harrison, Peter M. C. and Collins, Tom and Müllensiefen, Daniel},
	urldate = {2019-04-07},
	date = {2017-06-15},
	note = {Number: 1
Reporter: Scientific Reports},
}

@article{harrisonModellingMelodicDiscrimination2016,
	title = {Modelling melodic discrimination tests: descriptive and explanatory approaches},
	volume = {45},
	issn = {0929-8215},
	url = {https://doi.org/10.1080/09298215.2016.1197953},
	doi = {10.1080/09298215.2016.1197953},
	shorttitle = {Modelling melodic discrimination tests},
	abstract = {Melodic discrimination tests have been used for many years to assess individual differences in musical abilities. These tests are usually analysed using classical test theory. However, classical test theory is not well suited for optimizing test efficiency or for investigating construct validity. This paper addresses this problem by applying modern item response modelling techniques to three melodic discrimination tests. First, descriptive item response modelling is used to develop a short melodic discrimination test from a larger item pool. The resulting test meets the test-theoretic assumptions of a Rasch (1960) item response model and possesses good concurrent and convergent validity as well as good testing efficiency. Second, an explicit cognitive model of melodic discrimination is used to generate hypotheses relating item difficulty to structural item features such as melodic complexity, similarity, and tonalness. These hypotheses are then tested on response data from three melodic discrimination tests using explanatory item response modelling. Results indicate that item difficulty is predicted by melodic complexity and melodic similarity, consistent with the proposed cognitive model. This provides useful evidence for construct validity. This paper therefore demonstrates the benefits of item response modelling both for efficient test construction and for test validity.},
	pages = {265--280},
	number = {3},
	journaltitle = {Journal of New Music Research},
	author = {Harrison, Peter M. C. and Musil, Jason Jiří and Müllensiefen, Daniel},
	urldate = {2019-04-07},
	date = {2016-07-02},
	note = {Number: 3
Reporter: Journal of New Music Research},
	keywords = {item response modelling, melodic discrimination, memory, musical abilities, similarity},
}

@incollection{dreyfusRecognitionLeitmotivesRichard2016,
	title = {Recognition of Leitmotives in Richard Wagner's Music: An Item Response Theory Approach},
	isbn = {978-3-319-25224-7},
	url = {https://www.springer.com/gb/book/9783319252247},
	series = {Studies in Classification, Data Analysis, and Knowledge Organization},
	abstract = {This book offers a snapshot of the state-of-the-art in classification at the interface between statistics, computer science and application fields. The contributions span a broad spectrum, from theoretical developments to practical applications; they all share a strong computational component. The topics addressed are from the following fields: Statistics and Data Analysis; Machine Learning and Knowledge Discovery; Data Analysis in Marketing; Data Analysis in Finance and Economics; Data Analysis in Medicine and the Life Sciences; Data Analysis in the Social, Behavioural, and Health Care Sciences; Data Analysis in Interdisciplinary Domains; Classification and Subject Indexing in Library and Information Science. The book presents selected papers from the Second European Conference on Data Analysis, held at Jacobs University Bremen in July 2014. This conference unites diverse researchers in the pursuit of a common topic, creating truly unique synergies in the process.},
	pages = {473--483},
	booktitle = {Analysis of Large and Complex Data},
	publisher = {Springer International Publishing},
	author = {Dreyfus, L. and Crawford, T. and Müllensiefen, D. and Baker, D.},
	editor = {Wilhelm, Adalbert F. X. and Kestler, Hans A.},
	urldate = {2019-04-07},
	date = {2016},
	langid = {english},
	note = {Reporter: Analysis of Large and Complex Data},
}

@article{talaminiWorkingMemoryMusicians2016,
	title = {The working memory of musicians and nonmusicians},
	volume = {34},
	rights = {© 2016 by The Regents of the University of California},
	issn = {0730-7829, 1533-8312},
	url = {http://mp.ucpress.edu/content/34/2/183},
	doi = {10.1525/mp.2016.34.2.183},
	abstract = {Skip to Next Section
Musicians have superior performances compared to nonmusicians in many auditory perception tasks. This superiority extends to memory tasks such as the digit span. Literature suggests that the musicians’ advantage unfolds along two axes: sensory modality (musicians perform better when the task is auditory) and task complexity (musicians tend to perform better in the forward and not — for example — backward digit span). In addition, it is unclear whether there are specific music abilities linked with improved performance in the digit span. Here, musicians and nonmusicians performed a digit span task that was presented aurally, visually, or audiovisually. The task was performed with or without a concurrent task (i.e., articulatory suppression) in order to explore the role of rehearsal strategies and also manipulate task complexity. Finally, music abilities of all participants were assessed using the Profile of Music Perception Skills ({PROMS}) test. Musicians had larger spans than nonmusicians regardless of the sensory modality and the concurrent task. In addition, the auditory and audiovisual spans (but not visual) were correlated with one subscale of the {PROMS} test. Findings suggest a general advantage of musicians over nonmusicians in verbal working memory tasks, with a possible role of sensory modality and task complexity.},
	pages = {183--191},
	number = {2},
	journaltitle = {Music Perception: An Interdisciplinary Journal},
	shortjournal = {{MUSIC} {PERCEPT}},
	author = {Talamini, Francesca and Carretti, Barbara and Grassi, Massimo},
	urldate = {2019-04-13},
	date = {2016-12-01},
	langid = {english},
	note = {Number: 2
Reporter: Music Perception: An Interdisciplinary Journal},
	keywords = {articulatory suppression, digit span, musicians, nonmusicians, verbal working memory},
}

@article{mullensiefenMusicalityNonmusiciansIndex2014,
	title = {The musicality of non-musicians: an index for assessing musical sophistication in the general population},
	volume = {9},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0089642},
	doi = {10.1371/journal.pone.0089642},
	shorttitle = {The musicality of non-musicians},
	abstract = {Musical skills and expertise vary greatly in Western societies. Individuals can differ in their repertoire of musical behaviours as well as in the level of skill they display for any single musical behaviour. The types of musical behaviours we refer to here are broad, ranging from performance on an instrument and listening expertise, to the ability to employ music in functional settings or to communicate about music. In this paper, we first describe the concept of ‘musical sophistication’ which can be used to describe the multi-faceted nature of musical expertise. Next, we develop a novel measurement instrument, the Goldsmiths Musical Sophistication Index (Gold-{MSI}) to assess self-reported musical skills and behaviours on multiple dimensions in the general population using a large Internet sample (n = 147,636). Thirdly, we report results from several lab studies, demonstrating that the Gold-{MSI} possesses good psychometric properties, and that self-reported musical sophistication is associated with performance on two listening tasks. Finally, we identify occupation, occupational status, age, gender, and wealth as the main socio-demographic factors associated with musical sophistication. Results are discussed in terms of theoretical accounts of implicit and statistical music learning and with regard to social conditions of sophisticated musical engagement.},
	pages = {e89642},
	number = {2},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Müllensiefen, Daniel and Gingras, Bruno and Musil, Jason and Stewart, Lauren},
	urldate = {2019-04-23},
	date = {2014-02-26},
	langid = {english},
	note = {Number: 2
Reporter: {PLOS} {ONE}},
	keywords = {Behavior, Music cognition, Memory, Music perception, Psychometrics, Bioacoustics, Emotions, Professions},
}

@article{tarrMusicSocialBonding2014,
	title = {Music and social bonding: “self-other” merging and neurohormonal mechanisms},
	volume = {5},
	issn = {1664-1078},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4179700/},
	doi = {10.3389/fpsyg.2014.01096},
	shorttitle = {Music and social bonding},
	abstract = {It has been suggested that a key function of music during its development and spread amongst human populations was its capacity to create and strengthen social bonds amongst interacting group members. However, the mechanisms by which this occurs have not been fully discussed. In this paper we review evidence supporting two thus far independently investigated mechanisms for this social bonding effect: self-other merging as a consequence of inter-personal synchrony, and the release of endorphins during exertive rhythmic activities including musical interaction. In general, self-other merging has been experimentally investigated using dyads, which provide limited insight into large-scale musical activities. Given that music can provide an external rhythmic framework that facilitates synchrony, explanations of social bonding during group musical activities should include reference to endorphins, which are released during synchronized exertive movements. Endorphins (and the endogenous opioid system ({EOS}) in general) are involved in social bonding across primate species, and are associated with a number of human social behaviors (e.g., laughter, synchronized sports), as well as musical activities (e.g., singing and dancing). Furthermore, passively listening to music engages the {EOS}, so here we suggest that both self-other merging and the {EOS} are important in the social bonding effects of music. In order to investigate possible interactions between these two mechanisms, future experiments should recreate ecologically valid examples of musical activities.},
	journaltitle = {Frontiers in Psychology},
	shortjournal = {Front Psychol},
	author = {Tarr, Bronwyn and Launay, Jacques and Dunbar, Robin I. M.},
	urldate = {2019-07-23},
	date = {2014-09-30},
	pmid = {25324805},
	pmcid = {PMC4179700},
	note = {Reporter: Frontiers in Psychology},
}

@article{cowanMagicalMysteryFour2010,
	title = {The magical mystery four: how is working memory capacity limited, and why?},
	volume = {19},
	issn = {0963-7214},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2864034/},
	doi = {10.1177/0963721409359277},
	shorttitle = {The magical mystery four},
	abstract = {Working memory storage capacity is important because cognitive tasks can be completed only with sufficient ability to hold information as it is processed. The ability to repeat information depends on task demands but can be distinguished from a more constant, underlying mechanism: a central memory store limited to 3 to 5 meaningful items in young adults. I will discuss why this central limit is important, how it can be observed, how it differs among individuals, and why it may occur.},
	pages = {51--57},
	number = {1},
	journaltitle = {Current directions in psychological science},
	shortjournal = {Curr Dir Psychol Sci},
	author = {Cowan, Nelson},
	urldate = {2019-11-05},
	date = {2010-02-01},
	pmid = {20445769},
	pmcid = {PMC2864034},
	note = {Number: 1
Reporter: Current directions in psychological science},
}

@article{baddeleyEpisodicBufferNew2000,
	title = {The episodic buffer: a new component of working memory?},
	volume = {4},
	issn = {1364-6613, 1879-307X},
	url = {https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(00)01538-2},
	doi = {10.1016/S1364-6613(00)01538-2},
	shorttitle = {The episodic buffer},
	pages = {417--423},
	number = {11},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Baddeley, Alan},
	urldate = {2019-11-05},
	date = {2000-11-01},
	pmid = {11058819},
	note = {Number: 11
Reporter: Trends in Cognitive Sciences},
}

@article{vergauweMentalProcessesShare2010,
	title = {Do mental processes share a domain-general resource?},
	volume = {21},
	issn = {1467-9280},
	doi = {10.1177/0956797610361340},
	abstract = {What determines success and failure in dual-task situations? Many theories propose that the extent to which two activities can be performed concurrently depends on the nature of the information involved in the activities. In particular, verbal and visuospatial activities are thought to be fueled by distinct resources, so that interference occurs between two verbal activities or two visuospatial activities, but little or no interference occurs between verbal and visuospatial activities. The current study examined trade-offs in four dual-task situations in which participants maintained verbal or visuospatial information while concurrently processing either verbal or visuospatial information. We manipulated the cognitive load of concurrent processing and assessed recall performance in each condition. Results revealed that both verbal and visuospatial recall performance decreased as a direct function of increasing cognitive load, regardless of the nature of the information concurrently processed. The observed trade-offs suggest strongly that verbal and visuospatial activities compete for a common domain-general pool of resources.},
	pages = {384--390},
	number = {3},
	journaltitle = {Psychological Science},
	shortjournal = {Psychol Sci},
	author = {Vergauwe, Evie and Barrouillet, Pierre and Camos, Valérie},
	date = {2010-03},
	pmid = {20424075},
	note = {Number: 3
Reporter: Psychological Science},
	keywords = {Humans, Attention, Female, Male, Mental Processes, Retention (Psychology), Young Adult, Orientation, Color Perception, Judgment, Pattern Recognition, Visual, Verbal Learning},
}

@book{hoyleHandbookStructuralEquation2012,
	title = {Handbook of Structural Equation Modelling},
	isbn = {978-1-4625-0447-3},
	abstract = {The first comprehensive structural equation modeling ({SEM}) handbook, this accessible volume offers broad and deep coverage of both the mechanics of {SEM} and specific {SEM} strategies and applications. The editor, contributors, and editorial advisory board are leading methodologists who have organized the book to move from simpler material to more statistically complex modeling approaches. Sections cover the foundations of {SEM}; statistical underpinnings, from assumptions to model modifications; steps in implementation, from data preparation through writing the {SEM} report; and basic and advanced applications, including new and emerging topics in {SEM}, such as intensive longitudinal assessments, dyadic data, brain imaging, and genotyping. Each chapter provides conceptually oriented descriptions, fully explicated analyses, and engaging examples that reveal modeling possibilities for use with readers' data. Many of the chapters also include access to data and syntax files at the companion website, allowing readers to try their hands at reproducing the authors' results.},
	publisher = {Guilford Press},
	author = {Hoyle, Rick H.},
	date = {2012-05-21},
	langid = {english},
	note = {Book Authors: \_:n462
Reporter: Handbook of Structural Equation Modeling
Google-Books-{ID}: {qC}4aMfXL1JkC},
	keywords = {Business \& Economics / Statistics, Education / Statistics, Medical / Nursing / Research \& Theory, Psychology / Statistics, Social Science / Statistics},
}

@article{mullensiefenFANTASTICFeatureANalysis2009,
	title = {{FANTASTIC}: Feature {ANalysis} Technology Accessing {STatistics} (In a Corpus; Technical report)},
	url = {http://www.doc.gold.ac.uk/isms/m4s/FANTASTIC_docs.pdf},
	pages = {37},
	author = {Müllensiefen, Daniel},
	date = {2009},
	langid = {english},
	file = {Mullensiefen - Fantastic Feature ANalysis Technology Accessing S.pdf:/Users/sebsilas/Zotero/storage/U8DJP2VH/Mullensiefen - Fantastic Feature ANalysis Technology Accessing S.pdf:application/pdf},
}

@incollection{mullensiefenSlobodaParkerRecall2011,
	location = {New York, {NY}, {US}},
	title = {Sloboda and Parker's recall paradigm for melodic memory: A new, computational perspective},
	isbn = {978-0-19-958156-6},
	shorttitle = {Sloboda and Parker's recall paradigm for melodic memory},
	abstract = {Sloboda and Parker (1985) proposed a new experimental paradigm for research on melodic memory in which participants are asked to listen to novel melodies and to sing back the parts they can recall from memory. In contrast to the many varieties of melodic recognition paradigms frequently used in memory research this sung recall paradigm can answer questions about how mental representations of a melody build up in memory over time, about the nature of memory errors, and about the interplay between different musical dimensions in memory. Although the paradigm has clear advantages with regard to ecological validity, Sloboda and Parker also note a number of difficulties inherent to the paradigm that mostly result from necessity to analyse 'dirty musical data' as sung by mostly untrained participants. This contribution reviews previous research done using the sung recall paradigm and proposes a computational approach for the analysis of dirty melodic data. This approach is applied to data from a new study using Sloboda and Parker's paradigm. This chapter discusses how this new approach not only enables researchers to handle large amounts of data but also make use of concepts from computational music analysis and music information retrieval that introduce a new level of analytic precision and conceptual clarity and thus provide a new interface which connects Sloboda's paradigm to rigorous quantitative data analysis. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {161--186},
	booktitle = {Music and the mind: Essays in honour of John Sloboda},
	publisher = {Oxford University Press},
	author = {Müllensiefen, Daniel and Wiggins, Geraint A.},
	date = {2011},
	keywords = {Music, Memory, Automated Information Retrieval, Computational Modeling, Recall (Learning)},
	file = {Snapshot:/Users/sebsilas/Zotero/storage/6QHFQW7N/2011-07517-009.html:text/html},
}

@incollection{frielerComputationalMelodyAnalysis2018,
	title = {Computational melody analysis},
	isbn = {978-3-95983-125-3},
	pages = {41--84},
	booktitle = {Inside the Jazzomat. New Perspectives for Jazz Research},
	publisher = {Schott Campus},
	author = {Frieler, Klaus},
	editor = {Pfleiderer, M. and Frieler, K. and Abeßer, W.-G. and Zaddach, B. and Burkhard, B.},
	date = {2018},
}

@article{mullensiefenRoleFeaturesContext2014,
	title = {The role of features and context in recognition of novel melodies},
	volume = {31},
	issn = {1533-8312(Electronic),0730-7829(Print)},
	doi = {10.1525/mp.2014.31.5.418},
	abstract = {We investigated how well structural features such as note density or the relative number of changes in the melodic contour could predict success in implicit and explicit memory for unfamiliar melodies. We also analyzed which features are more likely to elicit increasingly confident judgments of “old” in a recognition memory task. An automated analysis program computed structural aspects of melodies, both independent of any context, and also with reference to the other melodies in the testset and the parent corpus of pop music. A few features predicted success in both memory tasks, which points to a shared memory component. However, motivic complexity compared to a large corpus of pop music had different effects on explicit and implicit memory. We also found that just a few features are associated with different rates of “old” judgments, whether the items were old or new. Rarer motives relative to the testset predicted hits and rarer motives relative to the corpus predicted false alarms. This data-driven analysis provides further support for both shared and separable mechanisms in implicit and explicit memory retrieval, as well as the role of distinctiveness in true and false judgments of familiarity. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {418--435},
	number = {5},
	journaltitle = {Music Perception},
	author = {Müllensiefen, Daniel and Halpern, Andrea R.},
	date = {2014},
	note = {Place: {US}
Publisher: University of California Press},
	keywords = {Music, Memory, Judgment, Analysis, Explicit Memory, Implicit Memory},
	file = {Full Text:/Users/sebsilas/Zotero/storage/8WSVRZYZ/Müllensiefen and Halpern - 2014 - The role of features and context in recognition of.pdf:application/pdf;Snapshot:/Users/sebsilas/Zotero/storage/PU8B6D3J/2014-24007-002.html:text/html},
}

@article{pearceStatisticalLearningProbabilistic2018,
	title = {Statistical learning and probabilistic prediction in music cognition: mechanisms of stylistic enculturation},
	volume = {1423},
	issn = {0077-8923},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6849749/},
	doi = {10.1111/nyas.13654},
	shorttitle = {Statistical learning and probabilistic prediction in music cognition},
	abstract = {Music perception depends on internal psychological models derived through exposure to a musical culture. It is hypothesized that this musical enculturation depends on two cognitive processes: (1) statistical learning, in which listeners acquire internal cognitive models of statistical regularities present in the music to which they are exposed; and (2) probabilistic prediction based on these learned models that enables listeners to organize and process their mental representations of music. To corroborate these hypotheses, I review research that uses a computational model of probabilistic prediction based on statistical learning (the information dynamics of music ({IDyOM}) model) to simulate data from empirical studies of human listeners. The results show that a broad range of psychological processes involved in music perception—expectation, emotion, memory, similarity, segmentation, and meter—can be understood in terms of a single, underlying process of probabilistic prediction using learned statistical models. Furthermore, {IDyOM} simulations of listeners from different musical cultures demonstrate that statistical learning can plausibly predict causal effects of differential cultural exposure to musical styles, providing a quantitative model of cultural distance. Understanding the neural basis of musical enculturation will benefit from close coordination between empirical neuroimaging and computational modeling of underlying mechanisms, as outlined here., It is hypothesized that this musical enculturation depends on two cognitive processes: statistical learning and probabilistic prediction. Here, I review research using the information dynamics of music model of probabilistic prediction based on statistical learning to suggest a single process underlying a broad range of psychological processes involved in music perception.},
	pages = {378--395},
	number = {1},
	journaltitle = {Annals of the New York Academy of Sciences},
	shortjournal = {Ann N Y Acad Sci},
	author = {Pearce, Marcus T.},
	urldate = {2020-08-31},
	date = {2018-07},
	pmid = {29749625},
	pmcid = {PMC6849749},
	file = {PubMed Central Full Text PDF:/Users/sebsilas/Zotero/storage/4VLDBUKV/Pearce - 2018 - Statistical learning and probabilistic prediction .pdf:application/pdf},
}

@article{oberauerWorkingMemoryCapacity2007,
	title = {Working memory capacity},
	volume = {54},
	doi = {10.1027/1618-3169.54.3.245},
	pages = {245--246},
	journaltitle = {Experimental Psychology},
	author = {Oberauer, Klaus and Cowan, Nelson},
	date = {2007},
}

@book{slobodaMusicalMindCognitive1985,
	title = {The Musical Mind: The Cognitive Psychology of Music},
	isbn = {978-0-19-852114-3},
	shorttitle = {The Musical Mind},
	abstract = {In this comprehensive survey of the experimental literature on the cognitive psychology of music, Professor Sloboda, a psychologist and practicing musician, and "understanding" music and shows how such skills are acquired. "A break-through...brings together recent work in a way that demonstrates its significance for musicians, whilst in no way compromising the psychological theory on which it is based. The clarity of Sloboda's writing and his numerous suggestions for further research will make his book essential reading for anyone, student or researcher, interested in how minds and music interact."--Nature},
	pagetotal = {312},
	publisher = {Clarendon Press},
	author = {Sloboda, John A.},
	date = {1985},
	langid = {english},
	note = {Google-Books-{ID}: {oZCfAAAAMAAJ}},
	keywords = {Music / General},
}

@article{christiansenNoworNeverBottleneckFundamental2016,
	title = {The Now-or-Never bottleneck: A fundamental constraint on language},
	volume = {39},
	issn = {0140-525X, 1469-1825},
	url = {https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/nowornever-bottleneck-a-fundamental-constraint-on-language/938D54E80A2A90A1C5990F4915B5E8D8#},
	doi = {10.1017/S0140525X1500031X},
	shorttitle = {The Now-or-Never bottleneck},
	abstract = {Memory is fleeting. New material rapidly obliterates previous material. How, then, can the brain deal successfully with the continual deluge of linguistic input? We argue that, to deal with this “Now-or-Never” bottleneck, the brain must compress and recode linguistic input as rapidly as possible. This observation has strong implications for the nature of language processing: (1) the language system must “eagerly” recode and compress linguistic input; (2) as the bottleneck recurs at each new representational level, the language system must build a multilevel linguistic representation; and (3) the language system must deploy all available information predictively to ensure that local linguistic ambiguities are dealt with “Right-First-Time”; once the original input is lost, there is no way for the language system to recover. This is “Chunk-and-Pass” processing. Similarly, language learning must also occur in the here and now, which implies that language acquisition is learning to process, rather than inducing, a grammar. Moreover, this perspective provides a cognitive foundation for grammaticalization and other aspects of language change. Chunk-and-Pass processing also helps explain a variety of core properties of language, including its multilevel representational structure and duality of patterning. This approach promises to create a direct relationship between psycholinguistics and linguistic theory. More generally, we outline a framework within which to integrate often disconnected inquiries into language processing, language acquisition, and language change and evolution.},
	journaltitle = {Behavioral and Brain Sciences},
	author = {Christiansen, Morten H. and Chater, Nick},
	urldate = {2020-12-21},
	date = {2016},
	langid = {english},
	note = {Publisher: Cambridge University Press},
	keywords = {chunking, grammaticalization, incremental interpretation, language acquisition, language evolution, language processing, online learning, prediction, processing bottleneck, psycholinguistics},
	file = {Snapshot:/Users/sebsilas/Zotero/storage/NJZBQPAC/938D54E80A2A90A1C5990F4915B5E8D8.html:text/html},
}

@collection{pfleidererJazzomatNewPerspectives2017,
	title = {Inside the Jazzomat - new perspectives for jazz research},
	publisher = {Schott Campus},
	editor = {Pfleiderer, Martin and Frieler, Klaus and Abeßer, Jakob and Zaddach, Wolf-Georg and Burkhart, Benjamin},
	date = {2017},
}

@article{silasSingingAbilityAssessment2023,
	title = {Singing Ability Assessment: development and validation of an open-source test environment for singing data},
	journaltitle = {Behaviour Research Methods. In review.},
	author = {Silas, S and Müllensiefen, D and Kopiez, Reinhard},
	date = {2023},
}

@inbook{mullensiefenCognitiveAdequacyMeasurement2004,
	title = {Cognitive adequacy in the measurement of melodic similarity: algorithmic vs. human judgments},
	booktitle = {Music Query: Methods, Models, and User Studies},
	publisher = {{MIT} Press},
	author = {Müllensiefen, Daniel and Frieler, Klaus},
	bookauthor = {Hewlett, Walter B. and Selfridge-Field, Eleanor},
	date = {2004},
}

@incollection{baddeleyWorkingMemory1974,
	title = {Working Memory},
	volume = {8},
	url = {https://www.sciencedirect.com/science/article/pii/S0079742108604521},
	abstract = {This chapter presents a body of new experimental evidence, which provides a firm basis for the working memory hypothesis. The chapter presents a series of experiments on the role of memory in reasoning, language comprehension, and learning. An attempt is made to apply the comparable techniques in all three cases to allow a common pattern to emerge, if the same working memory system is operative in all three instances. The chapter makes a case for postulating the working memory-{LTS} system as a modification of the current {STS}-{LTS} view. Working memory represents a control system with limits on both its storage and processing capabilities, and has access to phonemically coded information (possibly by controlling a rehearsal buffer), that it is responsible for the limited memory span, but does not underlie the recency effect in free recall. The experiments presented in the chapter suggest that the phonemic rehearsal buffer plays a limited role in this process, but is by no means essential. These experiments also suggest that working memory plays a part in verbal reasoning and in prose comprehension. Understanding the detailed role of working memory in these tasks, however, must proceed hand-in-hand with an understanding of the tasks themselves.},
	pages = {47--89},
	booktitle = {Psychology of Learning and Motivation},
	publisher = {Academic Press},
	author = {Baddeley, Alan D. and Hitch, Graham},
	editor = {Bower, Gordon H.},
	urldate = {2021-11-15},
	date = {1974-01-01},
	langid = {english},
	doi = {10.1016/S0079-7421(08)60452-1},
	file = {ScienceDirect Snapshot:/Users/sebsilas/Zotero/storage/G3XAYPRI/S0079742108604521.html:text/html},
}

@article{crayencourDTL1000JazzSolo2021,
	title = {The {DTL}1000 Jazz Solo Dataset (in prep.)},
	journaltitle = {Journal on Computing and Cultural Heritage},
	author = {Crayencour, H.-C. and Velichkina, O. and Frieler, K and Höger, F. and Pfleiderer, M. and Henry, L. and Solis, G. and Wolff, D. and Weyde, T. and Peeters, G. and Basaran, D. and Smith, J. and Proutskova, P.},
	date = {2021},
}

@article{mullensiefenModellingExpertsNotions2007,
	title = {Modelling experts’ notions of melodic similarity},
	volume = {11},
	issn = {1029-8649},
	url = {https://doi.org/10.1177/102986490701100108},
	doi = {10.1177/102986490701100108},
	abstract = {In this article we show that a subgroup of music experts has a reliable and consistent notion of melodic similarity, and that this notion can be measured with satisfactory precision. Our measurements enable us to model the similarity ratings of music experts by automated and algorithmic means. A large number of algorithmic similarity measure found in the literature were mathematically systematised and implemented. The best similarity algorithms compared to human experts were chosen and optimised by statistical means according to different contexts. A multidimensional scaling model of the algorithmic similarity measures is constructed to give an overiew over the different musical dimensions reflected by these measures. We show some examples where this optimised methods could be successfully applied to real world problems like folk song categorisation and analysis, and discuss further applications and implications.},
	pages = {183--210},
	number = {1},
	journaltitle = {Musicae Scientiae},
	shortjournal = {Musicae Scientiae},
	author = {Müllensiefen, Daniel and Frieler, Klaus},
	urldate = {2022-01-11},
	date = {2007-03-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Ltd},
}

@article{jakubowskiDissectingEarwormMelodic2017,
	title = {Dissecting an earworm: Melodic features and song popularity predict involuntary musical imagery},
	volume = {11},
	issn = {1931-390X},
	doi = {10.1037/aca0000090},
	shorttitle = {Dissecting an earworm},
	abstract = {Involuntary musical imagery ({INMI} or “earworms”)—the spontaneous recall and repeating of a tune in one’s mind—can be attributed to a wide range of triggers, including memory associations and recent musical exposure. The present study examined whether a song’s popularity and melodic features might also help to explain whether it becomes {INMI}, using a dataset of tunes that were named as {INMI} by 3,000 survey participants. It was found that songs that had achieved greater success and more recent runs in the U.K. music charts were reported more frequently as {INMI}. A set of 100 of these frequently named {INMI} tunes was then matched to 100 tunes never named as {INMI} by the survey participants, in terms of popularity and song style. These 2 groups of tunes were compared using 83 statistical summary and corpus-based melodic features and automated classification techniques. {INMI} tunes were found to have more common global melodic contours and less common average gradients between melodic turning points than non-{INMI} tunes, in relation to a large pop music corpus. {INMI} tunes also displayed faster average tempi than non-{INMI} tunes. Results are discussed in relation to literature on {INMI}, musical memory, and melodic “catchiness.” ({PsycInfo} Database Record (c) 2020 {APA}, all rights reserved)},
	pages = {122--135},
	number = {2},
	journaltitle = {Psychology of Aesthetics, Creativity, and the Arts},
	author = {Jakubowski, Kelly and Finkel, Sebastian and Stewart, Lauren and Müllensiefen, Daniel},
	date = {2017},
	note = {Place: {US}
Publisher: Educational Publishing Foundation},
	keywords = {Music, Music Perception, Memory, Analysis, Imagery},
	file = {Accepted Version:/Users/sebsilas/Zotero/storage/RHJGB2ZL/Jakubowski et al. - 2017 - Dissecting an earworm Melodic features and song p.pdf:application/pdf;Snapshot:/Users/sebsilas/Zotero/storage/SR9CUKCH/2016-53098-001.html:text/html},
}

@article{bigandMultidimensionalScalingEmotional2005,
	title = {Multidimensional scaling of emotional responses to music: The effect of musical expertise and of the duration of the excerpts},
	volume = {19},
	issn = {0269-9931},
	url = {https://doi.org/10.1080/02699930500204250},
	doi = {10.1080/02699930500204250},
	shorttitle = {Multidimensional scaling of emotional responses to music},
	abstract = {Musically trained and untrained listeners were required to listen to 27 musical excerpts and to group those that conveyed a similar emotional meaning (Experiment 1). The groupings were transformed into a matrix of emotional dissimilarity that was analysed through multidimensional scaling methods ({MDS}). A 3-dimensional space was found to provide a good fit of the data, with arousal and emotional valence as the primary dimensions. Experiments 2 and 3 confirmed the consistency of this 3-dimensional space using excerpts of only 1 second duration. The overall findings indicate that emotional responses to music are very stable within and between participants, and are weakly influenced by musical expertise and excerpt duration. These findings are discussed in light of a cognitive account of musical emotion.},
	pages = {1113--1139},
	number = {8},
	journaltitle = {Cognition and Emotion},
	author = {Bigand, E. and Vieillard, S. and Madurell, F. and Marozeau, J. and Dacquet, A.},
	urldate = {2022-01-28},
	date = {2005-12-01},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/02699930500204250},
}

@article{schellenbergFinegrainedImplicitMemory2019,
	title = {Fine-grained Implicit Memory for Key and Tempo},
	volume = {2},
	issn = {2059-2043},
	url = {https://doi.org/10.1177/2059204319857198},
	doi = {10.1177/2059204319857198},
	abstract = {Listeners remember the pitch level (key) and tempo of musical recordings they have heard multiple times. They also have long-term implicit memory for the key and tempo of novel melodies heard for the first time in the laboratory. In previous research, however, the stimulus melodies were simple and repetitive and the changes in key or tempo were large. Here, we tested the limits of implicit memory for the key and tempo of more complex stimulus melodies. Musically trained and untrained listeners heard 12 novel melodies during an exposure phase and 24 (12 old, 12 new) during a subsequent test (recognition) phase. From exposure to test, half of the melodies were transposed up or down (changed in key) (Experiment 1), or sped up or slowed down (Experiment 2), but to varying degrees. Musically trained listeners displayed enhanced recognition, but transposing or changing the tempo of the melodies reduced performance similarly for all listeners. The effect of the key change did not wane as the transposition was reduced from 6 semitones to 1, but recognition in general was worse as the pitch range of the stimulus melodies increased. The magnitude of the tempo change had a very small effect on response patterns, but Bayesian analyses indicated that the observed data were more likely without considering magnitude. The results suggest that musically trained and untrained listeners have implicit memory for key and tempo that is remarkably fine-grained, even for melodies that are heard for the first time in the laboratory, such that small changes in either feature make a melody less recognizable.},
	pages = {2059204319857198},
	journaltitle = {Music \& Science},
	shortjournal = {Music \& Science},
	author = {Schellenberg, E. Glenn and Weiss, Michael W. and Peng, Chen and Alam, Shayan},
	urldate = {2022-01-28},
	date = {2019-01-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Ltd},
	keywords = {music training, Key, melody, pitch, recognition, tempo},
	file = {SAGE PDF Full Text:/Users/sebsilas/Zotero/storage/PEWX4J99/Schellenberg et al. - 2019 - Fine-grained Implicit Memory for Key and Tempo.pdf:application/pdf},
}

@article{bigandAreWeExperienced2006,
	title = {Are we “experienced listeners”? A review of the musical capacities that do not depend on formal musical training},
	volume = {100},
	issn = {0010-0277},
	url = {https://www.sciencedirect.com/science/article/pii/S0010027705002234},
	doi = {10.1016/j.cognition.2005.11.007},
	series = {The Nature of Music},
	shorttitle = {Are we “experienced listeners”?},
	abstract = {The present paper reviews a set of studies designed to investigate different aspects of the capacity for processing Western music. This includes perceiving the relationships between a theme and its variations, perceiving musical tensions and relaxations, generating musical expectancies, integrating local structures in large-scale structures, learning new compositional systems and responding to music in an emotional (affective) way. The main focus of these studies was to evaluate the influence of intensive musical training on these capacities. The overall set of data highlights that some musical capacities are acquired through exposure to music without the help of explicit training. These capacities reach such a degree of sophistication that they enable untrained listeners to respond to music as “musically experienced listeners” do.},
	pages = {100--130},
	number = {1},
	journaltitle = {Cognition},
	shortjournal = {Cognition},
	author = {Bigand, E. and Poulin-Charronnat, B.},
	urldate = {2022-01-28},
	date = {2006-05-01},
	langid = {english},
	keywords = {Implicit learning, Music cognition, Musical expertise, Emotion, Musical priming},
	file = {ScienceDirect Snapshot:/Users/sebsilas/Zotero/storage/TUG72UXL/S0010027705002234.html:text/html},
}

@article{ettlingerImplicitMemoryMusic2011,
	title = {Implicit Memory in Music and Language},
	volume = {2},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2011.00211},
	abstract = {Research on music and language in recent decades has focused on their overlapping neurophysiological, perceptual, and cognitive underpinnings, ranging from the mechanism for encoding basic auditory cues to the mechanism for detecting violations in phrase structure. These overlaps have most often been identified in musicians with musical knowledge that was acquired explicitly, through formal training. In this paper, we review independent bodies of work in music and language that suggest an important role for implicitly acquired knowledge, implicit memory, and their associated neural structures in the acquisition of linguistic or musical grammar. These findings motivate potential new work that examines music and language comparatively in the context of the implicit memory system.},
	journaltitle = {Frontiers in Psychology},
	author = {Ettlinger, Marc and Margulis, Elizabeth and Wong, Patrick},
	urldate = {2022-01-28},
	date = {2011},
	file = {Full Text PDF:/Users/sebsilas/Zotero/storage/FKG9MDX4/Ettlinger et al. - 2011 - Implicit Memory in Music and Language.pdf:application/pdf},
}

@article{idsonBidimensionalModelPitch1978,
	title = {A bidimensional model of pitch in the recognition of melodies},
	volume = {24},
	issn = {1532-5962},
	doi = {10.3758/BF03198783},
	abstract = {In 4 experiments with a total of 81 undergraduates, melodies were subjected to structural transformations designed to evaluate the effects of interval magnitude, contour, tone height, and tone chroma. In 2 transformations, the component tones of a melody were displaced by octave intervals, either preserving or violating the pattern of changes in pitch direction (melodic contour). Replicating previous work, when contour was violated perception of the melody was severely disrupted. In contrast, when contour was preserved, the melodies were identified as accurately as the untransformed melodies. In other transformations, a variety of forms of contour information were preserved, while eliminating information for absolute pitch and interval magnitude. The level of performance on all such transformations fell between the levels observed in the other 2 conditions. Results suggest that the bidimensional model of pitch is applicable to recognition of melodies as well as single tones. Moreover, the results argue that contour, as well as interval magnitude, is providing essential information for melodic perception. (43 ref) ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {551--565},
	number = {6},
	journaltitle = {Perception \& Psychophysics},
	author = {Idson, Wendy L. and Massaro, Dominic W.},
	date = {1978},
	note = {Place: {US}
Publisher: Psychonomic Society},
	keywords = {Music, Pitch (Frequency), Models, Auditory Discrimination, Recognition (Learning), Stimulus Parameters},
	file = {Full Text:/Users/sebsilas/Zotero/storage/FH37X2SH/Idson and Massaro - 1978 - A bidimensional model of pitch in the recognition .pdf:application/pdf;Snapshot:/Users/sebsilas/Zotero/storage/2CCKTXRU/1980-20352-001.html:text/html},
}

@article{dowlingScaleContourTwo1978,
	title = {Scale and contour: Two components of a theory of memory for melodies},
	volume = {85},
	issn = {1939-1471},
	doi = {10.1037/0033-295X.85.4.341},
	shorttitle = {Scale and contour},
	abstract = {Develops a 2-component model of how melodies are stored in long- and short-term memory. The 1st component is the overlearned perceptual-motor schema of the musical scale. Evidence is presented supporting the lifetime stability of scales and the fact that they seem to have a basically logarithmic form cross-culturally. The 2nd component, melodic contour, is shown to function independently of pitch interval sequence in memory. 21 college students were studied using a recognition memory paradigm in which tonal standard stimuli were confused with same-contour comparisons, whether they were exact transpositions or tonal answers, but not with atonal comparison stimuli. This result is contrasted with earlier work using atonal melodies and shows the interdependence of the 2 components, scale and contour. (32 ref) ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {341--354},
	number = {4},
	journaltitle = {Psychological Review},
	author = {Dowling, W.J},
	date = {1978},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Music, Pitch (Frequency), Memory, Human Information Storage},
	file = {Snapshot:/Users/sebsilas/Zotero/storage/KUWF7RA7/1979-22754-001.html:text/html},
}

@article{massaroRoleToneHeight1980,
	title = {The role of tone height, melodic contour, and tone chroma in melody recognition},
	volume = {6},
	doi = {10.1037//0278-7393.6.1.77},
	abstract = {The present experiments assessed the contribution of tone height, melodic contour, and tone chroma to melody recognition. Rather than using highly familiar folk songs as in earlier studies, subjects were taught new melodies. Novel melodies were used to (a) more precisely control potential cues (e.g., rhythm) that are not of present interest, (b) eliminate unison intervals that cannot be transformed appropriately, (c) provide a direct analysis of the nature of confusion errors, (d) test whether recently learned melodies are recognized differently than highly overlearned melodies, and (e) evaluate the extent to which practice in the experimental task alters the process of recognition. The results replicate previous studies using familiar folk songs. Transformations of the original melodies were accurately recognized when tone height was violated, but both melodic contour and tone chroma were maintained. Violating both tone height and contour while maintaining chroma produced extremely poor recognition. Performance was intermediate when just melodic contour was preserved. There is now good evidence to support the idea that melodic contour and tone chroma, in addition to tone height, contribute to recognition of both highly familiar and recently learned melodies.},
	pages = {77--90},
	journaltitle = {Journal of experimental psychology. Human learning and memory},
	shortjournal = {Journal of experimental psychology. Human learning and memory},
	author = {Massaro, Dom and Kallman, Howard and Kelly, Janet},
	date = {1980-02-01},
	file = {Full Text PDF:/Users/sebsilas/Zotero/storage/9FN9SUGF/Massaro et al. - 1980 - The role of tone height, melodic contour, and tone.pdf:application/pdf},
}

@article{edworthyIntervalContourMelody1985,
	title = {Interval and Contour in Melody Processing},
	volume = {2},
	issn = {0730-7829},
	url = {https://www.jstor.org/stable/40285305},
	doi = {10.2307/40285305},
	abstract = {Musician subjects were required to detect interval and contour changes in transposed versions of standard melodies of 3, 5, 7, 9,11,13, and 15 notes. Subjects were significantly better at detecting contour alterations for melodies of up to 11 notes but significantly better at detecting interval alterations in the 15-note melodies. Serial position effects for 5-, 7-, and 9-note melodies showed contour to be immediately precise after transposition, whereas the ability to detect interval alterations improved as the melodies progressed. These results suggest that, on transposition, contour information is immediately precise but is lost as melody length increases. Interval information is initially less precise but is more resistant to forgetting in longer melodies. The implication of this is that contour can be encoded independently of tonal context, whereas interval information becomes more precise as a tonal framework is established. Some musical implications of the finding are discussed.},
	pages = {375--388},
	number = {3},
	journaltitle = {Music Perception: An Interdisciplinary Journal},
	author = {Edworthy, Judy},
	urldate = {2022-01-28},
	date = {1985},
	note = {Publisher: University of California Press},
}

@article{dowlingTimeCourseRecognition1995,
	title = {The time course of recognition of novel melodies},
	volume = {57},
	issn = {0031-5117},
	doi = {10.3758/bf03206500},
	abstract = {Seven experiments explored the time course of recognition of brief novel melodies. In a continuous-running-memory task, subjects recognized melodic transpositions following delays up to 2.0 min. The delays were either empty or filled with other melodies. Test items included exact transpositions (T), same-contour lures ({SC}) with altered pitch intervals, and different-contour lures ({DC}); {DCs} differed from Ts in the pattern of ups and downs of pitch. With this design, we assessed subjects' discrimination of detailed changes in pitch intervals (T/{SC} discrimination) as well as their discrimination of contour changes (T/{DC}). We used both artificial and "real" melodies. Artificial melodies differed in conformity to a musical key, being tonal or atonal. After empty delays, T/{DC} discrimination was superior to T/{SC} discrimination. Surprisingly, after filled delays, T/{SC} discrimination was superior to T/{DC}. When only filled delays were tested, T/{SC} discrimination did not decline over the longest delays. T/{DC} performance declined more than did T/{SC} performance across both empty and filled delays. Tonality was an important factor only for T/{SC} discrimination after filled delays. T/{DC} performance was better with rhythmically intact folk melodies than with artificial isochronous melodies. Although T/{SC} performance improved over filled delays, it did not overtake T/{DC} performance. These results suggest that (1) contour and pitch-interval information make different contributions to recognition, with contour dominating performance after brief empty delays and pitch intervals dominating after longer filled delays; (2) a coherent tonality facilitates the encoding of pitch-interval patterns of melodies; and (3) the rich melodic-rhythmic contours of real melodies facilitate T/{DC} discrimination. These results are discussed in terms of automatic and controlled processing of melodic information.},
	pages = {136--149},
	number = {2},
	journaltitle = {Perception \& Psychophysics},
	shortjournal = {Percept Psychophys},
	author = {Dowling, W. J. and Kwak, S. and Andrews, M. W.},
	date = {1995-02},
	pmid = {7885812},
	keywords = {Humans, Music, Pitch Perception, Adult, Attention, Female, Male, Retention, Psychology, Mental Recall, Psychoacoustics},
	file = {Full Text:/Users/sebsilas/Zotero/storage/M5I2KCKI/Dowling et al. - 1995 - The time course of recognition of novel melodies.pdf:application/pdf},
}

@article{longRelationshipsPitchMemory1977,
	title = {Relationships between Pitch Memory in Short Melodies and Selected Factors},
	volume = {25},
	issn = {0022-4294},
	url = {https://www.jstor.org/stable/3345268},
	doi = {10.2307/3345268},
	abstract = {This study investigated relationships between memory for pitch in short melodies and melody length, tonal structure, melodic contour, and music perception ability. Results indicated that all these factors interact to some degree with memory. The factors demonstrating the greatest influence were music perception ability (a product of previous music learning), and tonal structure (the degree of relationships among the pitches of a melody, commonly described as tonality or atonality). Memory for pitch improved as the number of pitches in a melody decreased. Certain melodic contours also caused variations in pitch memory.},
	pages = {272--282},
	number = {4},
	journaltitle = {Journal of Research in Music Education},
	author = {Long, Peggy A.},
	urldate = {2022-01-28},
	date = {1977},
	note = {Publisher: [{MENC}: The National Association for Music Education, Sage Publications, Inc.]},
}

@article{dowlingImportanceIntervalInformation1981,
	title = {The Importance of Interval Information in Long-term Memory for Melodies},
	volume = {1},
	doi = {10.1037/h0094275},
	abstract = {Four experiments examined the roles of melodic contour and pitch interval information in recognition memory for melodies. In Experiments 1 and 2, subjects heard excerpts from Beethoven String Quartets, and subsequently attempted to detect copies of input melodies (Targets) as well as Related items, which resembled input items with respect to contour and rhythm, but not pitch intervals. Targets were recognized significantly better than Relateds, which were recognized only slightly more often than lures (Lures were drawn from other quartet movements not represented on the input list). Experiment 3 replicated this finding with novel, randomly generated melodies. All three experiments supported substantial retention of information regarding pitch intervals, as well as contour, over a retention interval of several minutes. Using the materials of Experiment 3 in a short-term memory paradigm, Experiment 4 examined short (5 sec) and long (31 sec) retention interval conditions. Contour information dominated performance with the short delay, but not with the long delay, where performance resembled that of the prior long-term memory experiments. While interval information is difficult to encode, it is apparently retained with high efficiency in long-term memory.},
	journaltitle = {Psychomusicology: A Journal of Research in Music Cognition},
	shortjournal = {Psychomusicology: A Journal of Research in Music Cognition},
	author = {Dowling, Walter and Bartlett, James},
	date = {1981-01-01},
	file = {Full Text PDF:/Users/sebsilas/Zotero/storage/WSHGBDBT/Dowling and Bartlett - 1981 - The Importance of Interval Information in Long-ter.pdf:application/pdf},
}

@article{dewittRecognitionNovelMelodies1986,
	title = {Recognition of Novel Melodies after Brief Delays},
	volume = {3},
	issn = {0730-7829},
	url = {https://www.jstor.org/stable/40285336},
	doi = {10.2307/40285336},
	abstract = {Three experiments on the recognition of short melodies investigated the influence of contour and interval information (respectively, the pattern of changes in pitch direction and the ordered sequence of pitch distances in a melody). Subjects rated pairs of melodies as "same" or "different" on a five-point scale. Six conditions were defined by two delays (short, 1 sec; and long, 30 sec) and three item types (target, related, and lure). In Target pairs, the second melody retained the contour and interval information of the first melody, being an exact transposition to another key. In Related pairs, only the contour information was retained, while in the Lure pairs neither contour nor interval information was retained. In conformity with the reports of Dowling and Bartlett (1981), the results indicated that contour information had a larger influence on recognition at short delays, whereas interval information had a relatively larger influence at long delays. The results are also consistent with an alternative interpretation stressing the importance of tonality/modality information in melody recognition at long delays.},
	pages = {259--274},
	number = {3},
	journaltitle = {Music Perception: An Interdisciplinary Journal},
	author = {Dewitt, Lucinda A. and Crowder, Robert G.},
	urldate = {2022-01-28},
	date = {1986},
	note = {Publisher: University of California Press},
}

@article{dowlingTonalStrengthMelody1991,
	title = {Tonal strength and melody recognition after long and short delays},
	volume = {50},
	issn = {0031-5117},
	doi = {10.3758/bf03212222},
	abstract = {In a continuous-running-memory task, subjects heard novel seven-note melodies that were tested after delays of 11 sec (empty) or 39 sec (filled). Test items were transposed to new pitch levels (to moderately distant keys in the musical sense) and included exact transpositions (targets), same-contour lures with altered pitch intervals, and new-contour lures. Melodies differed in tonal strength (degree of conformity to a musical key) and were tonally strong, tonally weak, or atonal. False alarms to same-contour lures decreased over the longer delay period, but only for tonal stimuli. In agreement with previous studies, discrimination of detailed changes in pitch intervals improved with increased delay, whereas discrimination of more global contour information declined, again only for tonal stimuli. These results suggest that poor short-delay performance in rejecting same-contour lures arises from confusion that is based on the similarity of tonality between standard stimuli and lures. If a test item has the same contour and a similar tonality to a just-presented item, subjects tend to accept it. After a delay filled with melodies in other tonalities, the salience of key information recedes, and subjects base their judgments on more detailed pattern information (namely, exact pitch intervals). The fact that tonality affects judgments of melodic contour indicates that contour is not an entirely separable feature of melodies but rather that a melody with its contour constitutes an integrated perceptual whole.},
	pages = {305--313},
	number = {4},
	journaltitle = {Perception \& Psychophysics},
	shortjournal = {Percept Psychophys},
	author = {Dowling, W. J.},
	date = {1991-10},
	pmid = {1758762},
	keywords = {Humans, Music, Adult, Attention, Retention, Psychology, Pitch Discrimination, Mental Recall, Psychoacoustics},
	file = {Full Text:/Users/sebsilas/Zotero/storage/B3RDT3YJ/Dowling - 1991 - Tonal strength and melody recognition after long a.pdf:application/pdf},
}

@article{ouraMemoryMelodiesSubjects1988,
	title = {Memory for melodies among subjects differing in age and experience in music},
	volume = {16},
	issn = {1741-3087},
	doi = {10.1177/0305735688162001},
	abstract = {A total of 5 musically experienced and 9 inexperienced college students and 6 9–10 yr old children with about 5 yrs of piano training participated in 3 experiments to investigate storage and retrieval of a melody. In Exp 1, Ss learned an unfamiliar commercial song, which was presented auditorially and which they were required to reproduce by singing. Speed of acquisition and mastery of the melody were superior in the 2 experienced groups compared with the inexperienced group. Exp 2 indicated that experienced Ss' better performances in melodic memory were due to music domain-specific knowledge rather than general memory ability. Results of Exp 3 suggest that knowledge supporting memory of melodies was specific to tonal music. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {91--109},
	number = {2},
	journaltitle = {Psychology of Music},
	author = {Oura, Yoko and Hatano, Giyoo},
	date = {1988},
	note = {Place: {US}
Publisher: Sage Publications},
	keywords = {Music, Memory, Age Differences, Human Information Storage},
	file = {Snapshot:/Users/sebsilas/Zotero/storage/Z593ELYB/1989-21312-001.html:text/html},
}

@article{zielinskaMemorisingTwoMelodies1992,
	title = {Memorising two melodies of different style},
	volume = {20},
	issn = {1741-3087},
	doi = {10.1177/0305735692202001},
	abstract = {31 undergraduates at a music academy, 5 classified as having absolute pitch ({AP}) and 26 classified as not having {AP}, memorized 1 melody with a clear tonal structure and 1 melody based on a modal scale. The modal melody was more difficult for both groups, and the rhythm of the melodies caused more trouble in reproductions than pitch. The musical material and Ss' individual characteristics that were not controlled, not the possession of {AP} per se, influenced strategies of learning. Possession of {AP} did not modify the proportions of contour, interval and rhythm errors during melodic memorization of both melodies, though Ss with {AP} memorized both melodies faster than Ss without {AP}. Ss with {AP} also scored significantly better in retaining the key and storing pitch information when they recalled the melodies from long term memory. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {95--111},
	number = {2},
	journaltitle = {Psychology of Music},
	author = {Zielinska, Halina and Miklaszewski, Kacper},
	date = {1992},
	note = {Place: {US}
Publisher: Sage Publications},
	keywords = {Musical Ability, Memory, Pitch Discrimination, Learning Strategies},
	file = {Snapshot:/Users/sebsilas/Zotero/storage/CBWBT9CU/1993-16366-001.html:text/html},
}

@article{ogawaModificationMusicalSchema1995,
	title = {Modification of Musical Schema for Japanese Melody: A Study of Comprehensible and Memorable Melody},
	issn = {0010-9894},
	url = {https://www.jstor.org/stable/40318777},
	shorttitle = {Modification of Musical Schema for Japanese Melody},
	abstract = {The purpose of this study is to investigate differences in comprehensibility and memorability of melodies. This study examines the reference point employed by young people in Japan as they listen to Japanese traditional music using their musical schema. Two experiments were designed from the point of the difference of (a) musical experience, (b) musical stimuli, and (c) methodology in memory for melody research. In Experiment 1,44 high school students were required to make comprehensibility assessment task and recognition task In Experiment 2, 80 undergraduates were asked to listen to the same melodies as those prepared for Experiment 1, providing an attempt at sung recall The results show that the comprehensibility score was high for both mixed-schema melody that was constructed in mixed Japanese-Western tone and in-schema melody that was composed of typical Japanese tone. However, recognition probability scores of the music learner for in-schema melody were significantly lower than those for mixed-schema melody, in spite of the fact that the tones are confined within the in-schema form. On the other hand, in the recall task, musicians were usually able to perform with less errors and less trials for in-schema melody. These findings suggest that subjects vary in their reference point for comprehensibility and memorability depending on the melody pattern. They place their reference point for recognition only on the surface, however peculiar the pattern, whereas the reference point for recall task is placed on the deeper structural information underlying the input melodies.},
	pages = {136--141},
	number = {127},
	journaltitle = {Bulletin of the Council for Research in Music Education},
	author = {Ogawa, Yoko and Kimura, Tsugihiro and Mito, Hiromichi},
	urldate = {2022-01-28},
	date = {1995},
	note = {Publisher: University of Illinois Press},
}

@article{downieMusicInformationRetrieval2003,
	title = {Music information retrieval},
	volume = {37},
	issn = {1550-8382},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/aris.1440370108},
	doi = {10.1002/aris.1440370108},
	pages = {295--340},
	number = {1},
	journaltitle = {Annual Review of Information Science and Technology},
	author = {Downie, J. Stephen},
	urldate = {2022-01-28},
	date = {2003},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/aris.1440370108},
	file = {Snapshot:/Users/sebsilas/Zotero/storage/K5FKAJ27/aris.html:text/html},
}

@inproceedings{mullensiefenMelodicSimilarityApproaches2004,
	location = {{IL}},
	title = {Melodic similarity: approaches and applications},
	abstract = {This paper describes the systematization, testing and optimiziation of different approaches for measuring similarities of melodies. First, a quick overview of our mathematical systematization for similarity measures, including data transformations and calculation methods is given. Behavioral data from three listener experiments is used to model experts’ similarity judgments of short melodies from popular music in different contextual situations. A weighted combination of several similarity measures, representing two resp. three different sources of information, is found to explain user ratings best. As an application example one of the optimal similarity measures resulting from these three experiments is used to analyze a body of about 600 folk melodies from Luxembourg. Finally, the expert classification of the individual phrases of these melodies that has carried out in an extensive ethno-musicological study (Sagrillo, 1999) is reconstructed with the help of an optimal combination of similarity measures using logistic regression.},
	pages = {283--289},
	booktitle = {Proceedings of the 8th {ICMPC}},
	author = {Müllensiefen, Daniel and Frieler, Klaus},
	editor = {Lipscombe, S.D. and Ashley, R. and Gjerdingen, R.O. and Webster, P.},
	date = {2004},
	langid = {english},
	file = {Müllensiefen and Frieler - MELODIC SIMILARITY APPROACHES AND APPLICATIONS.pdf:/Users/sebsilas/Zotero/storage/CQZ78TYM/Müllensiefen and Frieler - MELODIC SIMILARITY APPROACHES AND APPLICATIONS.pdf:application/pdf},
}

@inproceedings{mullensiefenOptimizingMeasuresMelodic2004,
	location = {Barcelona},
	title = {Optimizing measures of melodic similarity for the explora-tion of a large folk song database},
	eventtitle = {{ISMIR} 2004, 5th International Conference on Music In-formation Retrieval, Barcelona, Spain, October 10-14, 2004, Proceedings.},
	author = {Müllensiefen, D and Frieler, K},
	date = {2004},
}

@article{mongeauComparisonMusicalSequences1990,
	title = {Comparison of Musical Sequences},
	volume = {24},
	issn = {0010-4817},
	url = {https://www.jstor.org/stable/30200223},
	abstract = {Concepts from the theory of sequence comparison are adapted to measure the overall similarity or dissimilarity between two musical scores. A key element is the notion of consolidation and fragmentation, different both from the deletions and insertions familiar in sequence comparison, and from the compressions and expansions of time warping in automatic speech recognition. The measure of comparison is defined so as to detect similarities in melodic line despite gross differences in key, mode or tempo. A dynamic programming algorithm is presented for calculating the measure, and is programmed and applied to a set of variations on a theme by Mozart. Cluster analysis and spatial representation of the results confirm subjective impressions of the patterns of similarities among the variations. A generalization of the algorithm is presented for detecting locally similar portions in two scores, and is then applied.},
	pages = {161--175},
	number = {3},
	journaltitle = {Computers and the Humanities},
	author = {Mongeau, Marcel and Sankoff, David},
	urldate = {2022-01-28},
	date = {1990},
	note = {Publisher: Springer},
}

@inproceedings{pfleidererPerceptionAccentsPop2006,
	title = {The perception of accents in pop music melodies.},
	eventtitle = {{ICMPC} 9 Proceedings},
	author = {Pfleiderer, M. and Müllensiefen, D},
	date = {2006},
}

@incollection{krumhanslTonalCognition2001,
	location = {New York, {NY}, {US}},
	title = {Tonal cognition},
	isbn = {978-1-57331-306-3 978-1-57331-307-0},
	series = {Annals of the New York Academy of Sciences},
	abstract = {This article presents a self-organizing map ({SOM}) neural network model of tonality based on experimentally quantified tonal hierarchies. A toroidal representation of key distances is recovered in which keys are located near their neighbors on the circle of fifths, and both parallel and relative major/minor key pairs are proximal. The map is used to represent dynamic changes in the sense of key as cues to key become more or less clear and modulations occur. Two models, one using tone distributions and the other using tone transitions, are proposed for key-finding. The tone transition model takes both pitch and temporal distance between tones into account. Both models produce results highly comparable to those of musically trained listeners, who performed a probe tone task for ten nine-chord sequences. A distributed mapping of tonality is used to visualize activation patterns that change over time. The location and spread of this activation pattern is similar for experimental results and the key-finding model. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {77--91},
	booktitle = {The biological foundations of music},
	publisher = {New York Academy of Sciences},
	author = {Krumhansl, Carol L. and Toiviainen, Petri},
	date = {2001},
	keywords = {Pitch Perception, Music Perception, Neural Networks, Pitch Discrimination, Models, Cognitive Processes, Human Information Storage},
	file = {Snapshot:/Users/sebsilas/Zotero/storage/ZVXL9J8L/2001-01491-006.html:text/html},
}

@article{shiffrinSevenMinusTwo1994,
	title = {Seven plus or minus two: A commentary on capacity limitations},
	volume = {101},
	issn = {1939-1471},
	doi = {10.1037/0033-295X.101.2.357},
	shorttitle = {Seven plus or minus two},
	abstract = {G. A. Miller's classic 1956 article (see {PA}, Vol 31:2914; see also {PA}, Vol 81:28291) is best known today for its discussion of capacity limitations in short-term memory, but the bulk of the article dealt with capacity limitations in absolute judgment tasks and the relation of such limitations to information theory. Many of the puzzles of absolute judgment first raised by Miller remain a puzzle today. Some of the literature directed toward this issue is reviewed, and a few models that attempt to elucidate the phenomena are discussed. Since 1956 there has been an enormous research effort aimed at understanding the mechanisms and limitations of short-term memory, resulting in considerable progress. The authors briefly discuss some of these advances. The authors conclude, as did Miller, by noting the probable lack of connection between the limitations observed in these 2 areas of inquiry. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {357--361},
	number = {2},
	journaltitle = {Psychological Review},
	author = {Shiffrin, Richard M. and Nosofsky, Robert M.},
	date = {1994},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Cognitive Processes, Human Channel Capacity, Information Theory},
	file = {Snapshot:/Users/sebsilas/Zotero/storage/RGFYVVWA/1994-28302-001.html:text/html},
}

@article{millerMagicalNumberSeven1956,
	title = {The magical number seven, plus or minus two: Some limits on our capacity for processing information},
	volume = {63},
	issn = {1939-1471},
	doi = {10.1037/h0043158},
	shorttitle = {The magical number seven, plus or minus two},
	abstract = {A variety of researches are examined from the standpoint of information theory. It is shown that the unaided observer is severely limited in terms of the amount of information he can receive, process, and remember. However, it is shown that by the use of various techniques, e.g., use of several stimulus dimensions, recoding, and various mnemonic devices, this informational bottleneck can be broken. 20 references. ({PsycInfo} Database Record (c) 2021 {APA}, all rights reserved)},
	pages = {81--97},
	number = {2},
	journaltitle = {Psychological Review},
	author = {Miller, George A.},
	date = {1956},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Cognitive Processes, Information Theory},
	file = {Snapshot:/Users/sebsilas/Zotero/storage/DR5WK2C9/1957-02914-001.html:text/html;Submitted Version:/Users/sebsilas/Zotero/storage/P5YA239F/Miller - 1956 - The magical number seven, plus or minus two Some .pdf:application/pdf},
}

@article{rosseelLavaanPackageStructural2012a,
	title = {lavaan: An R Package for Structural Equation Modeling},
	volume = {48},
	url = {https://www.jstatsoft.org/v48/i02/},
	pages = {1--36},
	number = {2},
	journaltitle = {Journal of Statistical Software},
	author = {Rosseel, Yves},
	date = {2012},
}

@article{silasAssociationsMusicTraining2022,
	title = {The associations between music training, musical working memory, and visuospatial working memory: an opportunity for causal modeling},
	volume = {39},
	issn = {0730-7829},
	url = {https://doi.org/10.1525/mp.2022.39.4.401},
	doi = {10.1525/mp.2022.39.4.401},
	shorttitle = {The associations between music training, musical working memory, and visuospatial working memory},
	abstract = {Prior research studying the relationship between music training ({MT}) and more general cognitive faculties, such as visuospatial working memory ({VSWM}), often fails to include tests of musical memory. This may result in causal pathways between {MT} and other such variables being misrepresented, potentially explaining certain ambiguous findings in the literature concerning the relationship between {MT} and executive functions. Here we address this problem using latent variable modeling and causal modeling to study a triplet of variables related to working memory: {MT}, musical working memory ({MWM}), and {VSWM}. The triplet framing allows for the potential application of d-separation (similar to mediation analysis) and V-structure search, which is particularly useful since, in the absence of expensive randomized control trials, it can test causal hypotheses using cross-sectional data. We collected data from 148 participants using a battery of {MWM} and {VSWM} tasks as well as a {MT} questionnaire. Our results suggest: 1) {VSWM} and {MT} are unrelated, conditional on {MWM}; and 2) by implication, there is no far transfer between {MT} and {VSWM} without near transfer. However, the data are unable to distinguish an unambiguous causal structure. We conclude by discussing the possibility of extending these models to incorporate more complex or cyclic effects.},
	pages = {401--420},
	number = {4},
	journaltitle = {Music Perception},
	shortjournal = {Music Perception},
	author = {Silas, Sebastian and Müllensiefen, Daniel and Gelding, Rebecca and Frieler, Klaus and Harrison, Peter M. C.},
	urldate = {2022-04-21},
	date = {2022-04-01},
	file = {Full Text PDF:/Users/sebsilas/Zotero/storage/EBWGRILD/Silas et al. - 2022 - The Associations Between Music Training, Musical W.pdf:application/pdf;Snapshot:/Users/sebsilas/Zotero/storage/2USNE25L/The-Associations-Between-Music-Training-Musical.html:text/html},
}

@inproceedings{chikhaouiLearningSongACTR2009,
	title = {Learning a Song: an {ACT}-R Model},
	shorttitle = {Learning a Song},
	abstract = {The way music is interpreted by the human brain is a very interesting topic, but also an intricate one. Although this domain has been studied for over a century, many gray areas remain in the understanding of music. Recent advances have enabled us to perform accurate measurements of the time taken by the human brain to interpret and assimilate a sound. Cognitive computing provides tools and development environments that facilitate human cognition simulation. {ACT}-R is a cognitive architecture which offers an environment for implementing human cognitive tasks. This project combines our understanding of the music interpretation by a human listener and the {ACT}-R cognitive architecture to build {SINGER}, a computerized simulation for listening and recalling songs. The results are similar to human experimental data. Simulation results also show how it is easier to remember short melodies than long melodies which require more trials to be recalled correctly.},
	eventtitle = {World Academy of Science, Engineering and Technology},
	booktitle = {World Academy of Science, Engineering and Technology 31 Proceedings},
	author = {Chikhaoui, Belkacem and Ene, Héì and Beaudoin, Mathieu and Pratte, Guillaume and Bellefeuille, Philippe and Laudares, Fernando},
	date = {2009},
	file = {Full Text PDF:/Users/sebsilas/Zotero/storage/JUA379SZ/Chikhaoui et al. - 2009 - Learning a Song an ACT-R Model.pdf:application/pdf},
}

@incollection{reiter-haasPredictingMusicRelistening2021,
	location = {New York, {NY}, {USA}},
	title = {Predicting Music Relistening Behavior Using the {ACT}-R Framework},
	isbn = {978-1-4503-8458-2},
	url = {https://doi.org/10.1145/3460231.3478846},
	abstract = {Providing suitable recommendations is of vital importance to improve the user satisfaction of music recommender systems. Here, users often listen to the same track repeatedly and appreciate recommendations of the same song multiple times. Thus, accounting for users’ relistening behavior is critical for music recommender systems. In this paper, we describe a psychology-informed approach to model and predict music relistening behavior that is inspired by studies in music psychology, which relate music preferences to human memory. We adopt a well-established psychological theory of human cognition that models the operations of human memory, i.e., Adaptive Control of Thought—Rational ({ACT}-R). In contrast to prior work, which uses only the base-level component of {ACT}-R, we utilize five components of {ACT}-R, i.e., base-level, spreading, partial matching, valuation, and noise, to investigate the effect of five factors on music relistening behavior: (i) recency and frequency of prior exposure to tracks, (ii) co-occurrence of tracks, (iii) the similarity between tracks, (iv) familiarity with tracks, and (v) randomness in behavior. On a dataset of 1.7 million listening events from Last.fm, we evaluate the performance of our approach by sequentially predicting the next track(s) in user sessions. We find that recency and frequency of prior exposure to tracks is an effective predictor of relistening behavior. Besides, considering the co-occurrence of tracks and familiarity with tracks further improves performance in terms of R-precision. We hope that our work inspires future research on the merits of considering cognitive aspects of memory retrieval to model and predict complex user behavior.},
	pages = {702--707},
	booktitle = {Fifteenth {ACM} Conference on Recommender Systems},
	publisher = {Association for Computing Machinery},
	author = {Reiter-Haas, Markus and Parada-Cabaleiro, Emilia and Schedl, Markus and Motamedi, Elham and Tkalcic, Marko and Lex, Elisabeth},
	urldate = {2022-05-27},
	date = {2021-09-13},
	keywords = {adaptive control thought-rational ({ACT}-R), cognition-inspired retrieval, human cognition, music prediction, psychology-informed recommender systems, relistening behavior, user modeling},
}

@article{kauffmanMemoryIntactMusic1989,
	title = {Memory for intact music works: The importance of music expertise and retention interval},
	volume = {8},
	issn = {2162-1535},
	doi = {10.1037/h0094235},
	shorttitle = {Memory for intact music works},
	abstract = {Examined the effects of music expertise and retention interval on memory for music. Expert and novice musicians and nonmusicians listened to pairs of musical excerpts under 2 conditions: a current phase, comprised of a number of standard/comparison-type trials, and a delayed phase, comprised of music excerpts played in later sessions compared with excerpts played in earlier sessions. Findings demonstrate that (1) music memory can be investigated in the context of intact music, (2) even nonmusicians possessed delayed memory ability for novel music well above the level of chance, (3) the outer limits of short-term memory for music did not conform well to data in the psychological literature with nonmusic stimuli, and (4) retention curves for different levels of music expertise were similar over time until one expertise level reached asymptote. ({PsycInfo} Database Record (c) 2020 {APA}, all rights reserved)},
	pages = {3--20},
	number = {1},
	journaltitle = {Psychomusicology: A Journal of Research in Music Cognition},
	author = {Kauffman, William H. and Carlsen, James C.},
	date = {1989},
	note = {Place: {US}
Publisher: Illinois State University},
	keywords = {Music, Memory, Experience Level, Retention},
	file = {Snapshot:/Users/sebsilas/Zotero/storage/6ZRBHDYA/1990-03541-001.html:text/html},
}

@article{bakerMeloSolCorpus2021,
	title = {{MeloSol} Corpus},
	volume = {16},
	doi = {10.18061/emr.v16i1.7645},
	abstract = {This data report introduces the {MeloSol} corpus, a collection of 783 Western, tonal monophonic melodies. I first begin by describing the overall structure of the corpus, then proceed to detail its contents as they would be helpful for researchers working in the field of computational musicology or music psychology. In order to contextualize the {MeloSol} corpus in relation to other corpora in the literature, I present descriptive statistics of the {MeloSol} corpus alongside the The Densmore Collection of Native American Song and The Essen Folk Song Collection. I suggest possible future uses of this corpus including extending research investigating Western tonality, perceptual experiments needing novel ecological stimuli, or work involving the musical generation of monophonic melodies in the style of Western tonal music.},
	pages = {106--113},
	journaltitle = {Empirical Musicology Review},
	shortjournal = {Empirical Musicology Review},
	author = {Baker, David},
	date = {2021-12-10},
	file = {Full Text:/Users/sebsilas/Zotero/storage/F3BH6E4H/Baker - 2021 - MeloSol Corpus.pdf:application/pdf},
}

@incollection{andersonFranSimulationModel1972,
	title = {Fran: A Simulation Model of Free Recall},
	volume = {5},
	url = {https://www.sciencedirect.com/science/article/pii/S0079742108604442},
	shorttitle = {Fran},
	abstract = {This chapter discusses fran—a simulation model of free recall. The basic free recall experiment with which one will be concerned involves the presentation to a subject (S) of a list of words, one word at a time. After seeing all the words in the list, the S is asked to recall them in any order one chooses. The experimental paradigm derives its name from the fact that the S is not constrained to recall items in a particular order. The free recall paradigm has recently attracted much research interest because of evidence indicating the strong influence of various types of conceptual organization upon the S's recall. This chapter outlines how several different strategies could be implemented in terms of {FRAN}'s mental mechanisms. The fact that these various strategies can be formulated in terms of {FRAN}'s machinery supports the assertion that {FRAN} models the structures and processes underlying human memory in general.},
	pages = {315--378},
	booktitle = {Psychology of Learning and Motivation},
	publisher = {Academic Press},
	author = {Anderson, John Robert},
	editor = {Bower, Gordon H.},
	urldate = {2022-05-28},
	date = {1972-01-01},
	langid = {english},
	doi = {10.1016/S0079-7421(08)60444-2},
	file = {ScienceDirect Snapshot:/Users/sebsilas/Zotero/storage/LHARVH5U/S0079742108604442.html:text/html},
}

@article{bakerModelingMelodicDictation2019,
	title = {Modeling Melodic Dictation},
	url = {https://digitalcommons.lsu.edu/gradschool_dissertations/4960},
	doi = {10.31390/gradschool_dissertations.4960},
	journaltitle = {{LSU} Doctoral Dissertations},
	author = {Baker, David},
	date = {2019-06-05},
	file = {"Modeling Melodic Dictation" by David John Baker:/Users/sebsilas/Zotero/storage/6R69SP8Q/4960.html:text/html},
}

@article{salakkaWhatMakesMusic2021,
	title = {What makes music memorable? Relationships between acoustic musical features and music-evoked emotions and memories in older adults},
	volume = {16},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0251692},
	doi = {10.1371/journal.pone.0251692},
	shorttitle = {What makes music memorable?},
	abstract = {Background and objectives Music has a unique capacity to evoke both strong emotions and vivid autobiographical memories. Previous music information retrieval ({MIR}) studies have shown that the emotional experience of music is influenced by a combination of musical features, including tonal, rhythmic, and loudness features. Here, our aim was to explore the relationship between music-evoked emotions and music-evoked memories and how musical features (derived with {MIR}) can predict them both. Methods Healthy older adults (N = 113, age ≥ 60 years) participated in a listening task in which they rated a total of 140 song excerpts comprising folk songs and popular songs from 1950s to 1980s on five domains measuring the emotional (valence, arousal, emotional intensity) and memory (familiarity, autobiographical salience) experience of the songs. A set of 24 musical features were extracted from the songs using computational {MIR} methods. Principal component analyses were applied to reduce multicollinearity, resulting in six core musical components, which were then used to predict the behavioural ratings in multiple regression analyses. Results All correlations between behavioural ratings were positive and ranged from moderate to very high (r = 0.46–0.92). Emotional intensity showed the highest correlation to both autobiographical salience and familiarity. In the {MIR} data, three musical components measuring salience of the musical pulse (Pulse strength), relative strength of high harmonics (Brightness), and fluctuation in the frequencies between 200–800 Hz (Low-mid) predicted both music-evoked emotions and memories. Emotional intensity (and valence to a lesser extent) mediated the predictive effect of the musical components on music-evoked memories. Conclusions The results suggest that music-evoked emotions are strongly related to music-evoked memories in healthy older adults and that both music-evoked emotions and memories are predicted by the same core musical features.},
	pages = {e0251692},
	number = {5},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Salakka, Ilja and Pitkäniemi, Anni and Pentikäinen, Emmi and Mikkonen, Kari and Saari, Pasi and Toiviainen, Petri and Särkämö, Teppo},
	urldate = {2022-05-28},
	date = {2021-05-14},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Music cognition, Memory, Music perception, Bioacoustics, Emotions, Elderly, Entropy, Regression analysis},
	file = {Full Text PDF:/Users/sebsilas/Zotero/storage/RA8SSB3W/Salakka et al. - 2021 - What makes music memorable Relationships between .pdf:application/pdf;Snapshot:/Users/sebsilas/Zotero/storage/I5ABRD6Y/article.html:text/html},
}

@article{ritterACTRCognitiveArchitecture2019,
	title = {{ACT}-R: A cognitive architecture for modeling cognition},
	volume = {10},
	issn = {1939-5086},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wcs.1488},
	doi = {10.1002/wcs.1488},
	shorttitle = {{ACT}-R},
	abstract = {{ACT}-R is a hybrid cognitive architecture. It is comprised of a set of programmable information processing mechanisms that can be used to predict and explain human behavior including cognition and interaction with the environment. We start by reviewing its history, which shapes its current form, contrasts and relates it to other architectures, and helps readers to anticipate where it is going. Based on this history, we then describe it as a theory of cognition that is realized as a computer program. After this, we briefly discuss tools for working with {ACT}-R, and also note several major accomplishments that have been gained by working with {ACT}-R in both basic and applied science, including summarizing some of the insights about human behavior. We conclude by discussing its future, which we believe will include adding emotions and physiology, increasing usability, and the use of nongenerative models. This article is categorized under: Computer Science {\textgreater} Artificial Intelligence Psychology {\textgreater} Reasoning and Decision Making Psychology {\textgreater} Theory and Methods},
	pages = {e1488},
	number = {3},
	journaltitle = {{WIREs} Cognitive Science},
	author = {Ritter, Frank E. and Tehranchi, Farnaz and Oury, Jacob D.},
	urldate = {2022-05-28},
	date = {2019},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wcs.1488},
	keywords = {{ACT}-R, cognitive architecture, human memory, modeling, simulation, unified theories of cognition},
	file = {Full Text PDF:/Users/sebsilas/Zotero/storage/6MYYI434/Ritter et al. - 2019 - ACT-R A cognitive architecture for modeling cogni.pdf:application/pdf;Snapshot:/Users/sebsilas/Zotero/storage/EAH2YZWD/wcs.html:text/html},
}

@inproceedings{okadaWhatMusicalAbility2021,
	title = {What is “musical ability” and how do we measure it?},
	eventtitle = {Music Cognition International Conference},
	booktitle = {Proceedings of the Future Directions of Music Cognition International Conference},
	author = {Okada, B.M and Slevc, Robert},
	date = {2021-03-06},
}

@book{krumhanslCognitiveFoundationsMusical1990,
	title = {Cognitive Foundations of Musical Pitch},
	isbn = {978-0-19-802215-2},
	abstract = {This book addresses the central problem of music cognition: how listeners' responses move beyond mere registration of auditory events to include the organization, interpretation, and remembrance of these events in terms of their function in a musical context of pitch and rhythm. Equally important, the work offers an analysis of the relationship between the psychological organization of music and its internal structure. Combining over a decade of original research on music cognition with an overview of the available literature, the work will be of interest to cognitive and physiological psychologists, psychobiologists, musicians, music researchers, and music educators. The author provides the necessary background in experimental methodology and music theory so that no specialized knowledge is required for following her major arguments.},
	pagetotal = {322},
	publisher = {Oxford University Press, {USA}},
	author = {Krumhansl, Carol},
	date = {1990-03-15},
	langid = {english},
	note = {Google-Books-{ID}: {aJDEVqyArr}4C},
	keywords = {Music / Instruction \& Study / General},
}

@article{berzWorkingMemoryMusic1995a,
	title = {Working Memory in Music: A Theoretical Model},
	volume = {12},
	issn = {0730-7829},
	url = {https://online.ucpress.edu/mp/article/12/3/353/61949/Working-Memory-in-Music-A-Theoretical-Model},
	doi = {10.2307/40286188},
	shorttitle = {Working Memory in Music},
	abstract = {Many psychologists have accepted a dual memory system with separate short-and long-term storage components. More recently, the concept of working memory, where short-term memory is composed of both storage and processing segments, has been considered. Baddeley (1990) proposes a model for working memory that includes a central executive controller along with two slave systems: the phonological loop and the visuospatial sketch pad. The model allows for both storage and manipulation of information. However, this model does not seem to account adequately for musical memory (Clarke, 1993). Through a review of relevant literature, a new model is proposed in which an additional slave system is added to the Baddeley model to account for musical information. Consideration of this kind of cognitive processing is important in understanding the significant demands placed on working memory in such activities as taking music dictation, where there would be a tradeoff between storage and processing functions.},
	pages = {353--364},
	number = {3},
	journaltitle = {Music Perception},
	shortjournal = {Music Perception},
	author = {Berz, William L.},
	urldate = {2022-06-07},
	date = {1995-04-01},
	langid = {english},
	note = {Publisher: University of California Press},
	file = {Snapshot:/Users/sebsilas/Zotero/storage/VQPFL8KU/Working-Memory-in-Music-A-Theoretical-Model.html:text/html},
}

@article{thalmannHowDoesChunking2019,
	title = {How does chunking help working memory?},
	volume = {45},
	issn = {1939-1285},
	doi = {10.1037/xlm0000578},
	abstract = {Chunking is the recoding of smaller units of information into larger, familiar units. Chunking is often assumed to help bypassing the limited capacity of working memory ({WM}). We investigate how chunks are used in {WM} tasks, addressing three questions: (a) Does chunking reduce the load on {WM}? Across four experiments chunking benefits were found not only for recall of the chunked but also of other not-chunked information concurrently held in {WM}, supporting the assumption that chunking reduces load. (b) Is the chunking benefit independent of chunk size? The chunking benefit was independent of chunk size only if the chunks were composed of unique elements, so that each chunk could be replaced by its first element (Experiment 1), but not when several chunks consisted of overlapping sets of elements, disabling this replacement strategy (Experiments 2 and 3). The chunk-size effect is not due to differences in rehearsal duration as it persisted when participants were required to perform articulatory suppression (Experiment 3). Hence, {WM} capacity is not limited to a fixed number of chunks regardless of their size. (c) Does the chunking benefit depend on the serial position of the chunk? Chunks in early list positions improved recall of other, not-chunked material, but chunks at the end of the list did not. We conclude that a chunk reduces the load on {WM} via retrieval of a compact chunk representation from long-term memory that replaces the representations of individual elements of the chunk. This frees up capacity for subsequently encoded material. ({PsycINFO} Database Record (c) 2018 {APA}, all rights reserved)},
	pages = {37--55},
	number = {1},
	journaltitle = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
	author = {Thalmann, Mirko and Souza, Alessandra S. and Oberauer, Klaus},
	date = {2019},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Short Term Memory, Human Channel Capacity, Chunking, Long Term Memory},
	file = {Accepted Version:/Users/sebsilas/Zotero/storage/FY8PNMXI/Thalmann et al. - 2019 - How does chunking help working memory.pdf:application/pdf;Snapshot:/Users/sebsilas/Zotero/storage/GXGR5UXM/2018-18179-001.html:text/html},
}

@article{dowlingContourIntervalPitch1971,
	title = {Contour, interval, and pitch recognition in memory for melodies},
	volume = {49},
	issn = {0001-4966},
	doi = {10.1121/1.1912382},
	abstract = {Demonstrated the role of melodic contour recognition in memory for melodies. Exp. I with 47 undergraduates as Ss (2 * 3 factorial design), involved short-term memory with comparison melodies either transposed or not transposed from the key of the standard. Separate groups had the tasks of distinguishing (a) between same and different melodies, (b) between some melodies and ones with only the same contour, and (c) between melodies with the same contour and different ones. The effects of transposition and task and their interaction were significant (p {\textless} .001). Untransposed melodies were recognized by their exact pitches, so that tasks a and b were equally easy. Contour recognition was more important with transposed melodies, so that task b was very difficult, and tasks a and c were easier. Task c was about equally difficult under both conditions. Exp. {II} with 28 undergraduates, involved recognition of distorted versions of familiar folktunes having the same length and rhythmic structure. In ascending order of recognizability, these distortions preserved merely the harmonic basis of the melody, the melodic contour, and the contour plus the relative sizes of successive intervals between notes (chi-square = 50.4, p {\textless} .001). ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {524--531},
	number = {2},
	journaltitle = {Journal of the Acoustical Society of America},
	author = {Dowling, W. J. and Fujitani, Diane S.},
	date = {1971},
	note = {Place: {US}
Publisher: Acoustical Society of American},
	keywords = {Music, Auditory Perception, Short Term Memory, Recognition (Learning), Interstimulus Interval},
}

@article{nakagawaGeneralSimpleMethod2013,
	title = {A general and simple method for obtaining R2 from generalized linear mixed-effects models},
	volume = {4},
	issn = {2041-210X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2041-210x.2012.00261.x},
	doi = {10.1111/j.2041-210x.2012.00261.x},
	abstract = {The use of both linear and generalized linear mixed-effects models ({LMMs} and {GLMMs}) has become popular not only in social and medical sciences, but also in biological sciences, especially in the field of ecology and evolution. Information criteria, such as Akaike Information Criterion ({AIC}), are usually presented as model comparison tools for mixed-effects models. The presentation of ‘variance explained’ (R2) as a relevant summarizing statistic of mixed-effects models, however, is rare, even though R2 is routinely reported for linear models ({LMs}) and also generalized linear models ({GLMs}). R2 has the extremely useful property of providing an absolute value for the goodness-of-fit of a model, which cannot be given by the information criteria. As a summary statistic that describes the amount of variance explained, R2 can also be a quantity of biological interest. One reason for the under-appreciation of R2 for mixed-effects models lies in the fact that R2 can be defined in a number of ways. Furthermore, most definitions of R2 for mixed-effects have theoretical problems (e.g. decreased or negative R2 values in larger models) and/or their use is hindered by practical difficulties (e.g. implementation). Here, we make a case for the importance of reporting R2 for mixed-effects models. We first provide the common definitions of R2 for {LMs} and {GLMs} and discuss the key problems associated with calculating R2 for mixed-effects models. We then recommend a general and simple method for calculating two types of R2 (marginal and conditional R2) for both {LMMs} and {GLMMs}, which are less susceptible to common problems. This method is illustrated by examples and can be widely employed by researchers in any fields of research, regardless of software packages used for fitting mixed-effects models. The proposed method has the potential to facilitate the presentation of R2 for a wide range of circumstances.},
	pages = {133--142},
	number = {2},
	journaltitle = {Methods in Ecology and Evolution},
	author = {Nakagawa, Shinichi and Schielzeth, Holger},
	urldate = {2022-07-18},
	date = {2013},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.2041-210x.2012.00261.x},
	keywords = {heritability, coefficient of determination, goodness-of-fit, information criteria, intra-class correlation, linear models, model fit, repeatability, variance explained},
	file = {Full Text PDF:/Users/sebsilas/Zotero/storage/VS84YCLK/Nakagawa and Schielzeth - 2013 - A general and simple method for obtaining R2 from .pdf:application/pdf},
}

@article{pearceMullensiiefen2017,
	title = {Compression-based modelling of musical similarity perception},
	volume = {46},
	url = {https://doi.org/10.1080/09298215.2017.1305419},
	doi = {10.1080/09298215.2017.1305419},
	pages = {135--155},
	number = {2},
	journaltitle = {Journal of New Music Research},
	author = {Pearce, Marcus and Müllensiefen, Daniel},
	date = {2017},
	note = {Publisher: Routledge
tex.eprint: https://doi.org/10.1080/09298215.2017.1305419},
}

@article{mullensiefenCourtDecisionsMusic2009,
	title = {Court decisions on music plagiarism and the predictive value of similarity algorithms},
	volume = {13},
	issn = {1029-8649},
	url = {https://doi.org/10.1177/102986490901300111},
	doi = {10.1177/102986490901300111},
	abstract = {Tune plagiarism in pop music is a common and often feverishly debated phenomenon which surely has to do with the vast amounts of money that individual melodies are able to generate in today's pop music business. The similarity between melodies is assumed to be a very important factor in a court's decision about whether a new tune is an illegitimate version of a pre-existing melody. Despite the wide-spread belief that there is a fixed and simple limit to the number of corresponding notes between two melodies, actual court decisions are based on far more complex considerations regarding the musical material., This paper first sketches the legal framework and principal features of the legal processing of cases of alleged melodic plagiarism with a focus on {US} copyright law and discusses selected cases to highlight the corresponding legal practices. In the empirical part of this paper, we model court decisions for cases of alleged melodic plagiarism employing a number of similarity algorithms. As a ground truth dataset we use a collection of 20 publicly available cases from the last 30 years of {US} jurisdiction. We compare the performance of standard similarity algorithms (edit distance and n-gram similarity measures) to several new similarity algorithms that make use of statistical information about the prevalence of chains of pitch intervals in a large pop music database. Results indicate that these statistically informed algorithms generally outperform the comparison algorithms. In particular, algorithms based on Tversky's (1977) concept of similarity show a high performance of up to 90\% of court decisions correctly predicted. We discuss the performance and structure of the algorithms in relation to a few interesting example cases and give an outlook on the potential and intricacies of our approach.},
	pages = {257--295},
	number = {1},
	journaltitle = {Musicae Scientiae},
	shortjournal = {Musicae Scientiae},
	author = {Müllensiefen, Daniel and Pendzich, Marc},
	urldate = {2022-07-22},
	date = {2009-03-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Ltd},
	keywords = {melodic similarity, music copyright, plagiarism, similarity algorithms, Tversky's similarity model},
	file = {SAGE PDF Full Text:/Users/sebsilas/Zotero/storage/LJNLD7E3/Müllensiefen and Pendzich - 2009 - Court decisions on music plagiarism and the predic.pdf:application/pdf},
}

@book{longLongitudinalDataAnalysis2011,
	title = {Longitudinal Data Analysis for the Behavioral Sciences Using R},
	isbn = {978-1-4833-4155-2},
	abstract = {This book is unique in its focus on showing students in the behavioral sciences how to analyze longitudinal data using R software. The book focuses on application, making it practical and accessible to students in psychology, education, and related fields, who have a basic foundation in statistics. It provides explicit instructions in R computer programming throughout the book, showing students exactly how a specific analysis is carried out and how output is interpreted.},
	pagetotal = {569},
	publisher = {{SAGE} Publications},
	author = {Long, Jeffrey D.},
	date = {2011-10-31},
	langid = {english},
	note = {Google-Books-{ID}: {RyFzAwAAQBAJ}},
	keywords = {Social Science / Research, Reference / Research},
}

@article{murdockjr.ImmediateRetentionUnrelated1960,
	title = {The immediate retention of unrelated words},
	volume = {60},
	issn = {0022-1015},
	doi = {10.1037/h0045145},
	abstract = {"For the experiments on free-recall verbal learning a standard procedure and a standard method of fitting the exponential were used; normative data and data on reliability were presented. It was shown that there was no learning-how-to-learn or warm-up effect. Also, there was no difference between visual and auditory presentation or between individual and group testing. Learning was found to be a linear function of log frequency of usage… . it was possible to predict the learning of a list with a fair degree of accuracy given its length and presentation time." (19 ref.) ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {222--234},
	number = {4},
	journaltitle = {Journal of Experimental Psychology},
	author = {Murdock Jr., Bennet B.},
	date = {1960},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Verbal Learning, Recall (Learning), Retention, Words (Phonetic Units)},
	file = {Snapshot:/Users/sebsilas/Zotero/storage/GK49PH7S/1961-04456-001.html:text/html},
}

@article{typkeTransportationDistancesHuman2007,
	title = {Transportation distances and human perception of melodic similarity},
	volume = {11},
	issn = {1029-8649},
	url = {https://doi.org/10.1177/102986490701100107},
	doi = {10.1177/102986490701100107},
	abstract = {This article describes how transportation distances such as the Earth Mover's Distance can be used for measuring melodic similarity for notated music. We represent music notation as weighted point sets in a two-dimensional space of onset time and pitch. The Earth Mover's Distance can then be used for comparing point sets by determining how much work it would take to convert one of the point sets into the other by moving weight between the point sets., For evaluating how well this method and other methods agree with human perception of melodic similarity, we established a ground truth for the {RISM} A/{II} collection based on the opinions of human experts., The {RISM} A/{II} collection contains about half a million musical incipits. For 22 queries, we filtered the collection so that about 50 candidates per query were left, each of which we then presented to about 30 human experts (out of a group of 37 experts) for a final ranking. We present our filtering methods, the experiment design, the resulting ground truth, and a new measure (called “Average Dynamic Recall”) that can be used for comparing different similarity measures with the ground truth.},
	pages = {153--181},
	number = {1},
	journaltitle = {Musicae Scientiae},
	shortjournal = {Musicae Scientiae},
	author = {Typke, Rainer and Wiering, Frans and Veltkamp, Remco C.},
	urldate = {2022-08-03},
	date = {2007-03-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Ltd},
	file = {SAGE PDF Full Text:/Users/sebsilas/Zotero/storage/K35589I5/Typke et al. - 2007 - Transportation distances and human perception of m.pdf:application/pdf},
}

@misc{yuanPerceptualVsAutomated2020,
	title = {Perceptual vs. automated judgments of music copyright infringement},
	url = {https://psyarxiv.com/tq7v5/},
	doi = {10.31234/osf.io/tq7v5},
	abstract = {Music copyright lawsuits often result in multimillion dollar damage awards or settlements, yet there are few objective guidelines for applying copyright law in infringement claims involving musical works. Recent re-search has attempted to develop objective methods based on automated similarity algorithms, but there remains almost no data on the role of perceived similarity in mu-sic copyright decisions despite its crucial role in copy-right law. We collected perceptual data from 20 participants for 17 adjudicated copyright cases from the {USA} and Japan after editing the disputed sections to contain either full audio, melody only, or lyrics only. Due to the historical emphasis in legal opinions on melody as the key criterion for deciding infringement, we predicted that listening to melody-only versions would result in perceptual judgements that more closely matched actual past legal decisions. Surprisingly, however, we found no significant differences between the three conditions, with participants matching past decisions in between 50-60\% of cases in all three conditions. Automated algorithms designed to calculate melodic and audio similarity produced comparable results: both algorithms were able to match past decisions with identical accuracy of 71\% (12/17 cases). Analysis of cases that were difficult to classify suggests that melody, lyrics, and other factors sometimes interact in complex ways difficult to capture using quantitative metrics. We propose directions for further investigation of the role of similarity in music copy-right law using larger and more diverse samples of cases and enhanced methods, and adapting our perceptual experiment method to avoid relying for ground truth data only on court decisions (which may be subject to selection bias). Our results contribute to important practical debates, such as whether jury members should be allowed to listen to full audio recordings during copyright cases.},
	publisher = {{PsyArXiv}},
	author = {Yuan, Yuchen and Oishi, Sho and Cronin, Charles and Müllensiefen, Daniel and Atkinson, Quentin and Fujii, Shinya and Savage, Patrick E.},
	urldate = {2022-08-03},
	date = {2020-07-10},
	langid = {english},
	keywords = {Music, Social and Behavioral Sciences},
	file = {Full Text PDF:/Users/sebsilas/Zotero/storage/JI7ZIYK4/Yuan et al. - 2020 - Perceptual vs. automated judgments of music copyri.pdf:application/pdf},
}

@article{gobetChunkingModelsExpertise2005,
	title = {Chunking models of expertise: implications for education},
	volume = {19},
	issn = {1099-0720},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/acp.1110},
	doi = {10.1002/acp.1110},
	shorttitle = {Chunking models of expertise},
	abstract = {Chunking models offer a parsimonious explanation of how people acquire knowledge and have been validated in domains such as expert behaviour and the acquisition of language. In this paper, we review two computational theories based on chunking mechanisms (the chunking theory and the template theory) and show what insight they offer for instruction and training. The suggested implications include the importance of perception in learning, the cost of acquiring knowledge, the significance of segmenting and ordering instruction material, the role of the variability of the instructional material in acquiring schemata, and the importance of taking individual differences into account. Copyright © 2005 John Wiley \& Sons, Ltd.},
	pages = {183--204},
	number = {2},
	journaltitle = {Applied Cognitive Psychology},
	author = {Gobet, Fernand},
	urldate = {2022-08-04},
	date = {2005},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/acp.1110},
	file = {Full Text PDF:/Users/sebsilas/Zotero/storage/UFBFJYAC/Gobet - 2005 - Chunking models of expertise implications for edu.pdf:application/pdf;Snapshot:/Users/sebsilas/Zotero/storage/JN56HS85/acp.html:text/html},
}

@article{gobetChunkingMechanismsHuman2001,
	title = {Chunking mechanisms in human learning},
	volume = {5},
	issn = {1364-6613},
	url = {https://www.sciencedirect.com/science/article/pii/S1364661300016624},
	doi = {10.1016/S1364-6613(00)01662-4},
	abstract = {Pioneering work in the 1940s and 1950s suggested that the concept of ‘chunking’ might be important in many processes of perception, learning and cognition in humans and animals. We summarize here the major sources of evidence for chunking mechanisms, and consider how such mechanisms have been implemented in computational models of the learning process. We distinguish two forms of chunking: the first deliberate, under strategic control, and goal-oriented; the second automatic, continuous, and linked to perceptual processes. Recent work with discrimination-network computational models of long- and short-term memory ({EPAM}/{CHREST}) has produced a diverse range of applications of perceptual chunking. We focus on recent successes in verbal learning, expert memory, language acquisition and learning multiple representations, to illustrate the implementation and use of chunking mechanisms within contemporary models of human learning.},
	pages = {236--243},
	number = {6},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Gobet, Fernand and Lane, Peter C. R. and Croker, Steve and Cheng, Peter C-H. and Jones, Gary and Oliver, Iain and Pine, Julian M.},
	urldate = {2022-08-04},
	date = {2001-06-01},
	langid = {english},
	keywords = {chunking, expertise, discrimination networks, language, learning, multiple representations},
	file = {ScienceDirect Snapshot:/Users/sebsilas/Zotero/storage/RKN5PBEB/S1364661300016624.html:text/html},
}

@article{clementeSet200Musical2020,
	title = {A Set of 200 Musical Stimuli Varying in Balance, Contour, Symmetry, and Complexity: Behavioral and Computational Assessments},
	volume = {52},
	issn = {1554-3528},
	url = {https://doi.org/10.3758/s13428-019-01329-8},
	doi = {10.3758/s13428-019-01329-8},
	shorttitle = {A Set of 200 Musical Stimuli Varying in Balance, Contour, Symmetry, and Complexity},
	abstract = {We present a novel set of 200 Western tonal musical stimuli ({MUST}) to be used in research on perception and appreciation of music. It consists of four subsets of 50 stimuli varying in balance, contour, symmetry, or complexity. All are 4 s long and designed to be musically appealing and experimentally controlled. We assessed them behaviorally and computationally. The behavioral assessment (Study 1) aimed to determine whether musically untrained participants could identify variations in each attribute. Forty-three participants rated the stimuli in each subset on the corresponding attribute. We found that inter-rater reliability was high and that the ratings mirrored the design features well. Participants’ ratings also served to create an abridged set of 24 stimuli per subset. The computational assessment (Study 2) required the development of a specific battery of computational measures describing the structural properties of each stimulus. We distilled nonredundant composite measures for each attribute and examined whether they predicted participants’ ratings. Our results show that the composite measures indeed predicted participants’ ratings. Moreover, the composite complexity measure predicted complexity ratings as well as existing models of musical complexity. We conclude that the four subsets are suitable for use in studies that require presenting participants with short musical motifs varying in balance, contour, symmetry, or complexity, and that the stimuli and the computational measures are valuable resources for research in music psychology, empirical aesthetics, music information retrieval, and musicology. The {MUST} set and {MATLAB} toolbox codifying the computational measures are freely available at osf.io/bfxz7.},
	pages = {1491--1509},
	number = {4},
	journaltitle = {Behavior Research Methods},
	shortjournal = {Behav Res},
	author = {Clemente, Ana and Vila-Vidal, Manel and Pearce, Marcus T. and Aguiló, Germán and Corradi, Guido and Nadal, Marcos},
	urldate = {2022-10-21},
	date = {2020-08-01},
	langid = {english},
	keywords = {aesthetics, balance, complexity, contour, {MIR}, music, symmetry},
	file = {Full Text PDF:/Users/sebsilas/Zotero/storage/P28E2DH5/Clemente et al. - 2020 - A Set of 200 Musical Stimuli Varying in Balance, C.pdf:application/pdf},
}

@book{herbornFeaturesPerceptionConstruction2022,
	title = {Features Of The Perception And Construction Of Melodies},
	isbn = {978-3-03836-051-3},
	abstract = {Most people in the Western world listen to music because of emotions. They want to create or experience emotions. But music is made of tones, tones are sound waves and sound waves are physics.How is it possible that physics becomes psychology, because emotions are a psychological phenomenon?When people like a certain piece of music, they usually want to listen to it again and again. Not infrequently for years and decades.What could be the reasons for this?When people like a piece of music, it is primarily the melody that they like. For most people, the melody is the face of a piece. More than anything else, it is the element of music they remember.What are the characteristics of melodies that make them to be remembered by listeners?What features of the melody could it be that ensure being liked by listeners?Based on more than 300 keywords, over 160 musical examples, and 39 charts, answers to these and many other questions are sought and offered in this book.This book is always two-in-one. By illuminating how melodies are built that enjoy great popularity, it is a book of music theory. In this way, it addresses readers who are primarily interested in the book because they themselves invent melodies. By illuminating what psychological mechanisms and physiological responses trigger the melodic operations of composers and improvisers, it is an introduction to music psychological thinking. It combines fundamental considerations from cognitive science, psychology, anthropology, and linguistics. Thus, it is addressed not only to music theorists and musicologists, but ultimately to all readers who wish to expand their knowledge of how melodies work.},
	pagetotal = {986},
	publisher = {Emanobooks},
	author = {Herborn, Peter},
	date = {2022},
	langid = {english},
	note = {Google-Books-{ID}: D7x8EAAAQBAJ},
	keywords = {Music / Musical Instruments / General},
}

@thesis{uitdenbogerdMusicInformationRetrieval2002,
	title = {Music Information Retrieval Technology},
	url = {http://www.pampalk.at/mir-phds/abstract/Uitdenbogerd2002.html},
	type = {phdthesis},
	author = {Uitdenbogerd, Alexandra},
	urldate = {2022-11-10},
	date = {2002},
	file = {MIR PhD Thesis\: Alexandra L. Uitdenbogerd (2002):/Users/sebsilas/Zotero/storage/8GUYTP86/Uitdenbogerd2002.html:text/html},
}

@thesis{kohMemoryLearningMusic2002,
	title = {Memory and Learning In Music Reproduction: The Effects of Melodic Structure, Perceptual Cues and Learning methods on Music Recall},
	type = {phdthesis},
	author = {Koh, Christine},
	date = {2002},
}

@inproceedings{mullensiefenEvaluatingDifferentApproaches2006,
	location = {Berlin, Heidelberg},
	title = {Evaluating Different Approaches to Measuring the Similarity of Melodies},
	isbn = {978-3-540-34416-2},
	doi = {10.1007/3-540-34416-0_32},
	series = {Studies in Classification, Data Analysis, and Knowledge Organization},
	abstract = {This paper describes an empirical approach to evaluating similarity measures for the comparision of two note sequences or melodies. In the first sections the experimental approach and the empirical results of previous studies on melodic similarity are reported. In the discussion section several questions are raised that concern the nature of similarity or distance measures for melodies and musical material in general. The approach taken here is based on an empirical comparision of a variety of similarity measures with experimentally gathered rating data from human music experts. An optimal measure is constructed on the basis of a linear model.},
	pages = {299--306},
	booktitle = {Data Science and Classification},
	publisher = {Springer},
	author = {Müllensiefen, Daniel and Frieler, Klaus},
	editor = {Batagelj, Vladimir and Bock, Hans-Hermann and Ferligoj, Anuška and Žiberna, Aleš},
	date = {2006},
	langid = {english},
	keywords = {Folk Song, Music Information Retrieval, Music Research, Pitch Error, Similarity Measure},
	file = {Submitted Version:/Users/sebsilas/Zotero/storage/7QC42DVS/Müllensiefen and Frieler - 2006 - Evaluating Different Approaches to Measuring the S.pdf:application/pdf},
}

@book{hallamMusicEducation21st2010,
	title = {Music Education in the 21st Century in the United Kingdom: Achievements, Analysis and Aspirations},
	isbn = {978-0-85473-899-1},
	shorttitle = {Music Education in the 21st Century in the United Kingdom},
	abstract = {The landscape of music education in the {UK} is constantly shifting and developing. This book provides a timely and unique overview of this restless sector by considering the achievements of music education, analysing its current performance and setting out aspirations for the future. "Music Education in the 21st Century in the United Kingdom" addresses the power of music to influence and change human behaviour, analyses current and future issues in music education and casts a spotlight on particular areas of education, including early years, the primary school, the secondary school, further education, universities and conservatoires, music services, the music studio and the role of music leaders and community musicians. Written by experts in the field of music education, the book provides an authoritative account of the current status of music education in the {UK}. While essential to understand the current and future context in the {UK}, the book will be invaluable to those involved in music education internationally, as it includes chapters on the provision of music education for all children, listening, the role of singing, playing an instrument, creativity, the role of technology, issues of performance and assessment, learning through the lifespan and the initial and ongoing education of music teachers. It also includes a range of case study examples and evaluations of practice. The book is a landmark publication in the field of music education and will be essential reading for policy-makers, practitioners, music students, trainee music teachers and those who provide music services in the {UK} and internationally. This book contains three parts. Part I, "Introduction", contains: (1) The power of music: its impact on the intellectual, personal and social development of children and young people (Susan Hallam); and (2) Contextualising music education in the {UK} (Pauline Adams, Hilary {McQueen}, and Susan Hallam). Part 2, "Current Issues in Music Education", contains: (3) Music for all (Graham Welch and Adam Ockelford); (4) Listening (Susan Hallam); (5) The role of singing (Jo Saunders, Maria Varvarigou and Graham Welch); (6) Learning to play an instrument (Susan Hallam and Andrea Creech); (7) Creativity (Susan Hallam and Lynne Rogers); (8) The role of technology (Evangelos Himonides and Ross Purves); (9) Issues of assessment and performance (Ioulia Papageorgi and Susan Hallam); (10) Learning through life (Hilary {McQueen} and Maria Varvarigou); and (11) The initial and ongoing education of music teachers (Colin Durrant and Kate Laurence). Part 3, "Contexts of Learning", contains: (12) Music in the early years (Andrea Creech and Jessica Ellison); (13) Music in the primary school (Jessica Ellison and Andrea Creech); (14) Music in the secondary school (Hilary {McQueen} and Susan Hallam); (15) Music in further education colleges (John Conlon and Lynne Rogers); (16) Music in universities and conservatoires (Helena Gaunt and Ioulia Papageorgi); (17) Music Services (Lynne Rogers and Susan Hallam); (18) The music studio (Andrea Creech); (19) The role of music leaders and community musicians (Andrea Creech); and (20) Where now? (Susan Hallam and Andrea Creech). This book also contains: Acknowledgements; Preface; Notes on contributors; and Index.},
	publisher = {Institute of Education - London},
	author = {Hallam, Susan and Creech, Andrea Ed},
	urldate = {2022-11-11},
	date = {2010-07},
	langid = {english},
	note = {Publication Title: Institute of Education - London
{ERIC} Number: {ED}513294},
	keywords = {Musicians, Music Education, Performance, Singing, Evaluation, Musical Instruments, Listening, Adult Education, Creativity, Early Childhood Education, Educational Trends, Elementary Education, Foreign Countries, Futures (of Society), Higher Education, Individual Development, Inservice Teacher Education, Intellectual Development, Leaders, Lifelong Learning, Music Teachers, Preservice Teacher Education, Secondary Education, Social Development, Technology Uses in Education},
	file = {Snapshot:/Users/sebsilas/Zotero/storage/BXCIHWEI/eric.ed.gov.html:text/html},
}

@article{burenWhatMakesChild2021,
	title = {What makes a child musical? conceptions of musical ability in childhood},
	volume = {191},
	issn = {0300-4430},
	url = {https://doi.org/10.1080/03004430.2020.1866566},
	doi = {10.1080/03004430.2020.1866566},
	shorttitle = {What makes a child musical?},
	abstract = {Tests of musical ability in children have relied on diverse conceptions of what musical abilities are. Recent investigations suggest that such conceptions can be seen as socially constructed and differ between cultures, sub-groups, and individuals. Based on a previous study on conceptions of adult musical ability, we designed a questionnaire targeting musical behaviours of 3–6-year-old children. 922 German adults who regularly spend time with children assessed how often a musical child would show these behaviours. Principal component analysis revealed four components of childhood musical ability: musical communication, enthusiasm and motivation, analytical understanding of music, and musical abilities in a narrow sense. The importance assigned to the components differed depending on musical expertise: Participants with higher expertise rated analytical music skills as significantly less important. Results suggest that ecologically valid tests of musical ability in childhood should cover a wide range of skills and observable behaviours.},
	pages = {1985--2000},
	number = {12},
	journaltitle = {Early Child Development and Care},
	author = {Buren, Verena and Müllensiefen, Daniel and Roeske, Tina and Degé, Franziska},
	urldate = {2022-11-11},
	date = {2021-09-10},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/03004430.2020.1866566},
	keywords = {children’s musical skills, Conceptions of musical ability, development of musical ability, musicality, survey},
	file = {Full Text:/Users/sebsilas/Zotero/storage/P6Y86C28/Buren et al. - 2021 - What makes a child musical conceptions of musical.pdf:application/pdf},
}

@article{sturmClassificationAccuracyNot2013,
	title = {Classification accuracy is not enough},
	volume = {41},
	issn = {1573-7675},
	url = {https://doi.org/10.1007/s10844-013-0250-y},
	doi = {10.1007/s10844-013-0250-y},
	abstract = {We argue that an evaluation of system behavior at the level of the music is required to usefully address the fundamental problems of music genre recognition ({MGR}), and indeed other tasks of music information retrieval, such as autotagging. A recent review of works in {MGR} since 1995 shows that most (82 \%) measure the capacity of a system to recognize genre by its classification accuracy. After reviewing evaluation in {MGR}, we show that neither classification accuracy, nor recall and precision, nor confusion tables, necessarily reflect the capacity of a system to recognize genre in musical signals. Hence, such figures of merit cannot be used to reliably rank, promote or discount the genre recognition performance of {MGR} systems if genre recognition (rather than identification by irrelevant confounding factors) is the objective. This motivates the development of a richer experimental toolbox for evaluating any system designed to intelligently extract information from music signals.},
	pages = {371--406},
	number = {3},
	journaltitle = {Journal of Intelligent Information Systems},
	shortjournal = {J Intell Inf Syst},
	author = {Sturm, Bob L.},
	urldate = {2023-04-20},
	date = {2013-12-01},
	langid = {english},
	keywords = {Music, Evaluation, Classification, Genre},
	file = {Full Text PDF:/Users/sebsilas/Zotero/storage/C3L4GJIA/Sturm - 2013 - Classification accuracy is not enough.pdf:application/pdf},
}

@article{coxMimeticHypothesisEmbodied2001,
	title = {The Mimetic Hypothesis and Embodied Musical Meaning},
	volume = {5},
	issn = {1029-8649},
	url = {https://doi.org/10.1177/102986490100500204},
	doi = {10.1177/102986490100500204},
	abstract = {Research into the bodily basis of musical meaning has focused on conceptual metaphor and image schemata, but the processes whereby embodied experience becomes relevant to music conceptualization remains largely unexplained. This paper offers an account of music conceptualization that helps explain how embodied experience motivates and constrains the formation of basic musical meaning.The core of the ?mimetic hypothesis? holds that 1) we understand sounds in comparison to sounds we have made ourselves, and that 2) this process of comparison involves tacit imitation, or mimetic participation, which in turn draws on the prior embodied experience of sound production. Evidence for the hypothesis comes from developmental and neuropsychological studies, and from speech imagery, motor imagery, and musical imagery studies. The embodied experience activated during mimetic participation motivates and constrains the cross-domain mappings on which so many musical concepts depend. For example, the metaphoric concept of musical verticality cannot be accounted for without acknowledging the role of mimetic participation. If this participation is as fundamental to musical experience as the hypothesis suggests, not only will it allow us to account for music's most fundamental concepts, but it will also help account for the affective features of musical experience and meaning. Furthermore, the proposed view of mimetic participation helps establish a physical grounding for theories of musical gesture, semiotics, music and gender, music and drama, aural skills pedagogy, music and society, music and dance, and music therapy.},
	pages = {195--212},
	number = {2},
	journaltitle = {Musicae Scientiae},
	author = {Cox, Arnie},
	urldate = {2023-04-20},
	date = {2001-09-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Ltd},
}

@article{silasMemorabilitySonicLogos2023,
	title = {The memorability of sonic logos: a multi-paradigm approach},
	journaltitle = {In prep.},
	author = {Silas, Sebastian and Robinson, Megan and Baker, David and Müllensiefen, Daniel and Harrison, Peter and Jacoby, Nori},
	date = {2023},
}

@article{dowlingRecognitionMelodicTransformations1972,
	title = {Recognition of melodic transformations: Inversion, retrograde, and retrograde inversion},
	volume = {12},
	issn = {1532-5962},
	url = {https://doi.org/10.3758/BF03205852},
	doi = {10.3758/BF03205852},
	shorttitle = {Recognition of melodic transformations},
	abstract = {The melodic transformations of inversion, retrograde, and retrograde inversion occur in pieces of music. An important question is whether such manipulations of melodic material are perceptually accessible to the listener. This study used a short-term recognition-memory paradigm and found that in the easier conditions all these transformations were recognized with better than chance accuracy. The ascending order of difficulty was: inversion, retrograde, retrograde inversion. There was no evidence that listeners distinguish between transforms that preserve the exact interval relationships of the standard stimulus and those that merely preserve its contour (pattern of ups and downs). In view of the order of difficulty of the transforms, two theoretical explanations of performance are possible (1) Listeners may perform the mental transformation required by the recognition task on a representation of the vector of pitches in the standard—an operation that is very like transforming a mental image of the written notation. (2) Listeners may handle inversions differently from the other transformations, comparing the standard and the comparison contour element by contour element, in temporal order. In this view, the temporal dimension would appear to have precedence over the pitch dimension in the musical structure, in consideration of the consequences of disturbing it.},
	pages = {417--421},
	number = {5},
	journaltitle = {Perception \& Psychophysics},
	shortjournal = {Perception \& Psychophysics},
	author = {Dowling, W. J.},
	urldate = {2023-04-23},
	date = {1972-09-01},
	langid = {english},
	keywords = {Actual Music, Comparison Stimulus, Standard Stimulus, Stimulus Type, Visual Task},
	file = {Full Text PDF:/Users/sebsilas/Zotero/storage/DTDJ4KJ7/Dowling - 1972 - Recognition of melodic transformations Inversion,.pdf:application/pdf},
}

@article{harrisonPPMDecayComputationalModel2020,
	title = {{PPM}-Decay: A computational model of auditory prediction with memory decay},
	volume = {16},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008304},
	doi = {10.1371/journal.pcbi.1008304},
	shorttitle = {{PPM}-Decay},
	abstract = {Statistical learning and probabilistic prediction are fundamental processes in auditory cognition. A prominent computational model of these processes is Prediction by Partial Matching ({PPM}), a variable-order Markov model that learns by internalizing n-grams from training sequences. However, {PPM} has limitations as a cognitive model: in particular, it has a perfect memory that weights all historic observations equally, which is inconsistent with memory capacity constraints and recency effects observed in human cognition. We address these limitations with {PPM}-Decay, a new variant of {PPM} that introduces a customizable memory decay kernel. In three studies—one with artificially generated sequences, one with chord sequences from Western music, and one with new behavioral data from an auditory pattern detection experiment—we show how this decay kernel improves the model’s predictive performance for sequences whose underlying statistics change over time, and enables the model to capture effects of memory constraints on auditory pattern detection. The resulting model is available in our new open-source R package, ppm (https://github.com/pmcharrison/ppm).},
	pages = {e1008304},
	number = {11},
	journaltitle = {{PLOS} Computational Biology},
	shortjournal = {{PLOS} Computational Biology},
	author = {Harrison, Peter M. C. and Bianco, Roberta and Chait, Maria and Pearce, Marcus T.},
	urldate = {2023-04-25},
	date = {2020-11-04},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Algorithms, Learning, Markov models, Music cognition, Memory, Reaction time, Forecasting, Human performance},
	file = {Full Text PDF:/Users/sebsilas/Zotero/storage/9NNRMIKB/Harrison et al. - 2020 - PPM-Decay A computational model of auditory predi.pdf:application/pdf},
}

@article{eitelPerceptionChordSequences2023,
	title = {Perception of chord sequences modelled with Prediction by Partial Matching, Voice-leading distance, and Pitch-Class Spectral Similarity: A new approach for testing individual differences in harmony perception.},
	journaltitle = {In review.},
	author = {Eitel, Matthew and Harrison, Peter and Ruth, Nicholas and Frieler, Klaus and Müllensiefen, D.},
	date = {2023},
}

@article{deutschProcessingStructuredUnstructured1980,
	title = {The processing of structured and unstructured tonal sequences},
	volume = {28},
	issn = {1532-5962},
	url = {https://doi.org/10.3758/BF03204881},
	doi = {10.3758/BF03204881},
	abstract = {The recall of hierarchically organized tonal sequences was investigated in two experiments. An adaptation of the technique of melodic dictation was employed, in which musically trained listeners notated each sequence after it was presented. Strong effects of sequence structure were obtained. Sequences whose tonal structure could be parsimoniously encoded in hierarchical fashion were recalled with a high level of accuracy. Sequences that could not be parsimoniously encoded produced substantially more errors in recall. Temporal segmentation was found to have a substantial effect on performance, which reflected grouping by temporal proximity regardless of tonal structure. The results provide evidence for the hypothesis that we encode tonal materials by inferring sequence structures and alphabets at different hierarchical levels, together with their rules of combination.},
	pages = {381--389},
	number = {5},
	journaltitle = {Perception \& Psychophysics},
	shortjournal = {Perception \& Psychophysics},
	author = {Deutsch, Diana},
	urldate = {2023-04-25},
	date = {1980-09-01},
	langid = {english},
	keywords = {Reference Element, Sequence Structure, Serial Position, Serial Position Curve, Temporal Group},
	file = {Full Text PDF:/Users/sebsilas/Zotero/storage/8CAGWE4J/Deutsch - 1980 - The processing of structured and unstructured tona.pdf:application/pdf},
}

@article{chenetteWhatAreTruly2021,
	title = {What Are the Truly Aural Skills?},
	volume = {27},
	url = {https://mtosmt.org/issues/mto.21.27.2/mto.21.27.2.chenette.html},
	number = {2},
	journaltitle = {Music Theory Online},
	author = {Chenette, Timothy},
	urldate = {2023-04-25},
	date = {2021-05-01},
	langid = {english},
	file = {Snapshot:/Users/sebsilas/Zotero/storage/EBJ53IWQ/mto.21.27.2.chenette.html:text/html},
}

@article{corneliusInteractionRepetitionDifficulty2020,
	title = {The interaction of repetition and difficulty for working memory in melodic dictation tasks},
	volume = {42},
	issn = {1321-103X},
	url = {https://doi.org/10.1177/1321103X18821194},
	doi = {10.1177/1321103X18821194},
	abstract = {This research examines the effect of repetition on melodic dictation tasks in an undergraduate ear-training class. A pilot group of freshman music majors (n = 17) were asked to notate four melodies, of which two were slightly more difficult since they contained more melodic leaps. Participants heard two melodies repeated three times and two other melodies six times. An analysis of variance ({ANOVA}) suggests that the number of repetitions had a significant effect on participants? dictation accuracy, both for scores on pitch and on rhythm. In addition, dictation accuracy was significantly lower when the melodies contained more leaps (controlling for other factors). Overall, we found a statistical interaction between the number of repetitions and the number of leaps in the melody, both of which factors affect the working memory load in these dictation tasks. Given the similarity of the notated melodies, these findings suggest that ear-training pedagogues must carefully select melodic dictations appropriate for student ability and control the number of melodic leaps. Furthermore, we found evidence that the variance in working memory for music among this population is wider than Karpinski (2000) hypothesizes. These findings provide pedagogues with melodic characteristics well-suited for the average incoming freshman music major. Finally, this first empirical evidence of the dictation ability of incoming undergraduate music majors invites a long-term study on the extent to which working memory and/or chunking ability may increase during the multi-semester ear-training curriculum.},
	pages = {368--382},
	number = {3},
	journaltitle = {Research Studies in Music Education},
	author = {Cornelius, Nathan and Brown, Jenine L},
	urldate = {2023-04-25},
	date = {2020-10-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Ltd},
}

@book{karpinskiAuralSkillsAcquisition2000,
	title = {Aural Skills Acquisition: The Development of Listening, Reading, and Performing Skills in College-level Musicians},
	isbn = {978-0-19-511785-1},
	shorttitle = {Aural Skills Acquisition},
	abstract = {This book is a hands-on investigation of the stages musicians go through as they learn to hear, read, and perform music. It draws on the latest research in music perception and cognition, music theory, and pedagogy, along with centuries of insight from music theorists, composers, and performers. The first part explores the development of music listening skills, including such broader activities as dictation and transcription, and specific abilities such as meter perception, short-term musical memory, and tonic inference. The second part then examines the skills involved in reading and performing music. It looks at such physical skills as vocal production and eye movements and at such complex integrated tasks as sight-singing transpositions and modulations. Throughout the book the author presents these skills in their musical contexts and emphasizes their roles in the general development of musicality. Aural Skills Acquisition builds important bridges between music theory, cognitive psychology, and pedagogy. It subjects ideas from music theory to the rigors of psychological testing and combines findings from the psychology of learning with ideas and methods of contemporary music theory. It will prove an invaluable guide for music teachers, music theorists, and psychologists interested in music perception and cognition.},
	pagetotal = {274},
	publisher = {Oxford University Press},
	author = {Karpinski, Gary Steven},
	date = {2000},
	langid = {english},
	note = {Google-Books-{ID}: j\_NcQ1Cw6OkC},
}

@article{gatesDevelopingMusicalImagery2021,
	title = {Developing Musical Imagery: Contributions from Pedagogy and Cognitive Science},
	volume = {27},
	url = {https://mtosmt.org/issues/mto.21.27.2/mto.21.27.2.gates.html},
	shorttitle = {Developing Musical Imagery},
	number = {2},
	journaltitle = {Music Theory Online},
	author = {Gates, Sarah},
	urldate = {2023-04-25},
	date = {2021-06-01},
	langid = {english},
	file = {Snapshot:/Users/sebsilas/Zotero/storage/X33SLLCC/mto.21.27.2.gates.html:text/html},
}

@incollection{pearceMelodicGroupingMusic2010,
	location = {Berlin, Heidelberg},
	title = {Melodic Grouping in Music Information Retrieval: New Methods and Applications},
	isbn = {978-3-642-11674-2},
	url = {https://doi.org/10.1007/978-3-642-11674-2_16},
	series = {Studies in Computational Intelligence},
	shorttitle = {Melodic Grouping in Music Information Retrieval},
	abstract = {We introduce the {MIR} task of segmenting melodies into phrases, summarise the musicological and psychological background to the task and review existing computational methods before presenting a new model, {IDyOM}, for melodic segmentation based on statistical learning and information-dynamic analysis. The performance of the model is compared to several existing algorithms in predicting the annotated phrase boundaries in a large corpus of folk music. The results indicate that four algorithms produce acceptable results: one of these is the {IDyOM} model which performs much better than naive statistical models and approaches the performance of the best-performing rule-based models. Further slight performance improvement can be obtained by combining the output of the four algorithms in a hybrid model, although the performance of this model is moderate at best, leaving a great deal of room for improvement on this task.},
	pages = {364--388},
	booktitle = {Advances in Music Information Retrieval},
	publisher = {Springer},
	author = {Pearce, Marcus T. and Müllensiefen, Daniel and Wiggins, Geraint A.},
	editor = {Raś, Zbigniew W. and Wieczorkowska, Alicja A.},
	urldate = {2023-04-25},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-3-642-11674-2_16},
	keywords = {Music Perception, Music Information Retrieval, Boundary Strength, Ground Truth, Phrase Boundary},
}

@book{gusfieldAlgorithmsStringsTrees1997,
	location = {Cambridge},
	title = {Algorithms on Strings, Trees, and Sequences: Computer Science and Computational Biology},
	isbn = {978-0-521-58519-4},
	url = {https://www.cambridge.org/core/books/algorithms-on-strings-trees-and-sequences/F0B095049C7E6EF5356F0A26686C20D3},
	shorttitle = {Algorithms on Strings, Trees, and Sequences},
	abstract = {String algorithms are a traditional area of study in computer science. In recent years their importance has grown dramatically with the huge increase of electronically stored text and of molecular sequence data ({DNA} or protein sequences) produced by various genome projects. This book is a general text on computer algorithms for string processing. In addition to pure computer science, the book contains extensive discussions on biological problems that are cast as string problems, and on methods developed to solve them. It emphasises the fundamental ideas and techniques central to today's applications. New approaches to this complex material simplify methods that up to now have been for the specialist alone. With over 400 exercises to reinforce the material and develop additional topics, the book is suitable as a text for graduate or advanced undergraduate students in computer science, computational biology, or bio-informatics. Its discussion of current algorithms and techniques also makes it a reference for professionals.},
	publisher = {Cambridge University Press},
	author = {Gusfield, Dan},
	urldate = {2023-05-04},
	date = {1997},
	doi = {10.1017/CBO9780511574931},
	file = {Snapshot:/Users/sebsilas/Zotero/storage/QJNS726T/F0B095049C7E6EF5356F0A26686C20D3.html:text/html},
}

@misc{yuanPerceptualVsAutomated2020a,
	title = {Perceptual vs. automated judgments of music copyright infringement},
	url = {https://psyarxiv.com/tq7v5/},
	doi = {10.31234/osf.io/tq7v5},
	abstract = {Music copyright lawsuits often result in multimillion dollar damage awards or settlements, yet there are few objective guidelines for applying copyright law in infringement claims involving musical works. Recent re-search has attempted to develop objective methods based on automated similarity algorithms, but there remains almost no data on the role of perceived similarity in mu-sic copyright decisions despite its crucial role in copy-right law. We collected perceptual data from 20 participants for 17 adjudicated copyright cases from the {USA} and Japan after editing the disputed sections to contain either full audio, melody only, or lyrics only. Due to the historical emphasis in legal opinions on melody as the key criterion for deciding infringement, we predicted that listening to melody-only versions would result in perceptual judgements that more closely matched actual past legal decisions. Surprisingly, however, we found no significant differences between the three conditions, with participants matching past decisions in between 50-60\% of cases in all three conditions. Automated algorithms designed to calculate melodic and audio similarity produced comparable results: both algorithms were able to match past decisions with identical accuracy of 71\% (12/17 cases). Analysis of cases that were difficult to classify suggests that melody, lyrics, and other factors sometimes interact in complex ways difficult to capture using quantitative metrics. We propose directions for further investigation of the role of similarity in music copy-right law using larger and more diverse samples of cases and enhanced methods, and adapting our perceptual experiment method to avoid relying for ground truth data only on court decisions (which may be subject to selection bias). Our results contribute to important practical debates, such as whether jury members should be allowed to listen to full audio recordings during copyright cases.},
	publisher = {{PsyArXiv}},
	author = {Yuan, Yuchen and Oishi, Sho and Cronin, Charles and Müllensiefen, Daniel and Atkinson, Quentin and Fujii, Shinya and Savage, Patrick E.},
	urldate = {2023-05-04},
	date = {2020-07-10},
	langid = {english},
	keywords = {Music, Social and Behavioral Sciences},
	file = {Full Text PDF:/Users/sebsilas/Zotero/storage/2J5E3WNZ/Yuan et al. - 2020 - Perceptual vs. automated judgments of music copyri.pdf:application/pdf},
}
